{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Powertools is a suite of utilities for AWS Lambda Functions that makes tracing with AWS X-Ray, structured logging and creating custom metrics asynchronously easier. Looking for a quick run through of the core utilities? Check out this detailed blog post with a practical example. Tenets \u00b6 This project separates core utilities that will be available in other runtimes vs general utilities that might not be available across all runtimes. AWS Lambda only \u2013 We optimise for AWS Lambda function environments and supported runtimes only. Utilities might work with web frameworks and non-Lambda environments, though they are not officially supported. Eases the adoption of best practices \u2013 The main priority of the utilities is to facilitate best practices adoption, as defined in the AWS Well-Architected Serverless Lens; all other functionality is optional. Keep it lean \u2013 Additional dependencies are carefully considered for security and ease of maintenance, and prevent negatively impacting startup time. We strive for backwards compatibility \u2013 New features and changes should keep backwards compatibility. If a breaking change cannot be avoided, the deprecation and migration process should be clearly defined. We work backwards from the community \u2013 We aim to strike a balance of what would work best for 80% of customers. Emerging practices are considered and discussed via Requests for Comment (RFCs) Progressive - Utilities are designed to be incrementally adoptable for customers at any stage of their Serverless journey. They follow language idioms and their community\u2019s common practices. Install \u00b6 Powertools dependencies are available in Maven Central. You can use your favourite dependency management tool to install it Maven Gradle Quick hello world examples using SAM CLI You can use SAM to quickly setup a serverless project including AWS Lambda Powertools Java. 1 sam init --location gh:aws-samples/cookiecutter-aws-sam-powertools-java For more information about the project and available options refer to this repository Maven Gradle 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 <dependencies> ... <dependency> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-tracing </artifactId> <version> 1.10.3 </version> </dependency> <dependency> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-logging </artifactId> <version> 1.10.3 </version> </dependency> <dependency> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-metrics </artifactId> <version> 1.10.3 </version> </dependency> ... </dependencies> ... <!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --> <build> <plugins> ... <plugin> <groupId> org.codehaus.mojo </groupId> <artifactId> aspectj-maven-plugin </artifactId> <version> 1.14.0 </version> <configuration> <source> 1.8 </source> <target> 1.8 </target> <complianceLevel> 1.8 </complianceLevel> <aspectLibraries> <aspectLibrary> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-tracing </artifactId> </aspectLibrary> <aspectLibrary> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-logging </artifactId> </aspectLibrary> <aspectLibrary> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-metrics </artifactId> </aspectLibrary> </aspectLibraries> </configuration> <executions> <execution> <goals> <goal> compile </goal> </goals> </execution> </executions> </plugin> ... </plugins> </build> 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 plugins { id 'java' id 'io.freefair.aspectj.post-compile-weaving' version '6.3.0' } repositories { mavenCentral () } dependencies { aspect 'software.amazon.lambda:powertools-logging:1.10.3' aspect 'software.amazon.lambda:powertools-tracing:1.10.3' aspect 'software.amazon.lambda:powertools-metrics:1.10.3' } sourceCompatibility = 11 targetCompatibility = 11 Environment variables \u00b6 Info Explicit parameters take precedence over environment variables. Environment variable Description Utility POWERTOOLS_SERVICE_NAME Sets service name used for tracing namespace, metrics dimension and structured logging All POWERTOOLS_METRICS_NAMESPACE Sets namespace used for metrics Metrics POWERTOOLS_LOGGER_SAMPLE_RATE Debug log sampling Logging POWERTOOLS_LOG_LEVEL Sets logging level Logging POWERTOOLS_TRACER_CAPTURE_RESPONSE Enables/Disables tracing mode to capture method response Tracing POWERTOOLS_TRACER_CAPTURE_ERROR Enables/Disables tracing mode to capture method error Tracing","title":"Homepage"},{"location":"#tenets","text":"This project separates core utilities that will be available in other runtimes vs general utilities that might not be available across all runtimes. AWS Lambda only \u2013 We optimise for AWS Lambda function environments and supported runtimes only. Utilities might work with web frameworks and non-Lambda environments, though they are not officially supported. Eases the adoption of best practices \u2013 The main priority of the utilities is to facilitate best practices adoption, as defined in the AWS Well-Architected Serverless Lens; all other functionality is optional. Keep it lean \u2013 Additional dependencies are carefully considered for security and ease of maintenance, and prevent negatively impacting startup time. We strive for backwards compatibility \u2013 New features and changes should keep backwards compatibility. If a breaking change cannot be avoided, the deprecation and migration process should be clearly defined. We work backwards from the community \u2013 We aim to strike a balance of what would work best for 80% of customers. Emerging practices are considered and discussed via Requests for Comment (RFCs) Progressive - Utilities are designed to be incrementally adoptable for customers at any stage of their Serverless journey. They follow language idioms and their community\u2019s common practices.","title":"Tenets"},{"location":"#install","text":"Powertools dependencies are available in Maven Central. You can use your favourite dependency management tool to install it Maven Gradle Quick hello world examples using SAM CLI You can use SAM to quickly setup a serverless project including AWS Lambda Powertools Java. 1 sam init --location gh:aws-samples/cookiecutter-aws-sam-powertools-java For more information about the project and available options refer to this repository Maven Gradle 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 <dependencies> ... <dependency> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-tracing </artifactId> <version> 1.10.3 </version> </dependency> <dependency> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-logging </artifactId> <version> 1.10.3 </version> </dependency> <dependency> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-metrics </artifactId> <version> 1.10.3 </version> </dependency> ... </dependencies> ... <!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --> <build> <plugins> ... <plugin> <groupId> org.codehaus.mojo </groupId> <artifactId> aspectj-maven-plugin </artifactId> <version> 1.14.0 </version> <configuration> <source> 1.8 </source> <target> 1.8 </target> <complianceLevel> 1.8 </complianceLevel> <aspectLibraries> <aspectLibrary> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-tracing </artifactId> </aspectLibrary> <aspectLibrary> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-logging </artifactId> </aspectLibrary> <aspectLibrary> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-metrics </artifactId> </aspectLibrary> </aspectLibraries> </configuration> <executions> <execution> <goals> <goal> compile </goal> </goals> </execution> </executions> </plugin> ... </plugins> </build> 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 plugins { id 'java' id 'io.freefair.aspectj.post-compile-weaving' version '6.3.0' } repositories { mavenCentral () } dependencies { aspect 'software.amazon.lambda:powertools-logging:1.10.3' aspect 'software.amazon.lambda:powertools-tracing:1.10.3' aspect 'software.amazon.lambda:powertools-metrics:1.10.3' } sourceCompatibility = 11 targetCompatibility = 11","title":"Install"},{"location":"#environment-variables","text":"Info Explicit parameters take precedence over environment variables. Environment variable Description Utility POWERTOOLS_SERVICE_NAME Sets service name used for tracing namespace, metrics dimension and structured logging All POWERTOOLS_METRICS_NAMESPACE Sets namespace used for metrics Metrics POWERTOOLS_LOGGER_SAMPLE_RATE Debug log sampling Logging POWERTOOLS_LOG_LEVEL Sets logging level Logging POWERTOOLS_TRACER_CAPTURE_RESPONSE Enables/Disables tracing mode to capture method response Tracing POWERTOOLS_TRACER_CAPTURE_ERROR Enables/Disables tracing mode to capture method error Tracing","title":"Environment variables"},{"location":"FAQs/","text":"How can I use Powertools with Lombok? \u00b6 Poweretools uses aspectj-maven-plugin to compile-time weave (CTW) aspects into the project. In case you want to use Lombok or other compile-time preprocessor for your project, it is required to change aspectj-maven-plugin configuration to enable in-place weaving feature. Otherwise the plugin will ignore changes introduced by Lombok and will use .java files as a source. To enable in-place weaving feature you need to use following aspectj-maven-plugin configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 <configuration> <forceAjcCompile> true </forceAjcCompile> <sources/> <weaveDirectories> <weaveDirectory> ${project.build.directory}/classes </weaveDirectory> </weaveDirectories> ... <aspectLibraries> <aspectLibrary> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-logging </artifactId> </aspectLibrary> </aspectLibraries> </configuration>","title":"FAQs"},{"location":"FAQs/#how-can-i-use-powertools-with-lombok","text":"Poweretools uses aspectj-maven-plugin to compile-time weave (CTW) aspects into the project. In case you want to use Lombok or other compile-time preprocessor for your project, it is required to change aspectj-maven-plugin configuration to enable in-place weaving feature. Otherwise the plugin will ignore changes introduced by Lombok and will use .java files as a source. To enable in-place weaving feature you need to use following aspectj-maven-plugin configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 <configuration> <forceAjcCompile> true </forceAjcCompile> <sources/> <weaveDirectories> <weaveDirectory> ${project.build.directory}/classes </weaveDirectory> </weaveDirectories> ... <aspectLibraries> <aspectLibrary> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-logging </artifactId> </aspectLibrary> </aspectLibraries> </configuration>","title":"How can I use Powertools with Lombok?"},{"location":"changelog/","text":"Changelog \u00b6 All notable changes to this project will be documented in this file. This project follows Keep a Changelog format for changes and adheres to Semantic Versioning . [Unreleased] \u00b6 [1.10.3] - 2022-02-01 \u00b6 Bug Fixes \u00b6 SQS Batch processing : Prevent message to be marked as success if failed sending to DLQ for non retryable exceptions. [#731]https://github.com/awslabs/aws-lambda-powertools-java/pull/731 Documentation \u00b6 SQS Batch processing : Improve documentation on IAM premissions required by function when using utility with an encrypted SQS queue with customer managed KMS keys. [1.10.2] - 2022-01-07 \u00b6 Tracing : Ability to override object mapper used for serializing method response as trace metadata when enabled. This provides users ability to customize how and what you want to capture as metadata from method response object. #698 [1.10.1] - 2022-01-06 \u00b6 Logging : Upgrade Log4j to version 2.17.1 for CVE-2021-44832 [1.10.0] - 2021-12-27 \u00b6 Logging : Modern log4j configuration to customise structured logging. Refer docs to start using new config. #670 SQS Batch : Support batch size greater than 10. #667 [1.9.0] - 2021-12-21 \u00b6 Logging : Upgrade Log4j to version 2.17.0 for CVE-2021-45105 Tracing : add Service annotation. #654 [1.8.2] - 2021-12-15 \u00b6 Security \u00b6 Upgrading Log4j to version 2.16.0 for CVE-2021-45046 [1.8.1] - 2021-12-10 \u00b6 Security \u00b6 Upgrading Log4j to version 2.15.0 for CVE-2021-44228 [1.8.0] - 2021-11-05 \u00b6 Added \u00b6 Powertools Cloudformation module (NEW) : New module simplifying AWS Lambda-backed custom resources written in Java. #560 SQS Large message processing : Ability to override the default S3Client use to fetch payload from S3. #602 Regression \u00b6 Logging : @Logging annotation now works with @Tracing annotation on RequestStreamHandler when used in logEvent mode. #567 Maintenance \u00b6 deps : Bump third party dependencies to the latest versions. [1.7.3] - 2021-09-14 \u00b6 SQS Batch processing : Ability to move non retryable message to configured dead letter queue(DLQ). #500 [1.7.2] - 2021-08-03 \u00b6 Powertools All Modules : Upgrade to the latest(1.14.0) aspectj-maven-plugin which also supports Java 9 and newer versions. Users no longer need to depend on com.nickwongdev as a workaround. #489 Logging : Performance optimisation to improve cold start. #484 SQS Batch processing/Large message : Module now lazy loads default SQS client. #484 [1.7.1] - 2021-07-06 \u00b6 Powertools All Modules : Fix static code analysis violations done via spotbugs ( #458 ). [1.7.0] - 2021-07-05 \u00b6 Added \u00b6 Logging : Support for extracting Correlation id using @Logging annotation via correlationIdPath attribute and setCorrelationId() method in LoggingUtils ( #448 ). Logging : New clearState attribute on @Logging annotation to clear previously added custom keys upon invocation( #453 ). Maintenance \u00b6 deps : Bump third party dependencies to the latest versions. [1.6.0] - 2021-06-21 \u00b6 Added \u00b6 Tracing : Support for Boolean and Number type as value in TracingUtils.putAnnotation() ( #423 ). Logging : API to remove any additional custom key from logger entry using LoggingUtils.removeKeys() ( #395 ). Maintenance \u00b6 deps : Bump third party dependencies to the latest versions. [1.5.0] - 2021-03-30 \u00b6 Metrics : Ability to set multiple dimensions as default dimensions via MetricsUtils.defaultDimensions() . Introduced in v1.4.0 MetricsUtils.defaultDimensionSet() is deprecated now for better user experience. [1.4.0] - 2021-03-11 \u00b6 Metrics : Ability to set default dimension for metrics via MetricsUtils.defaultDimensionSet() . Note : If your monitoring depends on default dimensions captured before via aws-embedded-metrics-java , those either need to be updated or has to be explicitly captured via MetricsUtils.defaultDimensionSet() . Metrics : Remove validation of having minimum one dimension. EMF now support Dimension set being empty as well. [1.3.0] - 2021-03-05 \u00b6 Powertools : It now works out of the box with code guru profile handler implementation . Logging : Ability to override object mapper used for logging event. This provides customers ability to customize how and what they want to log from event. Metrics : Module now by default captures AWS Request id as property if used together with Metrics annotation. It will also capture Xray Trace ID as property if tracing is enabled. This ensures good observability and tracing. Metrics : withSingleMetric from `MetricsUtils can now pick the default namespace specified either on Metrics annotation or via POWERTOOLS_METRICS_NAMESPACE env var, without need to specify explicitly for each call. Metrics : Metrics annotation captures metrics even in case of unhandled exception from Lambda function. Docs : Migrated from Gatsby to MKdocs documentation system","title":"Changelog"},{"location":"changelog/#changelog","text":"All notable changes to this project will be documented in this file. This project follows Keep a Changelog format for changes and adheres to Semantic Versioning .","title":"Changelog"},{"location":"changelog/#unreleased","text":"","title":"[Unreleased]"},{"location":"changelog/#1103-2022-02-01","text":"","title":"[1.10.3] - 2022-02-01"},{"location":"changelog/#bug-fixes","text":"SQS Batch processing : Prevent message to be marked as success if failed sending to DLQ for non retryable exceptions. [#731]https://github.com/awslabs/aws-lambda-powertools-java/pull/731","title":"Bug Fixes"},{"location":"changelog/#documentation","text":"SQS Batch processing : Improve documentation on IAM premissions required by function when using utility with an encrypted SQS queue with customer managed KMS keys.","title":"Documentation"},{"location":"changelog/#1102-2022-01-07","text":"Tracing : Ability to override object mapper used for serializing method response as trace metadata when enabled. This provides users ability to customize how and what you want to capture as metadata from method response object. #698","title":"[1.10.2] - 2022-01-07"},{"location":"changelog/#1101-2022-01-06","text":"Logging : Upgrade Log4j to version 2.17.1 for CVE-2021-44832","title":"[1.10.1] - 2022-01-06"},{"location":"changelog/#1100-2021-12-27","text":"Logging : Modern log4j configuration to customise structured logging. Refer docs to start using new config. #670 SQS Batch : Support batch size greater than 10. #667","title":"[1.10.0] - 2021-12-27"},{"location":"changelog/#190-2021-12-21","text":"Logging : Upgrade Log4j to version 2.17.0 for CVE-2021-45105 Tracing : add Service annotation. #654","title":"[1.9.0] - 2021-12-21"},{"location":"changelog/#182-2021-12-15","text":"","title":"[1.8.2] - 2021-12-15"},{"location":"changelog/#security","text":"Upgrading Log4j to version 2.16.0 for CVE-2021-45046","title":"Security"},{"location":"changelog/#181-2021-12-10","text":"","title":"[1.8.1] - 2021-12-10"},{"location":"changelog/#security_1","text":"Upgrading Log4j to version 2.15.0 for CVE-2021-44228","title":"Security"},{"location":"changelog/#180-2021-11-05","text":"","title":"[1.8.0] - 2021-11-05"},{"location":"changelog/#added","text":"Powertools Cloudformation module (NEW) : New module simplifying AWS Lambda-backed custom resources written in Java. #560 SQS Large message processing : Ability to override the default S3Client use to fetch payload from S3. #602","title":"Added"},{"location":"changelog/#regression","text":"Logging : @Logging annotation now works with @Tracing annotation on RequestStreamHandler when used in logEvent mode. #567","title":"Regression"},{"location":"changelog/#maintenance","text":"deps : Bump third party dependencies to the latest versions.","title":"Maintenance"},{"location":"changelog/#173-2021-09-14","text":"SQS Batch processing : Ability to move non retryable message to configured dead letter queue(DLQ). #500","title":"[1.7.3] - 2021-09-14"},{"location":"changelog/#172-2021-08-03","text":"Powertools All Modules : Upgrade to the latest(1.14.0) aspectj-maven-plugin which also supports Java 9 and newer versions. Users no longer need to depend on com.nickwongdev as a workaround. #489 Logging : Performance optimisation to improve cold start. #484 SQS Batch processing/Large message : Module now lazy loads default SQS client. #484","title":"[1.7.2] - 2021-08-03"},{"location":"changelog/#171-2021-07-06","text":"Powertools All Modules : Fix static code analysis violations done via spotbugs ( #458 ).","title":"[1.7.1] - 2021-07-06"},{"location":"changelog/#170-2021-07-05","text":"","title":"[1.7.0] - 2021-07-05"},{"location":"changelog/#added_1","text":"Logging : Support for extracting Correlation id using @Logging annotation via correlationIdPath attribute and setCorrelationId() method in LoggingUtils ( #448 ). Logging : New clearState attribute on @Logging annotation to clear previously added custom keys upon invocation( #453 ).","title":"Added"},{"location":"changelog/#maintenance_1","text":"deps : Bump third party dependencies to the latest versions.","title":"Maintenance"},{"location":"changelog/#160-2021-06-21","text":"","title":"[1.6.0] - 2021-06-21"},{"location":"changelog/#added_2","text":"Tracing : Support for Boolean and Number type as value in TracingUtils.putAnnotation() ( #423 ). Logging : API to remove any additional custom key from logger entry using LoggingUtils.removeKeys() ( #395 ).","title":"Added"},{"location":"changelog/#maintenance_2","text":"deps : Bump third party dependencies to the latest versions.","title":"Maintenance"},{"location":"changelog/#150-2021-03-30","text":"Metrics : Ability to set multiple dimensions as default dimensions via MetricsUtils.defaultDimensions() . Introduced in v1.4.0 MetricsUtils.defaultDimensionSet() is deprecated now for better user experience.","title":"[1.5.0] - 2021-03-30"},{"location":"changelog/#140-2021-03-11","text":"Metrics : Ability to set default dimension for metrics via MetricsUtils.defaultDimensionSet() . Note : If your monitoring depends on default dimensions captured before via aws-embedded-metrics-java , those either need to be updated or has to be explicitly captured via MetricsUtils.defaultDimensionSet() . Metrics : Remove validation of having minimum one dimension. EMF now support Dimension set being empty as well.","title":"[1.4.0] - 2021-03-11"},{"location":"changelog/#130-2021-03-05","text":"Powertools : It now works out of the box with code guru profile handler implementation . Logging : Ability to override object mapper used for logging event. This provides customers ability to customize how and what they want to log from event. Metrics : Module now by default captures AWS Request id as property if used together with Metrics annotation. It will also capture Xray Trace ID as property if tracing is enabled. This ensures good observability and tracing. Metrics : withSingleMetric from `MetricsUtils can now pick the default namespace specified either on Metrics annotation or via POWERTOOLS_METRICS_NAMESPACE env var, without need to specify explicitly for each call. Metrics : Metrics annotation captures metrics even in case of unhandled exception from Lambda function. Docs : Migrated from Gatsby to MKdocs documentation system","title":"[1.3.0] - 2021-03-05"},{"location":"core/logging/","text":"Logging provides an opinionated logger with output structured as JSON. Key features Capture key fields from Lambda context, cold start and structures logging output as JSON Log Lambda event when instructed, disabled by default, can be enabled explicitly via annotation param Append additional keys to structured log at any point in time Initialization \u00b6 Powertools extends the functionality of Log4J. Below is an example log4j2.xml file, with the JsonTemplateLayout using LambdaJso n Layou t .jso n configured. LambdaJsonLayout is now deprecated Configuring utiltiy using <LambdaJsonLayout/> plugin is deprecated now. While utility still supports the old configuration, we strongly recommend upgrading the log4j2.xml configuration to JsonTemplateLayout instead. JsonTemplateLayout is recommended way of doing structured logging. Please follow this guide for upgrade steps. log4j2.xml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 <?xml version=\"1.0\" encoding=\"UTF-8\"?> <Configuration> <Appenders> <Console name= \"JsonAppender\" target= \"SYSTEM_OUT\" > <JsonTemplateLayout eventTemplateUri= \"classpath:LambdaJsonLayout.json\" /> </Console> </Appenders> <Loggers> <Logger name= \"JsonLogger\" level= \"INFO\" additivity= \"false\" > <AppenderRef ref= \"JsonAppender\" /> </Logger> <Root level= \"info\" > <AppenderRef ref= \"JsonAppender\" /> </Root> </Loggers> </Configuration> You can also override log level by setting POWERTOOLS_LOG_LEVEL env var. Here is an example using AWS Serverless Application Model (SAM) template.yaml 1 2 3 4 5 6 7 8 9 10 Resources : HelloWorldFunction : Type : AWS::Serverless::Function Properties : ... Runtime : java8 Environment : Variables : POWERTOOLS_LOG_LEVEL : DEBUG POWERTOOLS_SERVICE_NAME : example You can also explicitly set a service name via POWERTOOLS_SERVICE_NAME env var. This sets service key that will be present across all log statements. Standard structured keys \u00b6 Your logs will always include the following keys to your structured logging: Key Type Example Description timestamp String \"2020-05-24 18:17:33,774\" Timestamp of actual log statement level String \"INFO\" Logging level coldStart Boolean true ColdStart value. service String \"payment\" Service name defined. \"service_undefined\" will be used if unknown samplingRate int 0.1 Debug logging sampling rate in percentage e.g. 10% in this case message String \"Collecting payment\" Log statement value. Unserializable JSON values will be casted to string functionName String \"example-powertools-HelloWorldFunction-1P1Z6B39FLU73\" functionVersion String \"12\" functionMemorySize String \"128\" functionArn String \"arn:aws:lambda:eu-west-1:012345678910:function:example-powertools-HelloWorldFunction-1P1Z6B39FLU73\" xray_trace_id String \"1-5759e988-bd862e3fe1be46a994272793\" X-Ray Trace ID when Lambda function has enabled Tracing function_request_id String \"899856cb-83d1-40d7-8611-9e78f15f32f4\"\" AWS Request ID from lambda context Capturing context Lambda info \u00b6 You can enrich your structured logs with key Lambda context information via logEvent annotation parameter. You can also explicitly log any incoming event using logEvent param. Refer Override default object mapper to customise what is logged. Warning Log event is disabled by default to prevent sensitive info being logged. App.java AppLogEvent.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import org.apache.logging.log4j.LogManager ; import org.apache.logging.log4j.Logger ; import software.amazon.lambda.powertools.logging.LoggingUtils ; import software.amazon.lambda.powertools.logging.Logging ; ... /** * Handler for requests to Lambda function. */ public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { Logger log = LogManager . getLogger (); @Logging public APIGatewayProxyResponseEvent handleRequest ( final APIGatewayProxyRequestEvent input , final Context context ) { ... } } 1 2 3 4 5 6 7 8 9 10 11 12 /** * Handler for requests to Lambda function. */ public class AppLogEvent implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { Logger log = LogManager . getLogger (); @Logging ( logEvent = true ) public APIGatewayProxyResponseEvent handleRequest ( final APIGatewayProxyRequestEvent input , final Context context ) { ... } } Customising fields in logs \u00b6 Utility by default emits timestamp field in the logs in format yyyy-MM-dd'T'HH:mm:ss.SSSZz and in system default timezone. If you need to customize format and timezone, you can do so by configuring log4j2.component.properties and configuring properties as shown in example below: log4j2.component.properties 1 2 log4j.layout.jsonTemplate.timestampFormatPattern = yyyy-MM-dd'T'HH:mm:ss.SSSZz log4j.layout.jsonTemplate.timeZone = Europe/Oslo Utility also provides sample template for Elastic Common Schema(ECS) layout. The field emitted in logs will follow specs from ECS together with field captured by utility as mentioned above . Use LambdaEcsLayout.json as eventTemplateUri when configuring JsonTemplateLayout . log4j2.xml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 <?xml version=\"1.0\" encoding=\"UTF-8\"?> <Configuration> <Appenders> <Console name= \"JsonAppender\" target= \"SYSTEM_OUT\" > <JsonTemplateLayout eventTemplateUri= \"classpath:LambdaEcsLayout.json\" /> </Console> </Appenders> <Loggers> <Logger name= \"JsonLogger\" level= \"INFO\" additivity= \"false\" > <AppenderRef ref= \"JsonAppender\" /> </Logger> <Root level= \"info\" > <AppenderRef ref= \"JsonAppender\" /> </Root> </Loggers> </Configuration> Setting a Correlation ID \u00b6 You can set a Correlation ID using correlationIdPath attribute by passing a JSON Pointer expression . App.java Example Event Example CloudWatch Logs excerpt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 /** * Handler for requests to Lambda function. */ public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { Logger log = LogManager . getLogger (); @Logging ( correlationIdPath = \"/headers/my_request_id_header\" ) public APIGatewayProxyResponseEvent handleRequest ( final APIGatewayProxyRequestEvent input , final Context context ) { ... log . info ( \"Collecting payment\" ) ... } } 1 2 3 4 5 { \"headers\" : { \"my_request_id_header\" : \"correlation_id_value\" } } 1 2 3 4 5 6 7 8 9 10 11 12 { \"level\" : \"INFO\" , \"message\" : \"Collecting payment\" , \"timestamp\" : \"2021-05-03 11:47:12,494+0200\" , \"service\" : \"payment\" , \"coldStart\" : true , \"functionName\" : \"test\" , \"functionMemorySize\" : 128 , \"functionArn\" : \"arn:aws:lambda:eu-west-1:12345678910:function:test\" , \"lambda_request_id\" : \"52fdfc07-2182-154f-163f-5f0f9a621d72\" , \"correlation_id\" : \"correlation_id_value\" } We provide built-in JSON Pointer expression for known event sources, where either a request ID or X-Ray Trace ID are present. App.java Example Event Example CloudWatch Logs excerpt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import software.amazon.lambda.powertools.logging.CorrelationIdPathConstants ; /** * Handler for requests to Lambda function. */ public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { Logger log = LogManager . getLogger (); @Logging ( correlationIdPath = CorrelationIdPathConstants . API_GATEWAY_REST ) public APIGatewayProxyResponseEvent handleRequest ( final APIGatewayProxyRequestEvent input , final Context context ) { ... log . info ( \"Collecting payment\" ) ... } } 1 2 3 4 5 { \"requestContext\" : { \"requestId\" : \"correlation_id_value\" } } 1 2 3 4 5 6 7 8 9 10 11 12 { \"level\" : \"INFO\" , \"message\" : \"Collecting payment\" , \"timestamp\" : \"2021-05-03 11:47:12,494+0200\" , \"service\" : \"payment\" , \"coldStart\" : true , \"functionName\" : \"test\" , \"functionMemorySize\" : 128 , \"functionArn\" : \"arn:aws:lambda:eu-west-1:12345678910:function:test\" , \"lambda_request_id\" : \"52fdfc07-2182-154f-163f-5f0f9a621d72\" , \"correlation_id\" : \"correlation_id_value\" } Appending additional keys \u00b6 Custom keys are persisted across warm invocations Always set additional keys as part of your handler to ensure they have the latest value, or explicitly clear them with clearState=true . You can append your own keys to your existing logs via appendKey . App.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 /** * Handler for requests to Lambda function. */ public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { Logger log = LogManager . getLogger (); @Logging ( logEvent = true ) public APIGatewayProxyResponseEvent handleRequest ( final APIGatewayProxyRequestEvent input , final Context context ) { ... LoggingUtils . appendKey ( \"test\" , \"willBeLogged\" ); ... ... Map < String , String > customKeys = new HashMap <> (); customKeys . put ( \"test\" , \"value\" ); customKeys . put ( \"test1\" , \"value1\" ); LoggingUtils . appendKeys ( customKeys ); ... } } Removing additional keys \u00b6 You can remove any additional key from entry using LoggingUtils.removeKeys() . App.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 /** * Handler for requests to Lambda function. */ public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { Logger log = LogManager . getLogger (); @Logging ( logEvent = true ) public APIGatewayProxyResponseEvent handleRequest ( final APIGatewayProxyRequestEvent input , final Context context ) { ... LoggingUtils . appendKey ( \"test\" , \"willBeLogged\" ); ... Map < String , String > customKeys = new HashMap <> (); customKeys . put ( \"test1\" , \"value\" ); customKeys . put ( \"test2\" , \"value1\" ); LoggingUtils . appendKeys ( customKeys ); ... LoggingUtils . removeKey ( \"test\" ); LoggingUtils . removeKeys ( \"test1\" , \"test2\" ); ... } } Clearing all state \u00b6 Logger is commonly initialized in the global scope. Due to Lambda Execution Context reuse , this means that custom keys can be persisted across invocations. If you want all custom keys to be deleted, you can use clearState=true attribute on @Logging annotation. App.java #1 Request #2 Request 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 /** * Handler for requests to Lambda function. */ public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { Logger log = LogManager . getLogger (); @Logging ( clearState = true ) public APIGatewayProxyResponseEvent handleRequest ( final APIGatewayProxyRequestEvent input , final Context context ) { ... if ( input . getHeaders (). get ( \"someSpecialHeader\" )) { LoggingUtils . appendKey ( \"specialKey\" , \"value\" ); } log . info ( \"Collecting payment\" ); ... } } 1 2 3 4 5 6 7 8 9 10 11 12 { \"level\" : \"INFO\" , \"message\" : \"Collecting payment\" , \"timestamp\" : \"2021-05-03 11:47:12,494+0200\" , \"service\" : \"payment\" , \"coldStart\" : true , \"functionName\" : \"test\" , \"functionMemorySize\" : 128 , \"functionArn\" : \"arn:aws:lambda:eu-west-1:12345678910:function:test\" , \"lambda_request_id\" : \"52fdfc07-2182-154f-163f-5f0f9a621d72\" , \"specialKey\" : \"value\" } 1 2 3 4 5 6 7 8 9 10 11 { \"level\" : \"INFO\" , \"message\" : \"Collecting payment\" , \"timestamp\" : \"2021-05-03 11:47:12,494+0200\" , \"service\" : \"payment\" , \"coldStart\" : true , \"functionName\" : \"test\" , \"functionMemorySize\" : 128 , \"functionArn\" : \"arn:aws:lambda:eu-west-1:12345678910:function:test\" , \"lambda_request_id\" : \"52fdfc07-2182-154f-163f-5f0f9a621d72\" } Override default object mapper \u00b6 You can optionally choose to override default object mapper which is used to serialize lambda function events. You might want to supply custom object mapper in order to control how serialisation is done, for example, when you want to log only specific fields from received event due to security. App.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 /** * Handler for requests to Lambda function. */ public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { Logger log = LogManager . getLogger (); static { ObjectMapper objectMapper = new ObjectMapper (); LoggingUtils . defaultObjectMapper ( objectMapper ); } @Logging ( logEvent = true ) public APIGatewayProxyResponseEvent handleRequest ( final APIGatewayProxyRequestEvent input , final Context context ) { ... } } Sampling debug logs \u00b6 You can dynamically set a percentage of your logs to DEBUG level via env var POWERTOOLS_LOGGER_SAMPLE_RATE or via samplingRate attribute on annotation. Info Configuration on environment variable is given precedence over sampling rate configuration on annotation, provided it's in valid value range. Sampling via annotation attribute Sampling via environment variable 1 2 3 4 5 6 7 8 9 10 11 12 /** * Handler for requests to Lambda function. */ public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { Logger log = LogManager . getLogger (); @Logging ( samplingRate = 0.5 ) public APIGatewayProxyResponseEvent handleRequest ( final APIGatewayProxyRequestEvent input , final Context context ) { ... } } 1 2 3 4 5 6 7 8 9 Resources : HelloWorldFunction : Type : AWS::Serverless::Function Properties : ... Runtime : java8 Environment : Variables : POWERTOOLS_LOGGER_SAMPLE_RATE : 0.5 Upgrade to JsonTemplateLayout from deprecated LambdaJsonLayout configuration in log4j2.xml \u00b6 Prior to version 1.10.0 , only supported way of configuring log4j2.xml was via <LambdaJsonLayout/> . This plugin is deprecated now and will be removed in future version. Switching to JsonTemplateLayout is straight forward. Below examples shows deprecated and new configuration of log4j2.xml . Deprecated configuration of log4j2.xml New configuration of log4j2.xml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 <?xml version=\"1.0\" encoding=\"UTF-8\"?> <Configuration> <Appenders> <Console name= \"JsonAppender\" target= \"SYSTEM_OUT\" > <LambdaJsonLayout compact= \"true\" eventEol= \"true\" /> </Console> </Appenders> <Loggers> <Logger name= \"JsonLogger\" level= \"INFO\" additivity= \"false\" > <AppenderRef ref= \"JsonAppender\" /> </Logger> <Root level= \"info\" > <AppenderRef ref= \"JsonAppender\" /> </Root> </Loggers> </Configuration> 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 <?xml version=\"1.0\" encoding=\"UTF-8\"?> <Configuration> <Appenders> <Console name= \"JsonAppender\" target= \"SYSTEM_OUT\" > <JsonTemplateLayout eventTemplateUri= \"classpath:LambdaJsonLayout.json\" /> </Console> </Appenders> <Loggers> <Logger name= \"JsonLogger\" level= \"INFO\" additivity= \"false\" > <AppenderRef ref= \"JsonAppender\" /> </Logger> <Root level= \"info\" > <AppenderRef ref= \"JsonAppender\" /> </Root> </Loggers> </Configuration>","title":"Logging"},{"location":"core/logging/#initialization","text":"Powertools extends the functionality of Log4J. Below is an example log4j2.xml file, with the JsonTemplateLayout using LambdaJso n Layou t .jso n configured. LambdaJsonLayout is now deprecated Configuring utiltiy using <LambdaJsonLayout/> plugin is deprecated now. While utility still supports the old configuration, we strongly recommend upgrading the log4j2.xml configuration to JsonTemplateLayout instead. JsonTemplateLayout is recommended way of doing structured logging. Please follow this guide for upgrade steps. log4j2.xml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 <?xml version=\"1.0\" encoding=\"UTF-8\"?> <Configuration> <Appenders> <Console name= \"JsonAppender\" target= \"SYSTEM_OUT\" > <JsonTemplateLayout eventTemplateUri= \"classpath:LambdaJsonLayout.json\" /> </Console> </Appenders> <Loggers> <Logger name= \"JsonLogger\" level= \"INFO\" additivity= \"false\" > <AppenderRef ref= \"JsonAppender\" /> </Logger> <Root level= \"info\" > <AppenderRef ref= \"JsonAppender\" /> </Root> </Loggers> </Configuration> You can also override log level by setting POWERTOOLS_LOG_LEVEL env var. Here is an example using AWS Serverless Application Model (SAM) template.yaml 1 2 3 4 5 6 7 8 9 10 Resources : HelloWorldFunction : Type : AWS::Serverless::Function Properties : ... Runtime : java8 Environment : Variables : POWERTOOLS_LOG_LEVEL : DEBUG POWERTOOLS_SERVICE_NAME : example You can also explicitly set a service name via POWERTOOLS_SERVICE_NAME env var. This sets service key that will be present across all log statements.","title":"Initialization"},{"location":"core/logging/#standard-structured-keys","text":"Your logs will always include the following keys to your structured logging: Key Type Example Description timestamp String \"2020-05-24 18:17:33,774\" Timestamp of actual log statement level String \"INFO\" Logging level coldStart Boolean true ColdStart value. service String \"payment\" Service name defined. \"service_undefined\" will be used if unknown samplingRate int 0.1 Debug logging sampling rate in percentage e.g. 10% in this case message String \"Collecting payment\" Log statement value. Unserializable JSON values will be casted to string functionName String \"example-powertools-HelloWorldFunction-1P1Z6B39FLU73\" functionVersion String \"12\" functionMemorySize String \"128\" functionArn String \"arn:aws:lambda:eu-west-1:012345678910:function:example-powertools-HelloWorldFunction-1P1Z6B39FLU73\" xray_trace_id String \"1-5759e988-bd862e3fe1be46a994272793\" X-Ray Trace ID when Lambda function has enabled Tracing function_request_id String \"899856cb-83d1-40d7-8611-9e78f15f32f4\"\" AWS Request ID from lambda context","title":"Standard structured keys"},{"location":"core/logging/#capturing-context-lambda-info","text":"You can enrich your structured logs with key Lambda context information via logEvent annotation parameter. You can also explicitly log any incoming event using logEvent param. Refer Override default object mapper to customise what is logged. Warning Log event is disabled by default to prevent sensitive info being logged. App.java AppLogEvent.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import org.apache.logging.log4j.LogManager ; import org.apache.logging.log4j.Logger ; import software.amazon.lambda.powertools.logging.LoggingUtils ; import software.amazon.lambda.powertools.logging.Logging ; ... /** * Handler for requests to Lambda function. */ public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { Logger log = LogManager . getLogger (); @Logging public APIGatewayProxyResponseEvent handleRequest ( final APIGatewayProxyRequestEvent input , final Context context ) { ... } } 1 2 3 4 5 6 7 8 9 10 11 12 /** * Handler for requests to Lambda function. */ public class AppLogEvent implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { Logger log = LogManager . getLogger (); @Logging ( logEvent = true ) public APIGatewayProxyResponseEvent handleRequest ( final APIGatewayProxyRequestEvent input , final Context context ) { ... } }","title":"Capturing context Lambda info"},{"location":"core/logging/#customising-fields-in-logs","text":"Utility by default emits timestamp field in the logs in format yyyy-MM-dd'T'HH:mm:ss.SSSZz and in system default timezone. If you need to customize format and timezone, you can do so by configuring log4j2.component.properties and configuring properties as shown in example below: log4j2.component.properties 1 2 log4j.layout.jsonTemplate.timestampFormatPattern = yyyy-MM-dd'T'HH:mm:ss.SSSZz log4j.layout.jsonTemplate.timeZone = Europe/Oslo Utility also provides sample template for Elastic Common Schema(ECS) layout. The field emitted in logs will follow specs from ECS together with field captured by utility as mentioned above . Use LambdaEcsLayout.json as eventTemplateUri when configuring JsonTemplateLayout . log4j2.xml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 <?xml version=\"1.0\" encoding=\"UTF-8\"?> <Configuration> <Appenders> <Console name= \"JsonAppender\" target= \"SYSTEM_OUT\" > <JsonTemplateLayout eventTemplateUri= \"classpath:LambdaEcsLayout.json\" /> </Console> </Appenders> <Loggers> <Logger name= \"JsonLogger\" level= \"INFO\" additivity= \"false\" > <AppenderRef ref= \"JsonAppender\" /> </Logger> <Root level= \"info\" > <AppenderRef ref= \"JsonAppender\" /> </Root> </Loggers> </Configuration>","title":"Customising  fields in logs"},{"location":"core/logging/#setting-a-correlation-id","text":"You can set a Correlation ID using correlationIdPath attribute by passing a JSON Pointer expression . App.java Example Event Example CloudWatch Logs excerpt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 /** * Handler for requests to Lambda function. */ public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { Logger log = LogManager . getLogger (); @Logging ( correlationIdPath = \"/headers/my_request_id_header\" ) public APIGatewayProxyResponseEvent handleRequest ( final APIGatewayProxyRequestEvent input , final Context context ) { ... log . info ( \"Collecting payment\" ) ... } } 1 2 3 4 5 { \"headers\" : { \"my_request_id_header\" : \"correlation_id_value\" } } 1 2 3 4 5 6 7 8 9 10 11 12 { \"level\" : \"INFO\" , \"message\" : \"Collecting payment\" , \"timestamp\" : \"2021-05-03 11:47:12,494+0200\" , \"service\" : \"payment\" , \"coldStart\" : true , \"functionName\" : \"test\" , \"functionMemorySize\" : 128 , \"functionArn\" : \"arn:aws:lambda:eu-west-1:12345678910:function:test\" , \"lambda_request_id\" : \"52fdfc07-2182-154f-163f-5f0f9a621d72\" , \"correlation_id\" : \"correlation_id_value\" } We provide built-in JSON Pointer expression for known event sources, where either a request ID or X-Ray Trace ID are present. App.java Example Event Example CloudWatch Logs excerpt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import software.amazon.lambda.powertools.logging.CorrelationIdPathConstants ; /** * Handler for requests to Lambda function. */ public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { Logger log = LogManager . getLogger (); @Logging ( correlationIdPath = CorrelationIdPathConstants . API_GATEWAY_REST ) public APIGatewayProxyResponseEvent handleRequest ( final APIGatewayProxyRequestEvent input , final Context context ) { ... log . info ( \"Collecting payment\" ) ... } } 1 2 3 4 5 { \"requestContext\" : { \"requestId\" : \"correlation_id_value\" } } 1 2 3 4 5 6 7 8 9 10 11 12 { \"level\" : \"INFO\" , \"message\" : \"Collecting payment\" , \"timestamp\" : \"2021-05-03 11:47:12,494+0200\" , \"service\" : \"payment\" , \"coldStart\" : true , \"functionName\" : \"test\" , \"functionMemorySize\" : 128 , \"functionArn\" : \"arn:aws:lambda:eu-west-1:12345678910:function:test\" , \"lambda_request_id\" : \"52fdfc07-2182-154f-163f-5f0f9a621d72\" , \"correlation_id\" : \"correlation_id_value\" }","title":"Setting a Correlation ID"},{"location":"core/logging/#appending-additional-keys","text":"Custom keys are persisted across warm invocations Always set additional keys as part of your handler to ensure they have the latest value, or explicitly clear them with clearState=true . You can append your own keys to your existing logs via appendKey . App.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 /** * Handler for requests to Lambda function. */ public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { Logger log = LogManager . getLogger (); @Logging ( logEvent = true ) public APIGatewayProxyResponseEvent handleRequest ( final APIGatewayProxyRequestEvent input , final Context context ) { ... LoggingUtils . appendKey ( \"test\" , \"willBeLogged\" ); ... ... Map < String , String > customKeys = new HashMap <> (); customKeys . put ( \"test\" , \"value\" ); customKeys . put ( \"test1\" , \"value1\" ); LoggingUtils . appendKeys ( customKeys ); ... } }","title":"Appending additional keys"},{"location":"core/logging/#removing-additional-keys","text":"You can remove any additional key from entry using LoggingUtils.removeKeys() . App.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 /** * Handler for requests to Lambda function. */ public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { Logger log = LogManager . getLogger (); @Logging ( logEvent = true ) public APIGatewayProxyResponseEvent handleRequest ( final APIGatewayProxyRequestEvent input , final Context context ) { ... LoggingUtils . appendKey ( \"test\" , \"willBeLogged\" ); ... Map < String , String > customKeys = new HashMap <> (); customKeys . put ( \"test1\" , \"value\" ); customKeys . put ( \"test2\" , \"value1\" ); LoggingUtils . appendKeys ( customKeys ); ... LoggingUtils . removeKey ( \"test\" ); LoggingUtils . removeKeys ( \"test1\" , \"test2\" ); ... } }","title":"Removing additional keys"},{"location":"core/logging/#clearing-all-state","text":"Logger is commonly initialized in the global scope. Due to Lambda Execution Context reuse , this means that custom keys can be persisted across invocations. If you want all custom keys to be deleted, you can use clearState=true attribute on @Logging annotation. App.java #1 Request #2 Request 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 /** * Handler for requests to Lambda function. */ public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { Logger log = LogManager . getLogger (); @Logging ( clearState = true ) public APIGatewayProxyResponseEvent handleRequest ( final APIGatewayProxyRequestEvent input , final Context context ) { ... if ( input . getHeaders (). get ( \"someSpecialHeader\" )) { LoggingUtils . appendKey ( \"specialKey\" , \"value\" ); } log . info ( \"Collecting payment\" ); ... } } 1 2 3 4 5 6 7 8 9 10 11 12 { \"level\" : \"INFO\" , \"message\" : \"Collecting payment\" , \"timestamp\" : \"2021-05-03 11:47:12,494+0200\" , \"service\" : \"payment\" , \"coldStart\" : true , \"functionName\" : \"test\" , \"functionMemorySize\" : 128 , \"functionArn\" : \"arn:aws:lambda:eu-west-1:12345678910:function:test\" , \"lambda_request_id\" : \"52fdfc07-2182-154f-163f-5f0f9a621d72\" , \"specialKey\" : \"value\" } 1 2 3 4 5 6 7 8 9 10 11 { \"level\" : \"INFO\" , \"message\" : \"Collecting payment\" , \"timestamp\" : \"2021-05-03 11:47:12,494+0200\" , \"service\" : \"payment\" , \"coldStart\" : true , \"functionName\" : \"test\" , \"functionMemorySize\" : 128 , \"functionArn\" : \"arn:aws:lambda:eu-west-1:12345678910:function:test\" , \"lambda_request_id\" : \"52fdfc07-2182-154f-163f-5f0f9a621d72\" }","title":"Clearing all state"},{"location":"core/logging/#override-default-object-mapper","text":"You can optionally choose to override default object mapper which is used to serialize lambda function events. You might want to supply custom object mapper in order to control how serialisation is done, for example, when you want to log only specific fields from received event due to security. App.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 /** * Handler for requests to Lambda function. */ public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { Logger log = LogManager . getLogger (); static { ObjectMapper objectMapper = new ObjectMapper (); LoggingUtils . defaultObjectMapper ( objectMapper ); } @Logging ( logEvent = true ) public APIGatewayProxyResponseEvent handleRequest ( final APIGatewayProxyRequestEvent input , final Context context ) { ... } }","title":"Override default object mapper"},{"location":"core/logging/#sampling-debug-logs","text":"You can dynamically set a percentage of your logs to DEBUG level via env var POWERTOOLS_LOGGER_SAMPLE_RATE or via samplingRate attribute on annotation. Info Configuration on environment variable is given precedence over sampling rate configuration on annotation, provided it's in valid value range. Sampling via annotation attribute Sampling via environment variable 1 2 3 4 5 6 7 8 9 10 11 12 /** * Handler for requests to Lambda function. */ public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { Logger log = LogManager . getLogger (); @Logging ( samplingRate = 0.5 ) public APIGatewayProxyResponseEvent handleRequest ( final APIGatewayProxyRequestEvent input , final Context context ) { ... } } 1 2 3 4 5 6 7 8 9 Resources : HelloWorldFunction : Type : AWS::Serverless::Function Properties : ... Runtime : java8 Environment : Variables : POWERTOOLS_LOGGER_SAMPLE_RATE : 0.5","title":"Sampling debug logs"},{"location":"core/logging/#upgrade-to-jsontemplatelayout-from-deprecated-lambdajsonlayout-configuration-in-log4j2xml","text":"Prior to version 1.10.0 , only supported way of configuring log4j2.xml was via <LambdaJsonLayout/> . This plugin is deprecated now and will be removed in future version. Switching to JsonTemplateLayout is straight forward. Below examples shows deprecated and new configuration of log4j2.xml . Deprecated configuration of log4j2.xml New configuration of log4j2.xml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 <?xml version=\"1.0\" encoding=\"UTF-8\"?> <Configuration> <Appenders> <Console name= \"JsonAppender\" target= \"SYSTEM_OUT\" > <LambdaJsonLayout compact= \"true\" eventEol= \"true\" /> </Console> </Appenders> <Loggers> <Logger name= \"JsonLogger\" level= \"INFO\" additivity= \"false\" > <AppenderRef ref= \"JsonAppender\" /> </Logger> <Root level= \"info\" > <AppenderRef ref= \"JsonAppender\" /> </Root> </Loggers> </Configuration> 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 <?xml version=\"1.0\" encoding=\"UTF-8\"?> <Configuration> <Appenders> <Console name= \"JsonAppender\" target= \"SYSTEM_OUT\" > <JsonTemplateLayout eventTemplateUri= \"classpath:LambdaJsonLayout.json\" /> </Console> </Appenders> <Loggers> <Logger name= \"JsonLogger\" level= \"INFO\" additivity= \"false\" > <AppenderRef ref= \"JsonAppender\" /> </Logger> <Root level= \"info\" > <AppenderRef ref= \"JsonAppender\" /> </Root> </Loggers> </Configuration>","title":"Upgrade to JsonTemplateLayout from deprecated LambdaJsonLayout configuration in log4j2.xml"},{"location":"core/metrics/","text":"Metrics creates custom metrics asynchronously by logging metrics to standard output following Amazon CloudWatch Embedded Metric Format (EMF). These metrics can be visualized through Amazon CloudWatch Console . Key features Aggregate up to 100 metrics using a single CloudWatch EMF object (large JSON blob). Validate against common metric definitions mistakes (metric unit, values, max dimensions, max metrics, etc). Metrics are created asynchronously by the CloudWatch service, no custom stacks needed. Context manager to create a one off metric with a different dimension. Terminologies \u00b6 If you're new to Amazon CloudWatch, there are two terminologies you must be aware of before using this utility: Namespace . It's the highest level container that will group multiple metrics from multiple services for a given application, for example ServerlessEcommerce . Dimensions . Metrics metadata in key-value format. They help you slice and dice metrics visualization, for example ColdStart metric by Payment service . Metric terminology, visually explained Getting started \u00b6 Metric has two global settings that will be used across all metrics emitted: Setting Description Environment variable Constructor parameter Metric namespace Logical container where all metrics will be placed e.g. ServerlessAirline POWERTOOLS_METRICS_NAMESPACE namespace Service Optionally, sets service metric dimension across all metrics e.g. payment POWERTOOLS_SERVICE_NAME service Use your application or main service as the metric namespace to easily group all metrics template.yaml MetricsEnabledHandler.java 1 2 3 4 5 6 7 8 9 10 Resources : HelloWorldFunction : Type : AWS::Serverless::Function Properties : ... Runtime : java8 Environment : Variables : POWERTOOLS_SERVICE_NAME : payment POWERTOOLS_METRICS_NAMESPACE : ServerlessAirline 1 2 3 4 5 6 7 8 9 10 11 12 import software.amazon.lambda.powertools.metrics.Metrics ; public class MetricsEnabledHandler implements RequestHandler < Object , Object > { MetricsLogger metricsLogger = MetricsUtils . metricsLogger (); @Override @Metrics ( namespace = \"ExampleApplication\" , service = \"booking\" ) public Object handleRequest ( Object input , Context context ) { ... } } You can initialize Metrics anywhere in your code as many times as you need - It'll keep track of your aggregate metrics in memory. Creating metrics \u00b6 You can create metrics using putMetric , and manually create dimensions for all your aggregate metrics using putDimensions . MetricsEnabledHandler.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import software.amazon.lambda.powertools.metrics.Metrics ; import software.amazon.cloudwatchlogs.emf.logger.MetricsLogger ; public class MetricsEnabledHandler implements RequestHandler < Object , Object > { MetricsLogger metricsLogger = MetricsUtils . metricsLogger (); @Override @Metrics ( namespace = \"ExampleApplication\" , service = \"booking\" ) public Object handleRequest ( Object input , Context context ) { metricsLogger . putDimensions ( DimensionSet . of ( \"environment\" , \"prod\" )); metricsLogger . putMetric ( \"SuccessfulBooking\" , 1 , Unit . COUNT ); ... } } The Unit enum facilitate finding a supported metric unit by CloudWatch. Metrics overflow CloudWatch EMF supports a max of 100 metrics. Metrics utility will flush all metrics when adding the 100th metric while subsequent metrics will be aggregated into a new EMF object, for your convenience. Flushing metrics \u00b6 The @Metrics annotation validates , serializes , and flushes all your metrics. During metrics validation, if no metrics are provided no exception will be raised. If metrics are provided, and any of the following criteria are not met, ValidationException exception will be raised. Metric validation Maximum of 9 dimensions If you want to ensure that at least one metric is emitted, you can pass raiseOnEmptyMetrics = true to the @Metrics annotation: MetricsRaiseOnEmpty.java 1 2 3 4 5 6 7 8 9 10 import software.amazon.lambda.powertools.metrics.Metrics ; public class MetricsRaiseOnEmpty implements RequestHandler < Object , Object > { @Override @Metrics ( raiseOnEmptyMetrics = true ) public Object handleRequest ( Object input , Context context ) { ... } } Capturing cold start metric \u00b6 You can capture cold start metrics automatically with @Metrics via the captureColdStart variable. MetricsColdStart.java 1 2 3 4 5 6 7 8 9 10 import software.amazon.lambda.powertools.metrics.Metrics ; public class MetricsColdStart implements RequestHandler < Object , Object > { @Override @Metrics ( captureColdStart = true ) public Object handleRequest ( Object input , Context context ) { ... } } If it's a cold start invocation, this feature will: Create a separate EMF blob solely containing a metric named ColdStart Add FunctionName and Service dimensions This has the advantage of keeping cold start metric separate from your application metrics. Advanced \u00b6 Adding metadata \u00b6 You can use putMetadata for advanced use cases, where you want to metadata as part of the serialized metrics object. Info This will not be available during metrics visualization, use dimensions for this purpose. App.java 1 2 3 4 5 6 7 8 9 10 11 12 13 import software.amazon.lambda.powertools.metrics.Metrics ; import software.amazon.cloudwatchlogs.emf.logger.MetricsLogger ; public class App implements RequestHandler < Object , Object > { @Override @Metrics ( namespace = \"ServerlessAirline\" , service = \"payment\" ) public Object handleRequest ( Object input , Context context ) { metricsLogger (). putMetric ( \"CustomMetric1\" , 1 , Unit . COUNT ); metricsLogger (). putMetadata ( \"booking_id\" , \"1234567890\" ); ... } } This will be available in CloudWatch Logs to ease operations on high cardinal data. Overriding default dimension set \u00b6 By default, all metrics emitted via module captures Service as one of the default dimension. This is either specified via POWERTOOLS_SERVICE_NAME environment variable or via service attribute on Metrics annotation. If you wish to override the default Dimension, it can be done via MetricsUtils . defaultDimensions () . App.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import software.amazon.lambda.powertools.metrics.Metrics ; import static software.amazon.lambda.powertools.metrics.MetricsUtils ; public class App implements RequestHandler < Object , Object > { MetricsLogger metricsLogger = MetricsUtils . metricsLogger (); static { MetricsUtils . defaultDimensions ( DimensionSet . of ( \"CustomDimension\" , \"booking\" )); } @Override @Metrics ( namespace = \"ExampleApplication\" , service = \"booking\" ) public Object handleRequest ( Object input , Context context ) { ... MetricsUtils . withSingleMetric ( \"Metric2\" , 1 , Unit . COUNT , log -> {}); } } Creating a metric with a different dimension \u00b6 CloudWatch EMF uses the same dimensions across all your metrics. Use withSingleMetric if you have a metric that should have different dimensions. Info Generally, this would be an edge case since you pay for unique metric . Keep the following formula in mind: unique metric = (metric_name + dimension_name + dimension_value) App.java 1 2 3 4 5 6 7 8 9 10 11 import static software.amazon.lambda.powertools.metrics.MetricsUtils.withSingleMetric ; public class App implements RequestHandler < Object , Object > { @Override public Object handleRequest ( Object input , Context context ) { withSingleMetric ( \"CustomMetrics2\" , 1 , Unit . COUNT , \"Another\" , ( metric ) -> { metric . setDimensions ( DimensionSet . of ( \"AnotherService\" , \"CustomService\" )); }); } }","title":"Metrics"},{"location":"core/metrics/#terminologies","text":"If you're new to Amazon CloudWatch, there are two terminologies you must be aware of before using this utility: Namespace . It's the highest level container that will group multiple metrics from multiple services for a given application, for example ServerlessEcommerce . Dimensions . Metrics metadata in key-value format. They help you slice and dice metrics visualization, for example ColdStart metric by Payment service . Metric terminology, visually explained","title":"Terminologies"},{"location":"core/metrics/#getting-started","text":"Metric has two global settings that will be used across all metrics emitted: Setting Description Environment variable Constructor parameter Metric namespace Logical container where all metrics will be placed e.g. ServerlessAirline POWERTOOLS_METRICS_NAMESPACE namespace Service Optionally, sets service metric dimension across all metrics e.g. payment POWERTOOLS_SERVICE_NAME service Use your application or main service as the metric namespace to easily group all metrics template.yaml MetricsEnabledHandler.java 1 2 3 4 5 6 7 8 9 10 Resources : HelloWorldFunction : Type : AWS::Serverless::Function Properties : ... Runtime : java8 Environment : Variables : POWERTOOLS_SERVICE_NAME : payment POWERTOOLS_METRICS_NAMESPACE : ServerlessAirline 1 2 3 4 5 6 7 8 9 10 11 12 import software.amazon.lambda.powertools.metrics.Metrics ; public class MetricsEnabledHandler implements RequestHandler < Object , Object > { MetricsLogger metricsLogger = MetricsUtils . metricsLogger (); @Override @Metrics ( namespace = \"ExampleApplication\" , service = \"booking\" ) public Object handleRequest ( Object input , Context context ) { ... } } You can initialize Metrics anywhere in your code as many times as you need - It'll keep track of your aggregate metrics in memory.","title":"Getting started"},{"location":"core/metrics/#creating-metrics","text":"You can create metrics using putMetric , and manually create dimensions for all your aggregate metrics using putDimensions . MetricsEnabledHandler.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import software.amazon.lambda.powertools.metrics.Metrics ; import software.amazon.cloudwatchlogs.emf.logger.MetricsLogger ; public class MetricsEnabledHandler implements RequestHandler < Object , Object > { MetricsLogger metricsLogger = MetricsUtils . metricsLogger (); @Override @Metrics ( namespace = \"ExampleApplication\" , service = \"booking\" ) public Object handleRequest ( Object input , Context context ) { metricsLogger . putDimensions ( DimensionSet . of ( \"environment\" , \"prod\" )); metricsLogger . putMetric ( \"SuccessfulBooking\" , 1 , Unit . COUNT ); ... } } The Unit enum facilitate finding a supported metric unit by CloudWatch. Metrics overflow CloudWatch EMF supports a max of 100 metrics. Metrics utility will flush all metrics when adding the 100th metric while subsequent metrics will be aggregated into a new EMF object, for your convenience.","title":"Creating metrics"},{"location":"core/metrics/#flushing-metrics","text":"The @Metrics annotation validates , serializes , and flushes all your metrics. During metrics validation, if no metrics are provided no exception will be raised. If metrics are provided, and any of the following criteria are not met, ValidationException exception will be raised. Metric validation Maximum of 9 dimensions If you want to ensure that at least one metric is emitted, you can pass raiseOnEmptyMetrics = true to the @Metrics annotation: MetricsRaiseOnEmpty.java 1 2 3 4 5 6 7 8 9 10 import software.amazon.lambda.powertools.metrics.Metrics ; public class MetricsRaiseOnEmpty implements RequestHandler < Object , Object > { @Override @Metrics ( raiseOnEmptyMetrics = true ) public Object handleRequest ( Object input , Context context ) { ... } }","title":"Flushing metrics"},{"location":"core/metrics/#capturing-cold-start-metric","text":"You can capture cold start metrics automatically with @Metrics via the captureColdStart variable. MetricsColdStart.java 1 2 3 4 5 6 7 8 9 10 import software.amazon.lambda.powertools.metrics.Metrics ; public class MetricsColdStart implements RequestHandler < Object , Object > { @Override @Metrics ( captureColdStart = true ) public Object handleRequest ( Object input , Context context ) { ... } } If it's a cold start invocation, this feature will: Create a separate EMF blob solely containing a metric named ColdStart Add FunctionName and Service dimensions This has the advantage of keeping cold start metric separate from your application metrics.","title":"Capturing cold start metric"},{"location":"core/metrics/#advanced","text":"","title":"Advanced"},{"location":"core/metrics/#adding-metadata","text":"You can use putMetadata for advanced use cases, where you want to metadata as part of the serialized metrics object. Info This will not be available during metrics visualization, use dimensions for this purpose. App.java 1 2 3 4 5 6 7 8 9 10 11 12 13 import software.amazon.lambda.powertools.metrics.Metrics ; import software.amazon.cloudwatchlogs.emf.logger.MetricsLogger ; public class App implements RequestHandler < Object , Object > { @Override @Metrics ( namespace = \"ServerlessAirline\" , service = \"payment\" ) public Object handleRequest ( Object input , Context context ) { metricsLogger (). putMetric ( \"CustomMetric1\" , 1 , Unit . COUNT ); metricsLogger (). putMetadata ( \"booking_id\" , \"1234567890\" ); ... } } This will be available in CloudWatch Logs to ease operations on high cardinal data.","title":"Adding metadata"},{"location":"core/metrics/#overriding-default-dimension-set","text":"By default, all metrics emitted via module captures Service as one of the default dimension. This is either specified via POWERTOOLS_SERVICE_NAME environment variable or via service attribute on Metrics annotation. If you wish to override the default Dimension, it can be done via MetricsUtils . defaultDimensions () . App.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import software.amazon.lambda.powertools.metrics.Metrics ; import static software.amazon.lambda.powertools.metrics.MetricsUtils ; public class App implements RequestHandler < Object , Object > { MetricsLogger metricsLogger = MetricsUtils . metricsLogger (); static { MetricsUtils . defaultDimensions ( DimensionSet . of ( \"CustomDimension\" , \"booking\" )); } @Override @Metrics ( namespace = \"ExampleApplication\" , service = \"booking\" ) public Object handleRequest ( Object input , Context context ) { ... MetricsUtils . withSingleMetric ( \"Metric2\" , 1 , Unit . COUNT , log -> {}); } }","title":"Overriding default dimension set"},{"location":"core/metrics/#creating-a-metric-with-a-different-dimension","text":"CloudWatch EMF uses the same dimensions across all your metrics. Use withSingleMetric if you have a metric that should have different dimensions. Info Generally, this would be an edge case since you pay for unique metric . Keep the following formula in mind: unique metric = (metric_name + dimension_name + dimension_value) App.java 1 2 3 4 5 6 7 8 9 10 11 import static software.amazon.lambda.powertools.metrics.MetricsUtils.withSingleMetric ; public class App implements RequestHandler < Object , Object > { @Override public Object handleRequest ( Object input , Context context ) { withSingleMetric ( \"CustomMetrics2\" , 1 , Unit . COUNT , \"Another\" , ( metric ) -> { metric . setDimensions ( DimensionSet . of ( \"AnotherService\" , \"CustomService\" )); }); } }","title":"Creating a metric with a different dimension"},{"location":"core/tracing/","text":"Powertools tracing is an opinionated thin wrapper for AWS X-Ray Java SDK a provides functionality to reduce the overhead of performing common tracing tasks. Key Features Capture cold start as annotation, and responses as well as full exceptions as metadata Helper methods to improve the developer experience of creating new X-Ray subsegments. Better developer experience when developing with multiple threads. Auto patch supported modules by AWS X-Ray Initialization Before your use this utility, your AWS Lambda function must have permissions to send traces to AWS X-Ray. Example using AWS Serverless Application Model (SAM) template.yaml 1 2 3 4 5 6 7 8 9 10 11 Resources : HelloWorldFunction : Type : AWS::Serverless::Function Properties : ... Runtime : java8 Tracing : Active Environment : Variables : POWERTOOLS_SERVICE_NAME : example The Powertools service name is used as the X-Ray namespace. This can be set using the environment variable POWERTOOLS_SERVICE_NAME Lambda handler \u00b6 To enable Powertools tracing to your function add the @Tracing annotation to your handleRequest method or on any method will capture the method as a separate subsegment automatically. You can optionally choose to customize segment name that appears in traces. Tracing annotation Custom Segment names 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Tracing public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { businessLogic1 (); businessLogic2 (); } @Tracing public void businessLogic1 (){ } @Tracing public void businessLogic2 (){ } } 1 2 3 4 5 6 public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Tracing ( segmentName = \"yourCustomName\" ) public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { ... } When using this @Tracing annotation, Utility performs these additional tasks to ease operations: Creates a ColdStart annotation to easily filter traces that have had an initialization overhead. Creates a Service annotation if service parameter or POWERTOOLS_SERVICE_NAME is set. Captures any response, or full exceptions generated by the handler, and include as tracing metadata. By default, this annotation will automatically record method responses and exceptions. You can change the default behavior by setting the environment variables POWERTOOLS_TRACER_CAPTURE_RESPONSE and POWERTOOLS_TRACER_CAPTURE_ERROR as needed. Optionally, you can override behavior by different supported captureMode to record response, exception or both. Returning sensitive information from your Lambda handler or functions, where Tracing is used? You can disable annotation from capturing their responses and exception as tracing metadata with captureMode=DISABLED or globally by setting environment variables POWERTOOLS_TRACER_CAPTURE_RESPONSE and POWERTOOLS_TRACER_CAPTURE_ERROR to false Disable on annotation Disable Globally 1 2 3 4 5 6 public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Tracing ( captureMode = CaptureMode . DISABLED ) public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { ... } 1 2 3 4 5 6 7 8 9 10 11 12 Resources : HelloWorldFunction : Type : AWS::Serverless::Function Properties : ... Runtime : java8 Tracing : Active Environment : Variables : POWERTOOLS_TRACER_CAPTURE_RESPONSE : false POWERTOOLS_TRACER_CAPTURE_ERROR : false Annotations & Metadata \u00b6 Annotations are key-values associated with traces and indexed by AWS X-Ray. You can use them to filter traces and to create Trace Groups to slice and dice your transactions. Metadata are key-values also associated with traces but not indexed by AWS X-Ray. You can use them to add additional context for an operation using any native object. Annotations Metadata You can add annotations using putAnnotation() method from TracingUtils 1 2 3 4 5 6 7 8 9 10 import software.amazon.lambda.powertools.tracing.Tracing ; import software.amazon.lambda.powertools.tracing.TracingUtils ; public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Tracing public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { TracingUtils . putAnnotation ( \"annotation\" , \"value\" ); } } You can add metadata using putMetadata() method from TracingUtils 1 2 3 4 5 6 7 8 9 10 import software.amazon.lambda.powertools.tracing.Tracing ; import software.amazon.lambda.powertools.tracing.TracingUtils ; public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Tracing public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { TracingUtils . putMetadata ( \"content\" , \"value\" ); } } Override default object mapper \u00b6 You can optionally choose to override default object mapper which is used to serialize method response and exceptions when enabled. You might want to supply custom object mapper in order to control how serialisation is done, for example, when you want to log only specific fields from received event due to security. App.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import software.amazon.lambda.powertools.tracing.Tracing ; import software.amazon.lambda.powertools.tracing.TracingUtils ; import static software.amazon.lambda.powertools.tracing.CaptureMode.RESPONSE ; /** * Handler for requests to Lambda function. */ public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { static { ObjectMapper objectMapper = new ObjectMapper (); SimpleModule simpleModule = new SimpleModule (); objectMapper . registerModule ( simpleModule ); TracingUtils . defaultObjectMapper ( objectMapper ); } @Tracing ( captureMode = RESPONSE ) public APIGatewayProxyResponseEvent handleRequest ( final APIGatewayProxyRequestEvent input , final Context context ) { ... } } Utilities \u00b6 Tracing modules comes with certain utility method when you don't want to use annotation for capturing a code block under a subsegment, or you are doing multithreaded programming. Refer examples below. Functional Api Multi Threaded Programming 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import software.amazon.lambda.powertools.tracing.Tracing ; import software.amazon.lambda.powertools.tracing.TracingUtils ; public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { TracingUtils . withSubsegment ( \"loggingResponse\" , subsegment -> { // Some business logic }); TracingUtils . withSubsegment ( \"localNamespace\" , \"loggingResponse\" , subsegment -> { // Some business logic }); } } 1 2 3 4 5 6 7 8 9 10 11 12 13 import static software.amazon.lambda.powertools.tracing.TracingUtils.withEntitySubsegment ; public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { // Extract existing trace data Entity traceEntity = AWSXRay . getTraceEntity (); Thread anotherThread = new Thread (() -> withEntitySubsegment ( \"inlineLog\" , traceEntity , subsegment -> { // Business logic in separate thread })); } } Instrumenting SDK clients and HTTP calls \u00b6 User should make sure to instrument the SDK clients explicitly based on the function dependency. Refer details on how to instrument SDK client with Xray and outgoing http calls .","title":"Tracing"},{"location":"core/tracing/#lambda-handler","text":"To enable Powertools tracing to your function add the @Tracing annotation to your handleRequest method or on any method will capture the method as a separate subsegment automatically. You can optionally choose to customize segment name that appears in traces. Tracing annotation Custom Segment names 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Tracing public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { businessLogic1 (); businessLogic2 (); } @Tracing public void businessLogic1 (){ } @Tracing public void businessLogic2 (){ } } 1 2 3 4 5 6 public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Tracing ( segmentName = \"yourCustomName\" ) public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { ... } When using this @Tracing annotation, Utility performs these additional tasks to ease operations: Creates a ColdStart annotation to easily filter traces that have had an initialization overhead. Creates a Service annotation if service parameter or POWERTOOLS_SERVICE_NAME is set. Captures any response, or full exceptions generated by the handler, and include as tracing metadata. By default, this annotation will automatically record method responses and exceptions. You can change the default behavior by setting the environment variables POWERTOOLS_TRACER_CAPTURE_RESPONSE and POWERTOOLS_TRACER_CAPTURE_ERROR as needed. Optionally, you can override behavior by different supported captureMode to record response, exception or both. Returning sensitive information from your Lambda handler or functions, where Tracing is used? You can disable annotation from capturing their responses and exception as tracing metadata with captureMode=DISABLED or globally by setting environment variables POWERTOOLS_TRACER_CAPTURE_RESPONSE and POWERTOOLS_TRACER_CAPTURE_ERROR to false Disable on annotation Disable Globally 1 2 3 4 5 6 public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Tracing ( captureMode = CaptureMode . DISABLED ) public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { ... } 1 2 3 4 5 6 7 8 9 10 11 12 Resources : HelloWorldFunction : Type : AWS::Serverless::Function Properties : ... Runtime : java8 Tracing : Active Environment : Variables : POWERTOOLS_TRACER_CAPTURE_RESPONSE : false POWERTOOLS_TRACER_CAPTURE_ERROR : false","title":"Lambda handler"},{"location":"core/tracing/#annotations-metadata","text":"Annotations are key-values associated with traces and indexed by AWS X-Ray. You can use them to filter traces and to create Trace Groups to slice and dice your transactions. Metadata are key-values also associated with traces but not indexed by AWS X-Ray. You can use them to add additional context for an operation using any native object. Annotations Metadata You can add annotations using putAnnotation() method from TracingUtils 1 2 3 4 5 6 7 8 9 10 import software.amazon.lambda.powertools.tracing.Tracing ; import software.amazon.lambda.powertools.tracing.TracingUtils ; public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Tracing public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { TracingUtils . putAnnotation ( \"annotation\" , \"value\" ); } } You can add metadata using putMetadata() method from TracingUtils 1 2 3 4 5 6 7 8 9 10 import software.amazon.lambda.powertools.tracing.Tracing ; import software.amazon.lambda.powertools.tracing.TracingUtils ; public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Tracing public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { TracingUtils . putMetadata ( \"content\" , \"value\" ); } }","title":"Annotations &amp; Metadata"},{"location":"core/tracing/#override-default-object-mapper","text":"You can optionally choose to override default object mapper which is used to serialize method response and exceptions when enabled. You might want to supply custom object mapper in order to control how serialisation is done, for example, when you want to log only specific fields from received event due to security. App.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import software.amazon.lambda.powertools.tracing.Tracing ; import software.amazon.lambda.powertools.tracing.TracingUtils ; import static software.amazon.lambda.powertools.tracing.CaptureMode.RESPONSE ; /** * Handler for requests to Lambda function. */ public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { static { ObjectMapper objectMapper = new ObjectMapper (); SimpleModule simpleModule = new SimpleModule (); objectMapper . registerModule ( simpleModule ); TracingUtils . defaultObjectMapper ( objectMapper ); } @Tracing ( captureMode = RESPONSE ) public APIGatewayProxyResponseEvent handleRequest ( final APIGatewayProxyRequestEvent input , final Context context ) { ... } }","title":"Override default object mapper"},{"location":"core/tracing/#utilities","text":"Tracing modules comes with certain utility method when you don't want to use annotation for capturing a code block under a subsegment, or you are doing multithreaded programming. Refer examples below. Functional Api Multi Threaded Programming 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import software.amazon.lambda.powertools.tracing.Tracing ; import software.amazon.lambda.powertools.tracing.TracingUtils ; public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { TracingUtils . withSubsegment ( \"loggingResponse\" , subsegment -> { // Some business logic }); TracingUtils . withSubsegment ( \"localNamespace\" , \"loggingResponse\" , subsegment -> { // Some business logic }); } } 1 2 3 4 5 6 7 8 9 10 11 12 13 import static software.amazon.lambda.powertools.tracing.TracingUtils.withEntitySubsegment ; public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { // Extract existing trace data Entity traceEntity = AWSXRay . getTraceEntity (); Thread anotherThread = new Thread (() -> withEntitySubsegment ( \"inlineLog\" , traceEntity , subsegment -> { // Business logic in separate thread })); } }","title":"Utilities"},{"location":"core/tracing/#instrumenting-sdk-clients-and-http-calls","text":"User should make sure to instrument the SDK clients explicitly based on the function dependency. Refer details on how to instrument SDK client with Xray and outgoing http calls .","title":"Instrumenting SDK clients and HTTP calls"},{"location":"utilities/batch/","text":"The SQS batch processing utility provides a way to handle partial failures when processing batches of messages from SQS. Key Features Prevent successfully processed messages from being returned to SQS A simple interface for individually processing messages from a batch Background When using SQS as a Lambda event source mapping, Lambda functions can be triggered with a batch of messages from SQS. If your function fails to process any message from the batch, the entire batch returns to your SQS queue, and your Lambda function will be triggered with the same batch again. With this utility, messages within a batch will be handled individually - only messages that were not successfully processed are returned to the queue. Warning While this utility lowers the chance of processing messages more than once, it is not guaranteed. We recommend implementing processing logic in an idempotent manner wherever possible. More details on how Lambda works with SQS can be found in the AWS documentation Install \u00b6 To install this utility, add the following dependency to your project. Maven Gradle 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 <dependencies> ... <dependency> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-sqs </artifactId> <version> 1.10.3 </version> </dependency> ... </dependencies> <!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --> <build> <plugins> ... <plugin> <groupId> org.codehaus.mojo </groupId> <artifactId> aspectj-maven-plugin </artifactId> <version> 1.14.0 </version> <configuration> <source> 1.8 </source> <target> 1.8 </target> <complianceLevel> 1.8 </complianceLevel> <aspectLibraries> <aspectLibrary> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-sqs </artifactId> </aspectLibrary> </aspectLibraries> </configuration> <executions> <execution> <goals> <goal> compile </goal> </goals> </execution> </executions> </plugin> ... </plugins> </build> 1 2 3 4 5 6 7 8 9 10 11 12 13 plugins { id 'java' id 'io.freefair.aspectj.post-compile-weaving' version '6.3.0' } repositories { mavenCentral () } dependencies { ... aspect 'software.amazon.lambda:powertools-sqs:1.10.3' } IAM Permissions \u00b6 This utility requires additional permissions to work as expected. Lambda functions using this utility require the sqs:DeleteMessageBatch permission. If you are also using nonRetryableExceptions attribute, utility will need additional permission of sqs:GetQueueAttributes on source SQS. It also needs sqs:SendMessage and sqs:SendMessageBatch on configured dead letter queue. If source or dead letter queue is configured to use encryption at rest using AWS Key Management Service (KMS) , function will need additional permissions of kms:GenerateDataKey and kms:Decrypt on the KMS key being used for encryption. Refer docs for more details. Refer example project for policy details example. Processing messages from SQS \u00b6 You can use either SqsBatch annotation , or SqsUtils Utility API as a fluent API. Both have nearly the same behaviour when it comes to processing messages from the batch: Entire batch has been successfully processed , where your Lambda handler returned successfully, we will let SQS delete the batch to optimize your cost Entire Batch has been partially processed successfully , where exceptions were raised within your SqsMessageHandler interface implementation, we will: 1) Delete successfully processed messages from the queue by directly calling sqs:DeleteMessageBatch 2) if, non retryable exceptions occur, messages resulting in configured exceptions during processing will be immediately moved to the dead letter queue associated to the source SQS queue or deleted from the source SQS queue if deleteNonRetryableMessageFromQueue is set to true . 3) Raise SQSBatchProcessingException to ensure failed messages return to your SQS queue The only difference is that SqsUtils Utility API will give you access to return from the processed messages if you need. Exception SQSBatchProcessingException thrown from the utility will have access to both successful and failed messaged along with failure exceptions. Functional Interface SqsMessageHandler \u00b6 Both annotation and SqsUtils Utility API requires an implementation of functional interface SqsMessageHandler . This implementation is responsible for processing each individual message from the batch, and to raise an exception if unable to process any of the messages sent. Any non-exception/successful return from your record handler function will instruct utility to queue up each individual message for deletion. SqsBatch annotation \u00b6 When using this annotation, you need provide a class implementation of SqsMessageHandler that will process individual messages from the batch - It should raise an exception if it is unable to process the record. All records in the batch will be passed to this handler for processing, even if exceptions are thrown - Here's the behaviour after completing the batch: Any successfully processed messages , we will delete them from the queue via sqs:DeleteMessageBatch . if, nonRetryableExceptions attribute is used , messages resulting in configured exceptions during processing will be immediately moved to the dead letter queue associated to the source SQS queue or deleted from the source SQS queue if deleteNonRetryableMessageFromQueue is set to true . Any unprocessed messages detected , we will raise SQSBatchProcessingException to ensure failed messages return to your SQS queue. Warning You will not have access to the processed messages within the Lambda Handler - all processing logic will and should be performed by the implemented SqsMessageHandler # process () function. AppSqsEvent.java AppSqsEventWithNonRetryableExceptions.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 import software.amazon.lambda.powertools.sqs.SqsBatch ; import software.amazon.lambda.powertools.sqs.SqsMessageHandler ; import software.amazon.lambda.powertools.sqs.SqsUtils ; public class AppSqsEvent implements RequestHandler < SQSEvent , String > { @Override @SqsBatch ( SampleMessageHandler . class ) public String handleRequest ( SQSEvent input , Context context ) { return \"{\\\"statusCode\\\": 200}\" ; } public class SampleMessageHandler implements SqsMessageHandler < Object > { @Override public String process ( SQSMessage message ) { // This will be called for each individual message from a batch // It should raise an exception if the message was not processed successfully String returnVal = doSomething ( message . getBody ()); return returnVal ; } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 import software.amazon.lambda.powertools.sqs.SqsBatch ; import software.amazon.lambda.powertools.sqs.SqsMessageHandler ; import software.amazon.lambda.powertools.sqs.SqsUtils ; public class AppSqsEvent implements RequestHandler < SQSEvent , String > { @Override @SqsBatch ( value = SampleMessageHandler . class , nonRetryableExceptions = { IllegalArgumentException . class }) public String handleRequest ( SQSEvent input , Context context ) { return \"{\\\"statusCode\\\": 200}\" ; } public class SampleMessageHandler implements SqsMessageHandler < Object > { @Override public String process ( SQSMessage message ) { // This will be called for each individual message from a batch // It should raise an exception if the message was not processed successfully String returnVal = doSomething ( message . getBody ()); if ( /**Business validation failure**/ ) { throw new IllegalArgumentException ( \"Failed business validation. No point of retrying. Move me to DLQ.\" + message . getMessageId ()); } return returnVal ; } } } SqsUtils Utility API \u00b6 If you require access to the result of processed messages, you can use this utility. The result from calling SqsUtils # batchProcessor () on the context manager will be a list of all the return values from your SqsMessageHandler # process () function. You can also use the utility in functional way by providing inline implementation of functional interface SqsMessageHandler # process () Utility API Function implementation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public class AppSqsEvent implements RequestHandler < SQSEvent , List < String >> { @Override public List < String > handleRequest ( SQSEvent input , Context context ) { List < String > returnValues = SqsUtils . batchProcessor ( input , SampleMessageHandler . class ); return returnValues ; } public class SampleMessageHandler implements SqsMessageHandler < String > { @Override public String process ( SQSMessage message ) { // This will be called for each individual message from a batch // It should raise an exception if the message was not processed successfully String returnVal = doSomething ( message . getBody ()); return returnVal ; } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class AppSqsEvent implements RequestHandler < SQSEvent , List < String >> { @Override public List < String > handleRequest ( SQSEvent input , Context context ) { List < String > returnValues = SqsUtils . batchProcessor ( input , ( message ) -> { // This will be called for each individual message from a batch // It should raise an exception if the message was not processed successfully String returnVal = doSomething ( message . getBody ()); return returnVal ; }); return returnValues ; } } Passing custom SqsClient \u00b6 If you need to pass custom SqsClient such as region to the SDK, you can pass your own SqsClient to be used by utility either for SqsBatch annotation , or SqsUtils Utility API . App.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 public class AppSqsEvent implements RequestHandler < SQSEvent , List < String >> { static { SqsUtils . overrideSqsClient ( SqsClient . builder () . build ()); } @Override public List < String > handleRequest ( SQSEvent input , Context context ) { List < String > returnValues = SqsUtils . batchProcessor ( input , SampleMessageHandler . class ); return returnValues ; } public class SampleMessageHandler implements SqsMessageHandler < String > { @Override public String process ( SQSMessage message ) { // This will be called for each individual message from a batch // It should raise an exception if the message was not processed successfully String returnVal = doSomething ( message . getBody ()); return returnVal ; } } } Suppressing exceptions \u00b6 If you want to disable the default behavior where SQSBatchProcessingException is raised if there are any exception, you can pass the suppressException boolean argument. Within SqsBatch annotation Within SqsUtils Utility API 1 2 3 4 5 @Override @SqsBatch ( value = SampleMessageHandler . class , suppressException = true ) public String handleRequest ( SQSEvent input , Context context ) { return \"{\\\"statusCode\\\": 200}\" ; } 1 2 3 4 5 6 @Override public List < String > handleRequest ( SQSEvent input , Context context ) { List < String > returnValues = SqsUtils . batchProcessor ( input , true , SampleMessageHandler . class ); return returnValues ; } Move non retryable messages to a dead letter queue \u00b6 If you want certain exceptions to be treated as permanent failures during batch processing, i.e. exceptions where the result of retrying will always be a failure and want these can be immediately moved to the dead letter queue associated to the source SQS queue, you can use SqsBatch#nonRetryableExceptions() to configure such exceptions. If you want such messages to be deleted instead, set SqsBatch#deleteNonRetryableMessageFromQueue() to true . By default, its value is false . Same capability is also provided by SqsUtils Utility API . Info Make sure the lambda function has required permissions needed by utility. Refer this section . SqsBatch annotation SqsBatch API 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 import software.amazon.lambda.powertools.sqs.SqsBatch ; import software.amazon.lambda.powertools.sqs.SqsMessageHandler ; import software.amazon.lambda.powertools.sqs.SqsUtils ; public class AppSqsEvent implements RequestHandler < SQSEvent , String > { @Override @SqsBatch ( value = SampleMessageHandler . class , nonRetryableExceptions = { IllegalArgumentException . class }) public String handleRequest ( SQSEvent input , Context context ) { return \"{\\\"statusCode\\\": 200}\" ; } public class SampleMessageHandler implements SqsMessageHandler < Object > { @Override public String process ( SQSMessage message ) { // This will be called for each individual message from a batch // It should raise an exception if the message was not processed successfully String returnVal = doSomething ( message . getBody ()); if ( /**Business validation failure**/ ) { throw new IllegalArgumentException ( \"Failed business validation. No point of retrying. Move me to DLQ.\" + message . getMessageId ()); } return returnVal ; } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 import software.amazon.lambda.powertools.sqs.SqsBatch ; import software.amazon.lambda.powertools.sqs.SqsMessageHandler ; import software.amazon.lambda.powertools.sqs.SqsUtils ; public class AppSqsEvent implements RequestHandler < SQSEvent , String > { @Override public String handleRequest ( SQSEvent input , Context context ) { SqsUtils . batchProcessor ( input , BatchProcessor . class , IllegalArgumentException . class ); return \"{\\\"statusCode\\\": 200}\" ; } public class SampleMessageHandler implements SqsMessageHandler < Object > { @Override public String process ( SQSMessage message ) { // This will be called for each individual message from a batch // It should raise an exception if the message was not processed successfully String returnVal = doSomething ( message . getBody ()); if ( /**Business validation failure**/ ) { throw new IllegalArgumentException ( \"Failed business validation. No point of retrying. Move me to DLQ.\" + message . getMessageId ()); } return returnVal ; } } }","title":"SQS Batch Processing"},{"location":"utilities/batch/#install","text":"To install this utility, add the following dependency to your project. Maven Gradle 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 <dependencies> ... <dependency> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-sqs </artifactId> <version> 1.10.3 </version> </dependency> ... </dependencies> <!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --> <build> <plugins> ... <plugin> <groupId> org.codehaus.mojo </groupId> <artifactId> aspectj-maven-plugin </artifactId> <version> 1.14.0 </version> <configuration> <source> 1.8 </source> <target> 1.8 </target> <complianceLevel> 1.8 </complianceLevel> <aspectLibraries> <aspectLibrary> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-sqs </artifactId> </aspectLibrary> </aspectLibraries> </configuration> <executions> <execution> <goals> <goal> compile </goal> </goals> </execution> </executions> </plugin> ... </plugins> </build> 1 2 3 4 5 6 7 8 9 10 11 12 13 plugins { id 'java' id 'io.freefair.aspectj.post-compile-weaving' version '6.3.0' } repositories { mavenCentral () } dependencies { ... aspect 'software.amazon.lambda:powertools-sqs:1.10.3' }","title":"Install"},{"location":"utilities/batch/#iam-permissions","text":"This utility requires additional permissions to work as expected. Lambda functions using this utility require the sqs:DeleteMessageBatch permission. If you are also using nonRetryableExceptions attribute, utility will need additional permission of sqs:GetQueueAttributes on source SQS. It also needs sqs:SendMessage and sqs:SendMessageBatch on configured dead letter queue. If source or dead letter queue is configured to use encryption at rest using AWS Key Management Service (KMS) , function will need additional permissions of kms:GenerateDataKey and kms:Decrypt on the KMS key being used for encryption. Refer docs for more details. Refer example project for policy details example.","title":"IAM Permissions"},{"location":"utilities/batch/#processing-messages-from-sqs","text":"You can use either SqsBatch annotation , or SqsUtils Utility API as a fluent API. Both have nearly the same behaviour when it comes to processing messages from the batch: Entire batch has been successfully processed , where your Lambda handler returned successfully, we will let SQS delete the batch to optimize your cost Entire Batch has been partially processed successfully , where exceptions were raised within your SqsMessageHandler interface implementation, we will: 1) Delete successfully processed messages from the queue by directly calling sqs:DeleteMessageBatch 2) if, non retryable exceptions occur, messages resulting in configured exceptions during processing will be immediately moved to the dead letter queue associated to the source SQS queue or deleted from the source SQS queue if deleteNonRetryableMessageFromQueue is set to true . 3) Raise SQSBatchProcessingException to ensure failed messages return to your SQS queue The only difference is that SqsUtils Utility API will give you access to return from the processed messages if you need. Exception SQSBatchProcessingException thrown from the utility will have access to both successful and failed messaged along with failure exceptions.","title":"Processing messages from SQS"},{"location":"utilities/batch/#functional-interface-sqsmessagehandler","text":"Both annotation and SqsUtils Utility API requires an implementation of functional interface SqsMessageHandler . This implementation is responsible for processing each individual message from the batch, and to raise an exception if unable to process any of the messages sent. Any non-exception/successful return from your record handler function will instruct utility to queue up each individual message for deletion.","title":"Functional Interface SqsMessageHandler"},{"location":"utilities/batch/#sqsbatch-annotation","text":"When using this annotation, you need provide a class implementation of SqsMessageHandler that will process individual messages from the batch - It should raise an exception if it is unable to process the record. All records in the batch will be passed to this handler for processing, even if exceptions are thrown - Here's the behaviour after completing the batch: Any successfully processed messages , we will delete them from the queue via sqs:DeleteMessageBatch . if, nonRetryableExceptions attribute is used , messages resulting in configured exceptions during processing will be immediately moved to the dead letter queue associated to the source SQS queue or deleted from the source SQS queue if deleteNonRetryableMessageFromQueue is set to true . Any unprocessed messages detected , we will raise SQSBatchProcessingException to ensure failed messages return to your SQS queue. Warning You will not have access to the processed messages within the Lambda Handler - all processing logic will and should be performed by the implemented SqsMessageHandler # process () function. AppSqsEvent.java AppSqsEventWithNonRetryableExceptions.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 import software.amazon.lambda.powertools.sqs.SqsBatch ; import software.amazon.lambda.powertools.sqs.SqsMessageHandler ; import software.amazon.lambda.powertools.sqs.SqsUtils ; public class AppSqsEvent implements RequestHandler < SQSEvent , String > { @Override @SqsBatch ( SampleMessageHandler . class ) public String handleRequest ( SQSEvent input , Context context ) { return \"{\\\"statusCode\\\": 200}\" ; } public class SampleMessageHandler implements SqsMessageHandler < Object > { @Override public String process ( SQSMessage message ) { // This will be called for each individual message from a batch // It should raise an exception if the message was not processed successfully String returnVal = doSomething ( message . getBody ()); return returnVal ; } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 import software.amazon.lambda.powertools.sqs.SqsBatch ; import software.amazon.lambda.powertools.sqs.SqsMessageHandler ; import software.amazon.lambda.powertools.sqs.SqsUtils ; public class AppSqsEvent implements RequestHandler < SQSEvent , String > { @Override @SqsBatch ( value = SampleMessageHandler . class , nonRetryableExceptions = { IllegalArgumentException . class }) public String handleRequest ( SQSEvent input , Context context ) { return \"{\\\"statusCode\\\": 200}\" ; } public class SampleMessageHandler implements SqsMessageHandler < Object > { @Override public String process ( SQSMessage message ) { // This will be called for each individual message from a batch // It should raise an exception if the message was not processed successfully String returnVal = doSomething ( message . getBody ()); if ( /**Business validation failure**/ ) { throw new IllegalArgumentException ( \"Failed business validation. No point of retrying. Move me to DLQ.\" + message . getMessageId ()); } return returnVal ; } } }","title":"SqsBatch annotation"},{"location":"utilities/batch/#sqsutils-utility-api","text":"If you require access to the result of processed messages, you can use this utility. The result from calling SqsUtils # batchProcessor () on the context manager will be a list of all the return values from your SqsMessageHandler # process () function. You can also use the utility in functional way by providing inline implementation of functional interface SqsMessageHandler # process () Utility API Function implementation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public class AppSqsEvent implements RequestHandler < SQSEvent , List < String >> { @Override public List < String > handleRequest ( SQSEvent input , Context context ) { List < String > returnValues = SqsUtils . batchProcessor ( input , SampleMessageHandler . class ); return returnValues ; } public class SampleMessageHandler implements SqsMessageHandler < String > { @Override public String process ( SQSMessage message ) { // This will be called for each individual message from a batch // It should raise an exception if the message was not processed successfully String returnVal = doSomething ( message . getBody ()); return returnVal ; } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class AppSqsEvent implements RequestHandler < SQSEvent , List < String >> { @Override public List < String > handleRequest ( SQSEvent input , Context context ) { List < String > returnValues = SqsUtils . batchProcessor ( input , ( message ) -> { // This will be called for each individual message from a batch // It should raise an exception if the message was not processed successfully String returnVal = doSomething ( message . getBody ()); return returnVal ; }); return returnValues ; } }","title":"SqsUtils Utility API"},{"location":"utilities/batch/#passing-custom-sqsclient","text":"If you need to pass custom SqsClient such as region to the SDK, you can pass your own SqsClient to be used by utility either for SqsBatch annotation , or SqsUtils Utility API . App.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 public class AppSqsEvent implements RequestHandler < SQSEvent , List < String >> { static { SqsUtils . overrideSqsClient ( SqsClient . builder () . build ()); } @Override public List < String > handleRequest ( SQSEvent input , Context context ) { List < String > returnValues = SqsUtils . batchProcessor ( input , SampleMessageHandler . class ); return returnValues ; } public class SampleMessageHandler implements SqsMessageHandler < String > { @Override public String process ( SQSMessage message ) { // This will be called for each individual message from a batch // It should raise an exception if the message was not processed successfully String returnVal = doSomething ( message . getBody ()); return returnVal ; } } }","title":"Passing custom SqsClient"},{"location":"utilities/batch/#suppressing-exceptions","text":"If you want to disable the default behavior where SQSBatchProcessingException is raised if there are any exception, you can pass the suppressException boolean argument. Within SqsBatch annotation Within SqsUtils Utility API 1 2 3 4 5 @Override @SqsBatch ( value = SampleMessageHandler . class , suppressException = true ) public String handleRequest ( SQSEvent input , Context context ) { return \"{\\\"statusCode\\\": 200}\" ; } 1 2 3 4 5 6 @Override public List < String > handleRequest ( SQSEvent input , Context context ) { List < String > returnValues = SqsUtils . batchProcessor ( input , true , SampleMessageHandler . class ); return returnValues ; }","title":"Suppressing exceptions"},{"location":"utilities/batch/#move-non-retryable-messages-to-a-dead-letter-queue","text":"If you want certain exceptions to be treated as permanent failures during batch processing, i.e. exceptions where the result of retrying will always be a failure and want these can be immediately moved to the dead letter queue associated to the source SQS queue, you can use SqsBatch#nonRetryableExceptions() to configure such exceptions. If you want such messages to be deleted instead, set SqsBatch#deleteNonRetryableMessageFromQueue() to true . By default, its value is false . Same capability is also provided by SqsUtils Utility API . Info Make sure the lambda function has required permissions needed by utility. Refer this section . SqsBatch annotation SqsBatch API 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 import software.amazon.lambda.powertools.sqs.SqsBatch ; import software.amazon.lambda.powertools.sqs.SqsMessageHandler ; import software.amazon.lambda.powertools.sqs.SqsUtils ; public class AppSqsEvent implements RequestHandler < SQSEvent , String > { @Override @SqsBatch ( value = SampleMessageHandler . class , nonRetryableExceptions = { IllegalArgumentException . class }) public String handleRequest ( SQSEvent input , Context context ) { return \"{\\\"statusCode\\\": 200}\" ; } public class SampleMessageHandler implements SqsMessageHandler < Object > { @Override public String process ( SQSMessage message ) { // This will be called for each individual message from a batch // It should raise an exception if the message was not processed successfully String returnVal = doSomething ( message . getBody ()); if ( /**Business validation failure**/ ) { throw new IllegalArgumentException ( \"Failed business validation. No point of retrying. Move me to DLQ.\" + message . getMessageId ()); } return returnVal ; } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 import software.amazon.lambda.powertools.sqs.SqsBatch ; import software.amazon.lambda.powertools.sqs.SqsMessageHandler ; import software.amazon.lambda.powertools.sqs.SqsUtils ; public class AppSqsEvent implements RequestHandler < SQSEvent , String > { @Override public String handleRequest ( SQSEvent input , Context context ) { SqsUtils . batchProcessor ( input , BatchProcessor . class , IllegalArgumentException . class ); return \"{\\\"statusCode\\\": 200}\" ; } public class SampleMessageHandler implements SqsMessageHandler < Object > { @Override public String process ( SQSMessage message ) { // This will be called for each individual message from a batch // It should raise an exception if the message was not processed successfully String returnVal = doSomething ( message . getBody ()); if ( /**Business validation failure**/ ) { throw new IllegalArgumentException ( \"Failed business validation. No point of retrying. Move me to DLQ.\" + message . getMessageId ()); } return returnVal ; } } }","title":"Move non retryable messages to a dead letter queue"},{"location":"utilities/custom_resources/","text":"title: Custom Resources description: Utility \u00b6 Custom resources provide a way for AWS Lambda functions to execute provisioning logic whenever CloudFormation stacks are created, updated, or deleted. The CloudFormation utility enables developers to write these Lambda functions in Java. The utility provides a base AbstractCustomResourceHandler class which handles custom resource request events , constructs custom resource responses , and sends them to the custom resources. Subclasses implement the provisioning logic and configure certain properties of these response objects. Install \u00b6 To install this utility, add the following dependency to your project. Maven Gradle 1 2 3 4 5 <dependency> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-cloudformation </artifactId> <version> 1.10.3 </version> </dependency> 1 2 3 4 dependencies { ... implementation 'software.amazon.lambda:powertools-cloudformation:1.10.3' } Usage \u00b6 Create a new AbstractCustomResourceHandler subclass and implement the create , update , and delete methods with provisioning logic in the appropriate methods(s). As an example, if a Lambda function only needs to provision something when a stack is created, put the provisioning logic exclusively within the create method; the other methods can just return null . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 import com.amazonaws.services.lambda.runtime.Context ; import com.amazonaws.services.lambda.runtime.events.CloudFormationCustomResourceEvent ; import software.amazon.lambda.powertools.cloudformation.AbstractCustomResourceHandler ; import software.amazon.lambda.powertools.cloudformation.Response ; public class ProvisionOnCreateHandler extends AbstractCustomResourceHandler { @Override protected Response create ( CloudFormationCustomResourceEvent createEvent , Context context ) { doProvisioning (); return Response . success (); } @Override protected Response update ( CloudFormationCustomResourceEvent updateEvent , Context context ) { return null ; } @Override protected Response delete ( CloudFormationCustomResourceEvent deleteEvent , Context context ) { return null ; } } Signaling Provisioning Failures \u00b6 If provisioning fails, the stack creation/modification/deletion as a whole can be failed by either throwing a RuntimeException or by explicitly returning a Response with a failed status, e.g. Response.failure() . Configuring Response Objects \u00b6 When provisioning results in data to be shared with other parts of the stack, include this data within the returned Response instance. This Lambda function creates a Chime AppInstance and maps the returned ARN to a \"ChimeAppInstanceArn\" attribute. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class ChimeAppInstanceHandler extends AbstractCustomResourceHandler { @Override protected Response create ( CloudFormationCustomResourceEvent createEvent , Context context ) { CreateAppInstanceRequest chimeRequest = CreateAppInstanceRequest . builder () . name ( \"my-app-name\" ) . build (); CreateAppInstanceResponse chimeResponse = ChimeClient . builder () . region ( \"us-east-1\" ) . createAppInstance ( chimeRequest ); Map < String , String > chimeAtts = Map . of ( \"ChimeAppInstanceArn\" , chimeResponse . appInstanceArn ()); return Response . builder () . value ( chimeAtts ) . build (); } } For the example above the following response payload will be sent. 1 2 3 4 5 6 7 8 9 10 11 { \"Status\" : \"SUCCESS\" , \"PhysicalResourceId\" : \"2021/10/01/e3a37e552eff4718a5675c1e31f0649e\" , \"StackId\" : \"arn:aws:cloudformation:us-east-1:123456789000:stack/Custom-stack/59e4d2d0-2fe2-10ec-b00e-124d7c1c5f15\" , \"RequestId\" : \"7cae0346-0359-4dff-b80a-a82f247467b6\" , \"LogicalResourceId:\" : \"ChimeTriggerResource\" , \"NoEcho\" : false , \"Data\" : { \"ChimeAppInstanceArn\" : \"arn:aws:chime:us-east-1:123456789000:app-instance/150972c2-5490-49a9-8ba7-e7da4257c16a\" } } Once the custom resource receives this response, it's \"ChimeAppInstanceArn\" attribute is set and the Fn::GetAtt function may be used to retrieve the attribute value and make it available to other resources in the stack. Sensitive Response Data \u00b6 If any attributes are sensitive, enable the \"noEcho\" flag to mask the output of the custom resource when it's retrieved with the Fn::GetAtt function. 1 2 3 4 5 6 7 8 9 public class SensitiveDataHandler extends AbstractResourceHandler { @Override protected Response create ( CloudFormationCustomResourceEvent createEvent , Context context ) { return Response . builder () . value ( Map . of ( \"SomeSecret\" , sensitiveValue )) . noEcho ( true ) . build (); } } Customizing Serialization \u00b6 Although using a Map as the Response's value is the most straightforward way to provide attribute name/value pairs, any arbitrary java.lang.Object may be used. By default, these objects are serialized with an internal Jackson ObjectMapper . If the object requires special serialization logic, a custom ObjectMapper can be specified. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 public class CustomSerializationHandler extends AbstractResourceHandler { /** * Type representing the custom response Data. */ static class Policy { public ZonedDateTime getExpires () { return ZonedDateTime . now (). plusDays ( 10 ); } } /** * Mapper for serializing Policy instances. */ private final ObjectMapper policyMapper = new ObjectMapper () . registerModule ( new JavaTimeModule ()) . disable ( SerializationFeature . WRITE_DATES_AS_TIMESTAMPS ); @Override protected Response create ( CloudFormationCustomResourceEvent createEvent , Context context ) { Policy policy = new Policy (); return Response . builder () . value ( policy ) . objectMapper ( policyMapper ) // customize serialization . build (); } }","title":"Custom resources"},{"location":"utilities/custom_resources/#title-custom-resources-description-utility","text":"Custom resources provide a way for AWS Lambda functions to execute provisioning logic whenever CloudFormation stacks are created, updated, or deleted. The CloudFormation utility enables developers to write these Lambda functions in Java. The utility provides a base AbstractCustomResourceHandler class which handles custom resource request events , constructs custom resource responses , and sends them to the custom resources. Subclasses implement the provisioning logic and configure certain properties of these response objects.","title":"title: Custom Resources description: Utility"},{"location":"utilities/custom_resources/#install","text":"To install this utility, add the following dependency to your project. Maven Gradle 1 2 3 4 5 <dependency> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-cloudformation </artifactId> <version> 1.10.3 </version> </dependency> 1 2 3 4 dependencies { ... implementation 'software.amazon.lambda:powertools-cloudformation:1.10.3' }","title":"Install"},{"location":"utilities/custom_resources/#usage","text":"Create a new AbstractCustomResourceHandler subclass and implement the create , update , and delete methods with provisioning logic in the appropriate methods(s). As an example, if a Lambda function only needs to provision something when a stack is created, put the provisioning logic exclusively within the create method; the other methods can just return null . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 import com.amazonaws.services.lambda.runtime.Context ; import com.amazonaws.services.lambda.runtime.events.CloudFormationCustomResourceEvent ; import software.amazon.lambda.powertools.cloudformation.AbstractCustomResourceHandler ; import software.amazon.lambda.powertools.cloudformation.Response ; public class ProvisionOnCreateHandler extends AbstractCustomResourceHandler { @Override protected Response create ( CloudFormationCustomResourceEvent createEvent , Context context ) { doProvisioning (); return Response . success (); } @Override protected Response update ( CloudFormationCustomResourceEvent updateEvent , Context context ) { return null ; } @Override protected Response delete ( CloudFormationCustomResourceEvent deleteEvent , Context context ) { return null ; } }","title":"Usage"},{"location":"utilities/custom_resources/#signaling-provisioning-failures","text":"If provisioning fails, the stack creation/modification/deletion as a whole can be failed by either throwing a RuntimeException or by explicitly returning a Response with a failed status, e.g. Response.failure() .","title":"Signaling Provisioning Failures"},{"location":"utilities/custom_resources/#configuring-response-objects","text":"When provisioning results in data to be shared with other parts of the stack, include this data within the returned Response instance. This Lambda function creates a Chime AppInstance and maps the returned ARN to a \"ChimeAppInstanceArn\" attribute. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class ChimeAppInstanceHandler extends AbstractCustomResourceHandler { @Override protected Response create ( CloudFormationCustomResourceEvent createEvent , Context context ) { CreateAppInstanceRequest chimeRequest = CreateAppInstanceRequest . builder () . name ( \"my-app-name\" ) . build (); CreateAppInstanceResponse chimeResponse = ChimeClient . builder () . region ( \"us-east-1\" ) . createAppInstance ( chimeRequest ); Map < String , String > chimeAtts = Map . of ( \"ChimeAppInstanceArn\" , chimeResponse . appInstanceArn ()); return Response . builder () . value ( chimeAtts ) . build (); } } For the example above the following response payload will be sent. 1 2 3 4 5 6 7 8 9 10 11 { \"Status\" : \"SUCCESS\" , \"PhysicalResourceId\" : \"2021/10/01/e3a37e552eff4718a5675c1e31f0649e\" , \"StackId\" : \"arn:aws:cloudformation:us-east-1:123456789000:stack/Custom-stack/59e4d2d0-2fe2-10ec-b00e-124d7c1c5f15\" , \"RequestId\" : \"7cae0346-0359-4dff-b80a-a82f247467b6\" , \"LogicalResourceId:\" : \"ChimeTriggerResource\" , \"NoEcho\" : false , \"Data\" : { \"ChimeAppInstanceArn\" : \"arn:aws:chime:us-east-1:123456789000:app-instance/150972c2-5490-49a9-8ba7-e7da4257c16a\" } } Once the custom resource receives this response, it's \"ChimeAppInstanceArn\" attribute is set and the Fn::GetAtt function may be used to retrieve the attribute value and make it available to other resources in the stack.","title":"Configuring Response Objects"},{"location":"utilities/custom_resources/#sensitive-response-data","text":"If any attributes are sensitive, enable the \"noEcho\" flag to mask the output of the custom resource when it's retrieved with the Fn::GetAtt function. 1 2 3 4 5 6 7 8 9 public class SensitiveDataHandler extends AbstractResourceHandler { @Override protected Response create ( CloudFormationCustomResourceEvent createEvent , Context context ) { return Response . builder () . value ( Map . of ( \"SomeSecret\" , sensitiveValue )) . noEcho ( true ) . build (); } }","title":"Sensitive Response Data"},{"location":"utilities/custom_resources/#customizing-serialization","text":"Although using a Map as the Response's value is the most straightforward way to provide attribute name/value pairs, any arbitrary java.lang.Object may be used. By default, these objects are serialized with an internal Jackson ObjectMapper . If the object requires special serialization logic, a custom ObjectMapper can be specified. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 public class CustomSerializationHandler extends AbstractResourceHandler { /** * Type representing the custom response Data. */ static class Policy { public ZonedDateTime getExpires () { return ZonedDateTime . now (). plusDays ( 10 ); } } /** * Mapper for serializing Policy instances. */ private final ObjectMapper policyMapper = new ObjectMapper () . registerModule ( new JavaTimeModule ()) . disable ( SerializationFeature . WRITE_DATES_AS_TIMESTAMPS ); @Override protected Response create ( CloudFormationCustomResourceEvent createEvent , Context context ) { Policy policy = new Policy (); return Response . builder () . value ( policy ) . objectMapper ( policyMapper ) // customize serialization . build (); } }","title":"Customizing Serialization"},{"location":"utilities/parameters/","text":"The parameters utility provides a way to retrieve parameter values from AWS Systems Manager Parameter Store or AWS Secrets Manager . It also provides a base class to create your parameter provider implementation. Key features Retrieve one or multiple parameters from the underlying provider Cache parameter values for a given amount of time (defaults to 5 seconds) Transform parameter values from JSON or base 64 encoded strings Install \u00b6 To install this utility, add the following dependency to your project. Maven Gradle 1 2 3 4 5 <dependency> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-parameters </artifactId> <version> 1.10.3 </version> </dependency> 1 2 3 4 dependencies { ... aspect 'software.amazon.lambda:powertools-parameters:1.10.3' } IAM Permissions This utility requires additional permissions to work as expected. See the table below: Provider Function/Method IAM Permission SSM Parameter Store SSMProvider.get(String) SSMProvider.get(String, Class) ssm:GetParameter SSM Parameter Store SSMProvider.getMultiple(String) ssm:GetParametersByPath Secrets Manager SecretsProvider.get(String) SecretsProvider.get(String, Class) secretsmanager:GetSecretValue SSM Parameter Store \u00b6 You can retrieve a single parameter using SSMProvider.get() and pass the key of the parameter. For multiple parameters, you can use SSMProvider.getMultiple() and pass the path to retrieve them all. Alternatively, you can retrieve an instance of a provider and configure its underlying SDK client, in order to get data from other regions or use specific credentials. SSMProvider SSMProvider with an explicit region 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import software.amazon.lambda.powertools.parameters.SSMProvider ; import software.amazon.lambda.powertools.parameters.ParamManager ; public class AppWithSSM implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { // Get an instance of the SSM Provider SSMProvider ssmProvider = ParamManager . getSsmProvider (); // Retrieve a single parameter String value = ssmProvider . get ( \"/my/parameter\" ); // Retrieve multiple parameters from a path prefix // This returns a Map with the parameter name as key Map < String , String > values = ssmProvider . getMultiple ( \"/my/path/prefix\" ); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import software.amazon.lambda.powertools.parameters.SSMProvider ; import software.amazon.lambda.powertools.parameters.ParamManager ; public class AppWithSSM implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { SsmClient client = SsmClient . builder (). region ( Region . EU_CENTRAL_1 ). build (); // Get an instance of the SSM Provider SSMProvider ssmProvider = ParamManager . getSsmProvider ( client ); // Retrieve a single parameter String value = ssmProvider . get ( \"/my/parameter\" ); // Retrieve multiple parameters from a path prefix // This returns a Map with the parameter name as key Map < String , String > values = ssmProvider . getMultiple ( \"/my/path/prefix\" ); } Additional arguments \u00b6 The AWS Systems Manager Parameter Store provider supports two additional arguments for the get() and getMultiple() methods: Option Default Description withDecryption() False Will automatically decrypt the parameter. recursive() False For getMultiple() only, will fetch all parameter values recursively based on a path prefix. Example: AppWithSSM.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 import software.amazon.lambda.powertools.parameters.SSMProvider ; import software.amazon.lambda.powertools.parameters.ParamManager ; public class AppWithSSM implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { // Get an instance of the SSM Provider SSMProvider ssmProvider = ParamManager . getSsmProvider (); // Retrieve a single parameter and decrypt it String value = ssmProvider . withDecryption (). get ( \"/my/parameter\" ); // Retrieve multiple parameters recursively from a path prefix Map < String , String > values = ssmProvider . recursive (). getMultiple ( \"/my/path/prefix\" ); } Secrets Manager \u00b6 For secrets stored in Secrets Manager, use getSecretsProvider . Alternatively, you can retrieve an instance of a provider and configure its underlying SDK client, in order to get data from other regions or use specific credentials. SecretsProvider SecretsProvider with an explicit region 1 2 3 4 5 6 7 8 9 10 11 import software.amazon.lambda.powertools.parameters.SecretsProvider ; import software.amazon.lambda.powertools.parameters.ParamManager ; public class AppWithSecrets implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { // Get an instance of the Secrets Provider SecretsProvider secretsProvider = ParamManager . getSecretsProvider (); // Retrieve a single secret String value = secretsProvider . get ( \"/my/secret\" ); } 1 2 3 4 5 6 7 8 9 10 11 12 import software.amazon.lambda.powertools.parameters.SecretsProvider ; import software.amazon.lambda.powertools.parameters.ParamManager ; public class AppWithSecrets implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { SecretsManagerClient client = SecretsManagerClient . builder (). region ( Region . EU_CENTRAL_1 ). build (); // Get an instance of the Secrets Provider SecretsProvider secretsProvider = ParamManager . getSecretsProvider ( client ); // Retrieve a single secret String value = secretsProvider . get ( \"/my/secret\" ); } Advanced configuration \u00b6 Caching \u00b6 By default, all parameters and their corresponding values are cached for 5 seconds. You can customize this default value using defaultMaxAge . You can also customize this value for each parameter using withMaxAge . Provider with default Max age Provider with age for each param 1 2 3 4 5 6 7 8 9 10 11 import software.amazon.lambda.powertools.parameters.SecretsProvider ; import software.amazon.lambda.powertools.parameters.ParamManager ; public class AppWithSecrets implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { // Get an instance of the Secrets Provider SecretsProvider secretsProvider = ParamManager . getSecretsProvider () . defaultMaxAge ( 10 , ChronoUnit . SECONDS ); String value = secretsProvider . get ( \"/my/secret\" ); } 1 2 3 4 5 6 7 8 9 10 11 import software.amazon.lambda.powertools.parameters.SecretsProvider ; import software.amazon.lambda.powertools.parameters.ParamManager ; public class AppWithSecrets implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { SecretsManagerClient client = SecretsManagerClient . builder (). region ( Region . EU_CENTRAL_1 ). build (); SecretsProvider secretsProvider = ParamManager . getSecretsProvider ( client ); String value = secretsProvider . withMaxAge ( 10 , ChronoUnit . SECONDS ). get ( \"/my/secret\" ); } Transform values \u00b6 Parameter values can be transformed using withTransformation(transformerClass) . Base64 and JSON transformations are provided. For more complex transformation, you need to specify how to deserialize- SSMProvider.getMultiple() does not support transformation and will return simple Strings. Base64 Transformation Complex Transformation 1 2 3 String value = provider . withTransformation ( Transformer . base64 ) . get ( \"/my/parameter/b64\" ); 1 2 3 MyObj object = provider . withTransformation ( Transformer . json ) . get ( \"/my/parameter/json\" , MyObj . class ); Write your own Transformer \u00b6 You can write your own transformer, by implementing the Transformer interface and the applyTransformation() method. For example, if you wish to deserialize XML into an object. XmlTransformer.java Using XmlTransformer 1 2 3 4 5 6 7 8 9 10 11 12 13 public class XmlTransformer < T > implements Transformer < T > { private final XmlMapper mapper = new XmlMapper (); @Override public T applyTransformation ( String value , Class < T > targetClass ) throws TransformationException { try { return mapper . readValue ( value , targetClass ); } catch ( IOException e ) { throw new TransformationException ( e ); } } } 1 2 3 MyObj object = provider . withTransformation ( XmlTransformer . class ) . get ( \"/my/parameter/xml\" , MyObj . class ); Fluent API \u00b6 To simplify the use of the library, you can chain all method calls before a get. Fluent API call 1 2 3 4 5 6 ssmProvider . defaultMaxAge ( 10 , SECONDS ) // will set 10 seconds as the default cache TTL . withMaxAge ( 1 , MINUTES ) // will set the cache TTL for this value at 1 minute . withTransformation ( json ) // json is a static import from Transformer.json . withDecryption () // enable decryption of the parameter value . get ( \"/my/param\" , MyObj . class ); // finally get the value Create your own provider \u00b6 You can create your own custom parameter store provider by inheriting the BaseProvider class and implementing the String getValue(String key) method to retrieve data from your underlying store. All transformation and caching logic is handled by the get() methods in the base class. Example implementation using S3 as a custom parameter Using custom parameter store 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 public class S3Provider extends BaseProvider { private final S3Client client ; private String bucket ; S3Provider ( CacheManager cacheManager ) { this ( cacheManager , S3Client . create ()); } S3Provider ( CacheManager cacheManager , S3Client client ) { super ( cacheManager ); this . client = client ; } public S3Provider withBucket ( String bucket ) { this . bucket = bucket ; return this ; } @Override protected String getValue ( String key ) { if ( bucket == null ) { throw new IllegalStateException ( \"A bucket must be specified, using withBucket() method\" ); } GetObjectRequest request = GetObjectRequest . builder (). bucket ( bucket ). key ( key ). build (); ResponseBytes < GetObjectResponse > response = client . getObject ( request , ResponseTransformer . toBytes ()); return response . asUtf8String (); } @Override protected Map < String , String > getMultipleValues ( String path ) { if ( bucket == null ) { throw new IllegalStateException ( \"A bucket must be specified, using withBucket() method\" ); } ListObjectsV2Request listRequest = ListObjectsV2Request . builder (). bucket ( bucket ). prefix ( path ). build (); List < S3Object > s3Objects = client . listObjectsV2 ( listRequest ). contents (); Map < String , String > result = new HashMap <> (); s3Objects . forEach ( s3Object -> { result . put ( s3Object . key (), getValue ( s3Object . key ())); }); return result ; } @Override protected void resetToDefaults () { super . resetToDefaults (); bucket = null ; } } 1 2 3 4 5 S3Provider provider = new S3Provider ( ParamManager . getCacheManager ()); provider . setTransformationManager ( ParamManager . getTransformationManager ()); String value = provider . withBucket ( \"myBucket\" ). get ( \"myKey\" ); Annotation \u00b6 You can make use of the annotation @Param to inject a parameter value in a variable. By default, it will use SSMProvider to retrieve the value from AWS System Manager Parameter Store. You could specify a different provider as long as it extends BaseProvider and/or a Transformer . Param Annotation Custom Provider Usage 1 2 3 4 5 6 public class AppWithAnnotation implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Param ( key = \"/my/parameter/json\" ) ObjectToDeserialize value ; } 1 2 3 4 5 6 public class AppWithAnnotation implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Param ( key = \"/my/parameter/json\" provider = SecretsProvider . class , transformer = JsonTransformer . class ) ObjectToDeserialize value ; } In this case SecretsProvider will be used to retrieve a raw value that is then trasformed into the target Object by using JsonTransformer . To show the convenience of the annotation compare the following two code snippets. Install \u00b6 If you want to use the @Param annotation in your project add configuration to compile-time weave (CTW) the powertools-parameters aspects into your project. Maven Gradle 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 <build> <plugins> ... <plugin> <groupId> org.codehaus.mojo </groupId> <artifactId> aspectj-maven-plugin </artifactId> <version> 1.14.0 </version> <configuration> ... <aspectLibraries> ... <aspectLibrary> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-parameters </artifactId> </aspectLibrary> </aspectLibraries> </configuration> <executions> <execution> <goals> <goal> compile </goal> </goals> </execution> </executions> </plugin> ... </plugins> </build> 1 2 3 4 5 6 7 8 9 10 11 12 13 plugins { id 'java' id 'io.freefair.aspectj.post-compile-weaving' version '6.3.0' } repositories { mavenCentral () } dependencies { ... aspect 'software.amazon.lambda:powertools-parameters:1.10.3' }","title":"Parameters"},{"location":"utilities/parameters/#install","text":"To install this utility, add the following dependency to your project. Maven Gradle 1 2 3 4 5 <dependency> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-parameters </artifactId> <version> 1.10.3 </version> </dependency> 1 2 3 4 dependencies { ... aspect 'software.amazon.lambda:powertools-parameters:1.10.3' } IAM Permissions This utility requires additional permissions to work as expected. See the table below: Provider Function/Method IAM Permission SSM Parameter Store SSMProvider.get(String) SSMProvider.get(String, Class) ssm:GetParameter SSM Parameter Store SSMProvider.getMultiple(String) ssm:GetParametersByPath Secrets Manager SecretsProvider.get(String) SecretsProvider.get(String, Class) secretsmanager:GetSecretValue","title":"Install"},{"location":"utilities/parameters/#ssm-parameter-store","text":"You can retrieve a single parameter using SSMProvider.get() and pass the key of the parameter. For multiple parameters, you can use SSMProvider.getMultiple() and pass the path to retrieve them all. Alternatively, you can retrieve an instance of a provider and configure its underlying SDK client, in order to get data from other regions or use specific credentials. SSMProvider SSMProvider with an explicit region 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import software.amazon.lambda.powertools.parameters.SSMProvider ; import software.amazon.lambda.powertools.parameters.ParamManager ; public class AppWithSSM implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { // Get an instance of the SSM Provider SSMProvider ssmProvider = ParamManager . getSsmProvider (); // Retrieve a single parameter String value = ssmProvider . get ( \"/my/parameter\" ); // Retrieve multiple parameters from a path prefix // This returns a Map with the parameter name as key Map < String , String > values = ssmProvider . getMultiple ( \"/my/path/prefix\" ); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import software.amazon.lambda.powertools.parameters.SSMProvider ; import software.amazon.lambda.powertools.parameters.ParamManager ; public class AppWithSSM implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { SsmClient client = SsmClient . builder (). region ( Region . EU_CENTRAL_1 ). build (); // Get an instance of the SSM Provider SSMProvider ssmProvider = ParamManager . getSsmProvider ( client ); // Retrieve a single parameter String value = ssmProvider . get ( \"/my/parameter\" ); // Retrieve multiple parameters from a path prefix // This returns a Map with the parameter name as key Map < String , String > values = ssmProvider . getMultiple ( \"/my/path/prefix\" ); }","title":"SSM Parameter Store"},{"location":"utilities/parameters/#additional-arguments","text":"The AWS Systems Manager Parameter Store provider supports two additional arguments for the get() and getMultiple() methods: Option Default Description withDecryption() False Will automatically decrypt the parameter. recursive() False For getMultiple() only, will fetch all parameter values recursively based on a path prefix. Example: AppWithSSM.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 import software.amazon.lambda.powertools.parameters.SSMProvider ; import software.amazon.lambda.powertools.parameters.ParamManager ; public class AppWithSSM implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { // Get an instance of the SSM Provider SSMProvider ssmProvider = ParamManager . getSsmProvider (); // Retrieve a single parameter and decrypt it String value = ssmProvider . withDecryption (). get ( \"/my/parameter\" ); // Retrieve multiple parameters recursively from a path prefix Map < String , String > values = ssmProvider . recursive (). getMultiple ( \"/my/path/prefix\" ); }","title":"Additional arguments"},{"location":"utilities/parameters/#secrets-manager","text":"For secrets stored in Secrets Manager, use getSecretsProvider . Alternatively, you can retrieve an instance of a provider and configure its underlying SDK client, in order to get data from other regions or use specific credentials. SecretsProvider SecretsProvider with an explicit region 1 2 3 4 5 6 7 8 9 10 11 import software.amazon.lambda.powertools.parameters.SecretsProvider ; import software.amazon.lambda.powertools.parameters.ParamManager ; public class AppWithSecrets implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { // Get an instance of the Secrets Provider SecretsProvider secretsProvider = ParamManager . getSecretsProvider (); // Retrieve a single secret String value = secretsProvider . get ( \"/my/secret\" ); } 1 2 3 4 5 6 7 8 9 10 11 12 import software.amazon.lambda.powertools.parameters.SecretsProvider ; import software.amazon.lambda.powertools.parameters.ParamManager ; public class AppWithSecrets implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { SecretsManagerClient client = SecretsManagerClient . builder (). region ( Region . EU_CENTRAL_1 ). build (); // Get an instance of the Secrets Provider SecretsProvider secretsProvider = ParamManager . getSecretsProvider ( client ); // Retrieve a single secret String value = secretsProvider . get ( \"/my/secret\" ); }","title":"Secrets Manager"},{"location":"utilities/parameters/#advanced-configuration","text":"","title":"Advanced configuration"},{"location":"utilities/parameters/#caching","text":"By default, all parameters and their corresponding values are cached for 5 seconds. You can customize this default value using defaultMaxAge . You can also customize this value for each parameter using withMaxAge . Provider with default Max age Provider with age for each param 1 2 3 4 5 6 7 8 9 10 11 import software.amazon.lambda.powertools.parameters.SecretsProvider ; import software.amazon.lambda.powertools.parameters.ParamManager ; public class AppWithSecrets implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { // Get an instance of the Secrets Provider SecretsProvider secretsProvider = ParamManager . getSecretsProvider () . defaultMaxAge ( 10 , ChronoUnit . SECONDS ); String value = secretsProvider . get ( \"/my/secret\" ); } 1 2 3 4 5 6 7 8 9 10 11 import software.amazon.lambda.powertools.parameters.SecretsProvider ; import software.amazon.lambda.powertools.parameters.ParamManager ; public class AppWithSecrets implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { SecretsManagerClient client = SecretsManagerClient . builder (). region ( Region . EU_CENTRAL_1 ). build (); SecretsProvider secretsProvider = ParamManager . getSecretsProvider ( client ); String value = secretsProvider . withMaxAge ( 10 , ChronoUnit . SECONDS ). get ( \"/my/secret\" ); }","title":"Caching"},{"location":"utilities/parameters/#transform-values","text":"Parameter values can be transformed using withTransformation(transformerClass) . Base64 and JSON transformations are provided. For more complex transformation, you need to specify how to deserialize- SSMProvider.getMultiple() does not support transformation and will return simple Strings. Base64 Transformation Complex Transformation 1 2 3 String value = provider . withTransformation ( Transformer . base64 ) . get ( \"/my/parameter/b64\" ); 1 2 3 MyObj object = provider . withTransformation ( Transformer . json ) . get ( \"/my/parameter/json\" , MyObj . class );","title":"Transform values"},{"location":"utilities/parameters/#write-your-own-transformer","text":"You can write your own transformer, by implementing the Transformer interface and the applyTransformation() method. For example, if you wish to deserialize XML into an object. XmlTransformer.java Using XmlTransformer 1 2 3 4 5 6 7 8 9 10 11 12 13 public class XmlTransformer < T > implements Transformer < T > { private final XmlMapper mapper = new XmlMapper (); @Override public T applyTransformation ( String value , Class < T > targetClass ) throws TransformationException { try { return mapper . readValue ( value , targetClass ); } catch ( IOException e ) { throw new TransformationException ( e ); } } } 1 2 3 MyObj object = provider . withTransformation ( XmlTransformer . class ) . get ( \"/my/parameter/xml\" , MyObj . class );","title":"Write your own Transformer"},{"location":"utilities/parameters/#fluent-api","text":"To simplify the use of the library, you can chain all method calls before a get. Fluent API call 1 2 3 4 5 6 ssmProvider . defaultMaxAge ( 10 , SECONDS ) // will set 10 seconds as the default cache TTL . withMaxAge ( 1 , MINUTES ) // will set the cache TTL for this value at 1 minute . withTransformation ( json ) // json is a static import from Transformer.json . withDecryption () // enable decryption of the parameter value . get ( \"/my/param\" , MyObj . class ); // finally get the value","title":"Fluent API"},{"location":"utilities/parameters/#create-your-own-provider","text":"You can create your own custom parameter store provider by inheriting the BaseProvider class and implementing the String getValue(String key) method to retrieve data from your underlying store. All transformation and caching logic is handled by the get() methods in the base class. Example implementation using S3 as a custom parameter Using custom parameter store 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 public class S3Provider extends BaseProvider { private final S3Client client ; private String bucket ; S3Provider ( CacheManager cacheManager ) { this ( cacheManager , S3Client . create ()); } S3Provider ( CacheManager cacheManager , S3Client client ) { super ( cacheManager ); this . client = client ; } public S3Provider withBucket ( String bucket ) { this . bucket = bucket ; return this ; } @Override protected String getValue ( String key ) { if ( bucket == null ) { throw new IllegalStateException ( \"A bucket must be specified, using withBucket() method\" ); } GetObjectRequest request = GetObjectRequest . builder (). bucket ( bucket ). key ( key ). build (); ResponseBytes < GetObjectResponse > response = client . getObject ( request , ResponseTransformer . toBytes ()); return response . asUtf8String (); } @Override protected Map < String , String > getMultipleValues ( String path ) { if ( bucket == null ) { throw new IllegalStateException ( \"A bucket must be specified, using withBucket() method\" ); } ListObjectsV2Request listRequest = ListObjectsV2Request . builder (). bucket ( bucket ). prefix ( path ). build (); List < S3Object > s3Objects = client . listObjectsV2 ( listRequest ). contents (); Map < String , String > result = new HashMap <> (); s3Objects . forEach ( s3Object -> { result . put ( s3Object . key (), getValue ( s3Object . key ())); }); return result ; } @Override protected void resetToDefaults () { super . resetToDefaults (); bucket = null ; } } 1 2 3 4 5 S3Provider provider = new S3Provider ( ParamManager . getCacheManager ()); provider . setTransformationManager ( ParamManager . getTransformationManager ()); String value = provider . withBucket ( \"myBucket\" ). get ( \"myKey\" );","title":"Create your own provider"},{"location":"utilities/parameters/#annotation","text":"You can make use of the annotation @Param to inject a parameter value in a variable. By default, it will use SSMProvider to retrieve the value from AWS System Manager Parameter Store. You could specify a different provider as long as it extends BaseProvider and/or a Transformer . Param Annotation Custom Provider Usage 1 2 3 4 5 6 public class AppWithAnnotation implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Param ( key = \"/my/parameter/json\" ) ObjectToDeserialize value ; } 1 2 3 4 5 6 public class AppWithAnnotation implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Param ( key = \"/my/parameter/json\" provider = SecretsProvider . class , transformer = JsonTransformer . class ) ObjectToDeserialize value ; } In this case SecretsProvider will be used to retrieve a raw value that is then trasformed into the target Object by using JsonTransformer . To show the convenience of the annotation compare the following two code snippets.","title":"Annotation"},{"location":"utilities/parameters/#install_1","text":"If you want to use the @Param annotation in your project add configuration to compile-time weave (CTW) the powertools-parameters aspects into your project. Maven Gradle 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 <build> <plugins> ... <plugin> <groupId> org.codehaus.mojo </groupId> <artifactId> aspectj-maven-plugin </artifactId> <version> 1.14.0 </version> <configuration> ... <aspectLibraries> ... <aspectLibrary> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-parameters </artifactId> </aspectLibrary> </aspectLibraries> </configuration> <executions> <execution> <goals> <goal> compile </goal> </goals> </execution> </executions> </plugin> ... </plugins> </build> 1 2 3 4 5 6 7 8 9 10 11 12 13 plugins { id 'java' id 'io.freefair.aspectj.post-compile-weaving' version '6.3.0' } repositories { mavenCentral () } dependencies { ... aspect 'software.amazon.lambda:powertools-parameters:1.10.3' }","title":"Install"},{"location":"utilities/sqs_large_message_handling/","text":"The large message handling utility handles SQS messages which have had their payloads offloaded to S3 due to them being larger than the SQS maximum. The utility automatically retrieves messages which have been offloaded to S3 using the amazon-sqs-java-extended-client-lib client library. Once the message payloads have been processed successful the utility can delete the message payloads from S3. This utility is compatible with versions 1.1.0+ of amazon-sqs-java-extended-client-lib. Maven Gradle 1 2 3 4 5 <dependency> <groupId> com.amazonaws </groupId> <artifactId> amazon-sqs-java-extended-client-lib </artifactId> <version> 1.1.0 </version> </dependency> 1 2 3 dependencies { implementation 'com.amazonaws:amazon-sqs-java-extended-client-lib:1.1.0' } Install \u00b6 To install this utility, add the following dependency to your project. Maven Gradle 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 <dependencies> ... <dependency> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-sqs </artifactId> <version> 1.10.3 </version> </dependency> ... </dependencies> <!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --> <build> <plugins> ... <plugin> <groupId> org.codehaus.mojo </groupId> <artifactId> aspectj-maven-plugin </artifactId> <version> 1.14.0 </version> <configuration> <source> 1.8 </source> <target> 1.8 </target> <complianceLevel> 1.8 </complianceLevel> <aspectLibraries> <aspectLibrary> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-sqs </artifactId> </aspectLibrary> </aspectLibraries> </configuration> <executions> <execution> <goals> <goal> compile </goal> </goals> </execution> </executions> </plugin> ... </plugins> </build> 1 2 3 4 5 6 7 8 9 10 11 12 13 plugins { id 'java' id 'io.freefair.aspectj.post-compile-weaving' version '6.3.0' } repositories { mavenCentral () } dependencies { ... aspect 'software.amazon.lambda:powertools-sqs:1.10.3' } Lambda handler \u00b6 The annotation @SqsLargeMessage should be used with the handleRequest method of a class which implements com.amazonaws.services.lambda.runtime.RequestHandler with com.amazonaws.services.lambda.runtime.events.SQSEvent as the first parameter. SqsMessageHandler.java 1 2 3 4 5 6 7 8 9 10 11 12 import software.amazon.lambda.powertools.sqs.SqsLargeMessage ; public class SqsMessageHandler implements RequestHandler < SQSEvent , String > { @Override @SqsLargeMessage public String handleRequest ( SQSEvent sqsEvent , Context context ) { // process messages return \"ok\" ; } } @SqsLargeMessage creates a default S3 Client AmazonS3 amazonS3 = AmazonS3ClientBuilder.defaultClient() . Tip When the Lambda function is invoked with an event from SQS, each received record in the SQSEvent is checked to see to validate if it is offloaded to S3. If it does then getObject(bucket, key) will be called, and the payload retrieved. If there is an error during this process then the function will fail with a FailedProcessingLargePayloadException exception. If the request handler method returns without error then each payload will be deleted from S3 using deleteObject(bucket, key) To disable deletion of payloads setting the following annotation parameter: Disable payload deletion 1 2 3 4 5 6 import software.amazon.lambda.powertools.sqs.SqsLargeMessage ; @SqsLargeMessage ( deletePayloads = false ) public class SqsMessageHandler implements RequestHandler < SQSEvent , String > { } Utility \u00b6 If you want to avoid using annotation and have control over error that can happen during payload enrichment use SqsUtils.enrichedMessageFromS3() . It provides you access with list of SQSMessage object enriched from S3 payload. Original SQSEvent object is never mutated. You can also control if the S3 payload should be deleted after successful processing. Functional API without annotation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 import software.amazon.lambda.powertools.sqs.SqsLargeMessage ; import software.amazon.lambda.powertools.sqs.SqsUtils ; public class SqsMessageHandler implements RequestHandler < SQSEvent , String > { @Override public String handleRequest ( SQSEvent sqsEvent , Context context ) { Map < String , String > sqsMessage = SqsUtils . enrichedMessageFromS3 ( sqsEvent , sqsMessages -> { // Some business logic Map < String , String > someBusinessLogic = new HashMap <> (); someBusinessLogic . put ( \"Message\" , sqsMessages . get ( 0 ). getBody ()); return someBusinessLogic ; }); // Do not delete payload after processing. Map < String , String > sqsMessage = SqsUtils . enrichedMessageFromS3 ( sqsEvent , false , sqsMessages -> { // Some business logic Map < String , String > someBusinessLogic = new HashMap <> (); someBusinessLogic . put ( \"Message\" , sqsMessages . get ( 0 ). getBody ()); return someBusinessLogic ; }); // Better control over exception during enrichment try { // Do not delete payload after processing. SqsUtils . enrichedMessageFromS3 ( sqsEvent , false , sqsMessages -> { // Some business logic }); } catch ( FailedProcessingLargePayloadException e ) { // handle any exception. } return \"ok\" ; } } Overriding the default S3Client \u00b6 If you require customisations to the default S3Client, you can create your own S3Client and pass it to be used by utility either for SqsLargeMessage annotation , or SqsUtils Utility API . App.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import software.amazon.lambda.powertools.sqs.SqsLargeMessage ; static { SqsUtils . overrideS3Client ( S3Client . builder () . build ()); } public class SqsMessageHandler implements RequestHandler < SQSEvent , String > { @Override @SqsLargeMessage public String handleRequest ( SQSEvent sqsEvent , Context context ) { // process messages return \"ok\" ; } }","title":"SQS Large Message Handling"},{"location":"utilities/sqs_large_message_handling/#install","text":"To install this utility, add the following dependency to your project. Maven Gradle 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 <dependencies> ... <dependency> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-sqs </artifactId> <version> 1.10.3 </version> </dependency> ... </dependencies> <!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --> <build> <plugins> ... <plugin> <groupId> org.codehaus.mojo </groupId> <artifactId> aspectj-maven-plugin </artifactId> <version> 1.14.0 </version> <configuration> <source> 1.8 </source> <target> 1.8 </target> <complianceLevel> 1.8 </complianceLevel> <aspectLibraries> <aspectLibrary> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-sqs </artifactId> </aspectLibrary> </aspectLibraries> </configuration> <executions> <execution> <goals> <goal> compile </goal> </goals> </execution> </executions> </plugin> ... </plugins> </build> 1 2 3 4 5 6 7 8 9 10 11 12 13 plugins { id 'java' id 'io.freefair.aspectj.post-compile-weaving' version '6.3.0' } repositories { mavenCentral () } dependencies { ... aspect 'software.amazon.lambda:powertools-sqs:1.10.3' }","title":"Install"},{"location":"utilities/sqs_large_message_handling/#lambda-handler","text":"The annotation @SqsLargeMessage should be used with the handleRequest method of a class which implements com.amazonaws.services.lambda.runtime.RequestHandler with com.amazonaws.services.lambda.runtime.events.SQSEvent as the first parameter. SqsMessageHandler.java 1 2 3 4 5 6 7 8 9 10 11 12 import software.amazon.lambda.powertools.sqs.SqsLargeMessage ; public class SqsMessageHandler implements RequestHandler < SQSEvent , String > { @Override @SqsLargeMessage public String handleRequest ( SQSEvent sqsEvent , Context context ) { // process messages return \"ok\" ; } } @SqsLargeMessage creates a default S3 Client AmazonS3 amazonS3 = AmazonS3ClientBuilder.defaultClient() . Tip When the Lambda function is invoked with an event from SQS, each received record in the SQSEvent is checked to see to validate if it is offloaded to S3. If it does then getObject(bucket, key) will be called, and the payload retrieved. If there is an error during this process then the function will fail with a FailedProcessingLargePayloadException exception. If the request handler method returns without error then each payload will be deleted from S3 using deleteObject(bucket, key) To disable deletion of payloads setting the following annotation parameter: Disable payload deletion 1 2 3 4 5 6 import software.amazon.lambda.powertools.sqs.SqsLargeMessage ; @SqsLargeMessage ( deletePayloads = false ) public class SqsMessageHandler implements RequestHandler < SQSEvent , String > { }","title":"Lambda handler"},{"location":"utilities/sqs_large_message_handling/#utility","text":"If you want to avoid using annotation and have control over error that can happen during payload enrichment use SqsUtils.enrichedMessageFromS3() . It provides you access with list of SQSMessage object enriched from S3 payload. Original SQSEvent object is never mutated. You can also control if the S3 payload should be deleted after successful processing. Functional API without annotation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 import software.amazon.lambda.powertools.sqs.SqsLargeMessage ; import software.amazon.lambda.powertools.sqs.SqsUtils ; public class SqsMessageHandler implements RequestHandler < SQSEvent , String > { @Override public String handleRequest ( SQSEvent sqsEvent , Context context ) { Map < String , String > sqsMessage = SqsUtils . enrichedMessageFromS3 ( sqsEvent , sqsMessages -> { // Some business logic Map < String , String > someBusinessLogic = new HashMap <> (); someBusinessLogic . put ( \"Message\" , sqsMessages . get ( 0 ). getBody ()); return someBusinessLogic ; }); // Do not delete payload after processing. Map < String , String > sqsMessage = SqsUtils . enrichedMessageFromS3 ( sqsEvent , false , sqsMessages -> { // Some business logic Map < String , String > someBusinessLogic = new HashMap <> (); someBusinessLogic . put ( \"Message\" , sqsMessages . get ( 0 ). getBody ()); return someBusinessLogic ; }); // Better control over exception during enrichment try { // Do not delete payload after processing. SqsUtils . enrichedMessageFromS3 ( sqsEvent , false , sqsMessages -> { // Some business logic }); } catch ( FailedProcessingLargePayloadException e ) { // handle any exception. } return \"ok\" ; } }","title":"Utility"},{"location":"utilities/sqs_large_message_handling/#overriding-the-default-s3client","text":"If you require customisations to the default S3Client, you can create your own S3Client and pass it to be used by utility either for SqsLargeMessage annotation , or SqsUtils Utility API . App.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import software.amazon.lambda.powertools.sqs.SqsLargeMessage ; static { SqsUtils . overrideS3Client ( S3Client . builder () . build ()); } public class SqsMessageHandler implements RequestHandler < SQSEvent , String > { @Override @SqsLargeMessage public String handleRequest ( SQSEvent sqsEvent , Context context ) { // process messages return \"ok\" ; } }","title":"Overriding the default S3Client"},{"location":"utilities/validation/","text":"This utility provides JSON Schema validation for payloads held within events and response used in AWS Lambda. Key features Validate incoming events and responses Built-in validation for most common events (API Gateway, SNS, SQS, ...) JMESPath support validate only a sub part of the event Install \u00b6 To install this utility, add the following dependency to your project. Maven Gradle 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 <dependencies> ... <dependency> <groupId> com.amazonaws </groupId> <artifactId> powertools-validation </artifactId> <version> 1.10.3 </version> </dependency> ... </dependencies> <!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --> <build> <plugins> ... <plugin> <groupId> org.codehaus.mojo </groupId> <artifactId> aspectj-maven-plugin </artifactId> <version> 1.14.0 </version> <configuration> <source> 1.8 </source> <target> 1.8 </target> <complianceLevel> 1.8 </complianceLevel> <aspectLibraries> <aspectLibrary> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-validation </artifactId> </aspectLibrary> </aspectLibraries> </configuration> <executions> <execution> <goals> <goal> compile </goal> </goals> </execution> </executions> </plugin> ... </plugins> </build> 1 2 3 4 5 6 7 8 9 10 11 12 plugins { id 'java' id 'io.freefair.aspectj.post-compile-weaving' version '6.3.0' } repositories { mavenCentral () } dependencies { aspect 'software.amazon.lambda:powertools-validation:1.10.3' } Validating events \u00b6 You can validate inbound and outbound events using @Validation annotation. You can also use the Validator#validate() methods, if you want more control over the validation process such as handling a validation error. We support JSON schema version 4, 6, 7 and 201909 (from jmespath-jackson library ). Validation annotation \u00b6 @Validation annotation is used to validate either inbound events or functions' response. It will fail fast with ValidationException if an event or response doesn't conform with given JSON Schema. While it is easier to specify a json schema file in the classpath (using the notation \"classpath:/path/to/schema.json\" ), you can also provide a JSON String containing the schema. MyFunctionHandler.java 1 2 3 4 5 6 7 8 9 10 11 import software.amazon.lambda.powertools.validation.Validation ; public class MyFunctionHandler implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Override @Validation ( inboundSchema = \"classpath:/schema_in.json\" , outboundSchema = \"classpath:/schema_out.json\" ) public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { // ... return something ; } } NOTE : It's not a requirement to validate both inbound and outbound schemas - You can either use one, or both. Validate function \u00b6 Validate standalone function is used within the Lambda handler, or any other methods that perform data validation. You can also gracefully handle schema validation errors by catching ValidationException . MyFunctionHandler.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import static software.amazon.lambda.powertools.validation.ValidationUtils.* ; public class MyFunctionHandler implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Override public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { try { validate ( input , \"classpath:/schema.json\" ); } catch ( ValidationException ex ) { // do something before throwing it throw ex ; } // ... return something ; } } NOTE : Schemas are stored in memory for reuse, to avoid loading them from file each time. Built-in events and responses \u00b6 For the following events and responses, the Validator will automatically perform validation on the content. Events Type of event Class Path to content API Gateway REST APIGatewayProxyRequestEvent body API Gateway HTTP APIGatewayV2HTTPEvent body Application Load Balancer ApplicationLoadBalancerRequestEvent body Cloudformation Custom Resource CloudFormationCustomResourceEvent resourceProperties CloudWatch Logs CloudWatchLogsEvent awslogs.powertools_base64_gzip(data) EventBridge / Cloudwatch ScheduledEvent detail Kafka KafkaEvent records[*][*].value Kinesis KinesisEvent Records[*].kinesis.powertools_base64(data) Kinesis Firehose KinesisFirehoseEvent Records[*].powertools_base64(data) Kinesis Analytics from Firehose KinesisAnalyticsFirehoseInputPreprocessingEvent Records[*].powertools_base64(data) Kinesis Analytics from Streams KinesisAnalyticsStreamsInputPreprocessingEvent Records[*].powertools_base64(data) SNS SNSEvent Records[*].Sns.Message SQS SQSEvent Records[*].body Responses Type of response Class Path to content (envelope) API Gateway REST APIGatewayProxyResponseEvent} body API Gateway HTTP APIGatewayV2HTTPResponse} body API Gateway WebSocket APIGatewayV2WebSocketResponse} body Load Balancer ApplicationLoadBalancerResponseEvent} body Kinesis Analytics KinesisAnalyticsInputPreprocessingResponse} `Records[*].powertools_base64(data)`` Custom events and responses \u00b6 You can also validate any Event or Response type, once you have the appropriate schema. Sometimes, you might want to validate only a portion of it - This is where the envelope parameter is for. Envelopes are JMESPath expressions to extract a portion of JSON you want before applying JSON Schema validation. MyCustomEventHandler.java my_custom_event_schema.json 1 2 3 4 5 6 7 8 9 10 11 import software.amazon.lambda.powertools.validation.Validation ; public class MyCustomEventHandler implements RequestHandler < MyCustomEvent , String > { @Override @Validation ( inboundSchema = \"classpath:/my_custom_event_schema.json\" , envelope = \"basket.products[*]\" ) public String handleRequest ( MyCustomEvent input , Context context ) { return \"OK\" ; } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 { \"basket\" : { \"products\" : [ { \"id\" : 43242 , \"name\" : \"FooBar XY\" , \"price\" : 258 }, { \"id\" : 765 , \"name\" : \"BarBaz AB\" , \"price\" : 43.99 } ] } } This is quite powerful because you can use JMESPath Query language to extract records from arrays, slice and dice , to pipe expressions and function expressions, where you'd extract what you need before validating the actual payload. JMESPath functions \u00b6 JMESPath functions ensure to make an operation on a specific part of the json.validate Powertools provides two built-in functions: powertools_base64 function \u00b6 Use powertools_base64 function to decode any base64 data. Below sample will decode the base64 value within the data key, and decode the JSON string into a valid JSON before we can validate it. MyEventHandler.java schema.json 1 2 3 4 5 6 7 8 9 10 import software.amazon.lambda.powertools.validation.ValidationUtils ; public class MyEventHandler implements RequestHandler < MyEvent , String > { @Override public String handleRequest ( MyEvent myEvent , Context context ) { validate ( myEvent , \"classpath:/schema.json\" , \"powertools_base64(data)\" ); return \"OK\" ; } } 1 2 3 { \"data\" : \"ewogICJpZCI6IDQzMjQyLAogICJuYW1lIjogIkZvb0JhciBYWSIsCiAgInByaWNlIjogMjU4Cn0=\" } powertools_base64_gzip function \u00b6 Use powertools_base64_gzip function to decompress and decode base64 data. Below sample will decompress and decode base64 data. MyEventHandler.java schema.json 1 2 3 4 5 6 7 8 9 10 import software.amazon.lambda.powertools.validation.ValidationUtils ; public class MyEventHandler implements RequestHandler < MyEvent , String > { @Override public String handleRequest ( MyEvent myEvent , Context context ) { validate ( myEvent , \"classpath:/schema.json\" , \"powertools_base64_gzip(data)\" ); return \"OK\" ; } } 1 2 3 { \"data\" : \"H4sIAAAAAAAA/6vmUlBQykxRslIwMTYyMdIBcfMSc1OBAkpu+flOiUUKEZFKYOGCosxkkLiRqQVXLQDnWo6bOAAAAA==\" } Note You don't need any function to transform a JSON String into a JSON object, powertools-validation will do it for you. In the 2 previous example, data contains JSON. Just provide the function to transform the base64 / gzipped / ... string into a clear JSON string. Bring your own JMESPath function \u00b6 Warning This should only be used for advanced use cases where you have special formats not covered by the built-in functions. New functions will be added to the 2 built-in ones. Your function must extend io.burt.jmespath.function.BaseFunction , take a String as parameter and return a String. You can read the doc for more information. Below is an example that takes some xml and transform it into json. Once your function is created, you need to add it to powertools.You can then use it to do your validation or using annotation. XMLFunction.java Handler with validation API Handler with validation annotation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class XMLFunction extends BaseFunction { public Base64Function () { super ( \"powertools_xml\" , ArgumentConstraints . typeOf ( JmesPathType . STRING )); } @Override protected < T > T callFunction ( Adapter < T > runtime , List < FunctionArgument < T >> arguments ) { T value = arguments . get ( 0 ). value (); String xmlString = runtime . toString ( value ); String jsonString = // ... transform xmlString to json return runtime . createString ( jsonString ); } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ... import software.amazon.lambda.powertools.validation.ValidationConfig ; import software.amazon.lambda.powertools.validation.ValidationUtils.validate ; static { ValidationConfig . get (). addFunction ( new XMLFunction ()); } public class MyXMLEventHandler implements RequestHandler < MyEventWithXML , String > { @Override public String handleRequest ( MyEventWithXML myEvent , Context context ) { validate ( myEvent , \"classpath:/schema.json\" , \"powertools_xml(path.to.xml_data)\" ); return \"OK\" ; } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ... import software.amazon.lambda.powertools.validation.ValidationConfig ; import software.amazon.lambda.powertools.validation.Validation ; static { ValidationConfig . get (). addFunction ( new XMLFunction ()); } public class MyXMLEventHandler implements RequestHandler < MyEventWithXML , String > { @Override @Validation ( inboundSchema = \"classpath:/schema.json\" , envelope = \"powertools_xml(path.to.xml_data)\" ) public String handleRequest ( MyEventWithXML myEvent , Context context ) { return \"OK\" ; } } Change the schema version \u00b6 By default, powertools-validation is configured with V7 . You can use the ValidationConfig to change that behaviour. Handler with custom schema version 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ... import software.amazon.lambda.powertools.validation.ValidationConfig ; import software.amazon.lambda.powertools.validation.Validation ; static { ValidationConfig . get (). setSchemaVersion ( SpecVersion . VersionFlag . V4 ); } public class MyXMLEventHandler implements RequestHandler < MyEventWithXML , String > { @Override @Validation ( inboundSchema = \"classpath:/schema.json\" , envelope = \"powertools_xml(path.to.xml_data)\" ) public String handleRequest ( MyEventWithXML myEvent , Context context ) { return \"OK\" ; } } Advanced ObjectMapper settings \u00b6 If you need to configure the Jackson ObjectMapper, you can use the ValidationConfig : Handler with custom ObjectMapper 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ... import software.amazon.lambda.powertools.validation.ValidationConfig ; import software.amazon.lambda.powertools.validation.Validation ; static { ObjectMapper objectMapper = ValidationConfig . get (). getObjectMapper (); // update (de)serializationConfig or other properties } public class MyXMLEventHandler implements RequestHandler < MyEventWithXML , String > { @Override @Validation ( inboundSchema = \"classpath:/schema.json\" , envelope = \"powertools_xml(path.to.xml_data)\" ) public String handleRequest ( MyEventWithXML myEvent , Context context ) { return \"OK\" ; } }","title":"Validation"},{"location":"utilities/validation/#install","text":"To install this utility, add the following dependency to your project. Maven Gradle 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 <dependencies> ... <dependency> <groupId> com.amazonaws </groupId> <artifactId> powertools-validation </artifactId> <version> 1.10.3 </version> </dependency> ... </dependencies> <!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --> <build> <plugins> ... <plugin> <groupId> org.codehaus.mojo </groupId> <artifactId> aspectj-maven-plugin </artifactId> <version> 1.14.0 </version> <configuration> <source> 1.8 </source> <target> 1.8 </target> <complianceLevel> 1.8 </complianceLevel> <aspectLibraries> <aspectLibrary> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-validation </artifactId> </aspectLibrary> </aspectLibraries> </configuration> <executions> <execution> <goals> <goal> compile </goal> </goals> </execution> </executions> </plugin> ... </plugins> </build> 1 2 3 4 5 6 7 8 9 10 11 12 plugins { id 'java' id 'io.freefair.aspectj.post-compile-weaving' version '6.3.0' } repositories { mavenCentral () } dependencies { aspect 'software.amazon.lambda:powertools-validation:1.10.3' }","title":"Install"},{"location":"utilities/validation/#validating-events","text":"You can validate inbound and outbound events using @Validation annotation. You can also use the Validator#validate() methods, if you want more control over the validation process such as handling a validation error. We support JSON schema version 4, 6, 7 and 201909 (from jmespath-jackson library ).","title":"Validating events"},{"location":"utilities/validation/#validation-annotation","text":"@Validation annotation is used to validate either inbound events or functions' response. It will fail fast with ValidationException if an event or response doesn't conform with given JSON Schema. While it is easier to specify a json schema file in the classpath (using the notation \"classpath:/path/to/schema.json\" ), you can also provide a JSON String containing the schema. MyFunctionHandler.java 1 2 3 4 5 6 7 8 9 10 11 import software.amazon.lambda.powertools.validation.Validation ; public class MyFunctionHandler implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Override @Validation ( inboundSchema = \"classpath:/schema_in.json\" , outboundSchema = \"classpath:/schema_out.json\" ) public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { // ... return something ; } } NOTE : It's not a requirement to validate both inbound and outbound schemas - You can either use one, or both.","title":"Validation annotation"},{"location":"utilities/validation/#validate-function","text":"Validate standalone function is used within the Lambda handler, or any other methods that perform data validation. You can also gracefully handle schema validation errors by catching ValidationException . MyFunctionHandler.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import static software.amazon.lambda.powertools.validation.ValidationUtils.* ; public class MyFunctionHandler implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Override public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { try { validate ( input , \"classpath:/schema.json\" ); } catch ( ValidationException ex ) { // do something before throwing it throw ex ; } // ... return something ; } } NOTE : Schemas are stored in memory for reuse, to avoid loading them from file each time.","title":"Validate function"},{"location":"utilities/validation/#built-in-events-and-responses","text":"For the following events and responses, the Validator will automatically perform validation on the content. Events Type of event Class Path to content API Gateway REST APIGatewayProxyRequestEvent body API Gateway HTTP APIGatewayV2HTTPEvent body Application Load Balancer ApplicationLoadBalancerRequestEvent body Cloudformation Custom Resource CloudFormationCustomResourceEvent resourceProperties CloudWatch Logs CloudWatchLogsEvent awslogs.powertools_base64_gzip(data) EventBridge / Cloudwatch ScheduledEvent detail Kafka KafkaEvent records[*][*].value Kinesis KinesisEvent Records[*].kinesis.powertools_base64(data) Kinesis Firehose KinesisFirehoseEvent Records[*].powertools_base64(data) Kinesis Analytics from Firehose KinesisAnalyticsFirehoseInputPreprocessingEvent Records[*].powertools_base64(data) Kinesis Analytics from Streams KinesisAnalyticsStreamsInputPreprocessingEvent Records[*].powertools_base64(data) SNS SNSEvent Records[*].Sns.Message SQS SQSEvent Records[*].body Responses Type of response Class Path to content (envelope) API Gateway REST APIGatewayProxyResponseEvent} body API Gateway HTTP APIGatewayV2HTTPResponse} body API Gateway WebSocket APIGatewayV2WebSocketResponse} body Load Balancer ApplicationLoadBalancerResponseEvent} body Kinesis Analytics KinesisAnalyticsInputPreprocessingResponse} `Records[*].powertools_base64(data)``","title":"Built-in events and responses"},{"location":"utilities/validation/#custom-events-and-responses","text":"You can also validate any Event or Response type, once you have the appropriate schema. Sometimes, you might want to validate only a portion of it - This is where the envelope parameter is for. Envelopes are JMESPath expressions to extract a portion of JSON you want before applying JSON Schema validation. MyCustomEventHandler.java my_custom_event_schema.json 1 2 3 4 5 6 7 8 9 10 11 import software.amazon.lambda.powertools.validation.Validation ; public class MyCustomEventHandler implements RequestHandler < MyCustomEvent , String > { @Override @Validation ( inboundSchema = \"classpath:/my_custom_event_schema.json\" , envelope = \"basket.products[*]\" ) public String handleRequest ( MyCustomEvent input , Context context ) { return \"OK\" ; } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 { \"basket\" : { \"products\" : [ { \"id\" : 43242 , \"name\" : \"FooBar XY\" , \"price\" : 258 }, { \"id\" : 765 , \"name\" : \"BarBaz AB\" , \"price\" : 43.99 } ] } } This is quite powerful because you can use JMESPath Query language to extract records from arrays, slice and dice , to pipe expressions and function expressions, where you'd extract what you need before validating the actual payload.","title":"Custom events and responses"},{"location":"utilities/validation/#jmespath-functions","text":"JMESPath functions ensure to make an operation on a specific part of the json.validate Powertools provides two built-in functions:","title":"JMESPath functions"},{"location":"utilities/validation/#powertools_base64-function","text":"Use powertools_base64 function to decode any base64 data. Below sample will decode the base64 value within the data key, and decode the JSON string into a valid JSON before we can validate it. MyEventHandler.java schema.json 1 2 3 4 5 6 7 8 9 10 import software.amazon.lambda.powertools.validation.ValidationUtils ; public class MyEventHandler implements RequestHandler < MyEvent , String > { @Override public String handleRequest ( MyEvent myEvent , Context context ) { validate ( myEvent , \"classpath:/schema.json\" , \"powertools_base64(data)\" ); return \"OK\" ; } } 1 2 3 { \"data\" : \"ewogICJpZCI6IDQzMjQyLAogICJuYW1lIjogIkZvb0JhciBYWSIsCiAgInByaWNlIjogMjU4Cn0=\" }","title":"powertools_base64 function"},{"location":"utilities/validation/#powertools_base64_gzip-function","text":"Use powertools_base64_gzip function to decompress and decode base64 data. Below sample will decompress and decode base64 data. MyEventHandler.java schema.json 1 2 3 4 5 6 7 8 9 10 import software.amazon.lambda.powertools.validation.ValidationUtils ; public class MyEventHandler implements RequestHandler < MyEvent , String > { @Override public String handleRequest ( MyEvent myEvent , Context context ) { validate ( myEvent , \"classpath:/schema.json\" , \"powertools_base64_gzip(data)\" ); return \"OK\" ; } } 1 2 3 { \"data\" : \"H4sIAAAAAAAA/6vmUlBQykxRslIwMTYyMdIBcfMSc1OBAkpu+flOiUUKEZFKYOGCosxkkLiRqQVXLQDnWo6bOAAAAA==\" } Note You don't need any function to transform a JSON String into a JSON object, powertools-validation will do it for you. In the 2 previous example, data contains JSON. Just provide the function to transform the base64 / gzipped / ... string into a clear JSON string.","title":"powertools_base64_gzip function"},{"location":"utilities/validation/#bring-your-own-jmespath-function","text":"Warning This should only be used for advanced use cases where you have special formats not covered by the built-in functions. New functions will be added to the 2 built-in ones. Your function must extend io.burt.jmespath.function.BaseFunction , take a String as parameter and return a String. You can read the doc for more information. Below is an example that takes some xml and transform it into json. Once your function is created, you need to add it to powertools.You can then use it to do your validation or using annotation. XMLFunction.java Handler with validation API Handler with validation annotation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class XMLFunction extends BaseFunction { public Base64Function () { super ( \"powertools_xml\" , ArgumentConstraints . typeOf ( JmesPathType . STRING )); } @Override protected < T > T callFunction ( Adapter < T > runtime , List < FunctionArgument < T >> arguments ) { T value = arguments . get ( 0 ). value (); String xmlString = runtime . toString ( value ); String jsonString = // ... transform xmlString to json return runtime . createString ( jsonString ); } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ... import software.amazon.lambda.powertools.validation.ValidationConfig ; import software.amazon.lambda.powertools.validation.ValidationUtils.validate ; static { ValidationConfig . get (). addFunction ( new XMLFunction ()); } public class MyXMLEventHandler implements RequestHandler < MyEventWithXML , String > { @Override public String handleRequest ( MyEventWithXML myEvent , Context context ) { validate ( myEvent , \"classpath:/schema.json\" , \"powertools_xml(path.to.xml_data)\" ); return \"OK\" ; } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ... import software.amazon.lambda.powertools.validation.ValidationConfig ; import software.amazon.lambda.powertools.validation.Validation ; static { ValidationConfig . get (). addFunction ( new XMLFunction ()); } public class MyXMLEventHandler implements RequestHandler < MyEventWithXML , String > { @Override @Validation ( inboundSchema = \"classpath:/schema.json\" , envelope = \"powertools_xml(path.to.xml_data)\" ) public String handleRequest ( MyEventWithXML myEvent , Context context ) { return \"OK\" ; } }","title":"Bring your own JMESPath function"},{"location":"utilities/validation/#change-the-schema-version","text":"By default, powertools-validation is configured with V7 . You can use the ValidationConfig to change that behaviour. Handler with custom schema version 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ... import software.amazon.lambda.powertools.validation.ValidationConfig ; import software.amazon.lambda.powertools.validation.Validation ; static { ValidationConfig . get (). setSchemaVersion ( SpecVersion . VersionFlag . V4 ); } public class MyXMLEventHandler implements RequestHandler < MyEventWithXML , String > { @Override @Validation ( inboundSchema = \"classpath:/schema.json\" , envelope = \"powertools_xml(path.to.xml_data)\" ) public String handleRequest ( MyEventWithXML myEvent , Context context ) { return \"OK\" ; } }","title":"Change the schema version"},{"location":"utilities/validation/#advanced-objectmapper-settings","text":"If you need to configure the Jackson ObjectMapper, you can use the ValidationConfig : Handler with custom ObjectMapper 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ... import software.amazon.lambda.powertools.validation.ValidationConfig ; import software.amazon.lambda.powertools.validation.Validation ; static { ObjectMapper objectMapper = ValidationConfig . get (). getObjectMapper (); // update (de)serializationConfig or other properties } public class MyXMLEventHandler implements RequestHandler < MyEventWithXML , String > { @Override @Validation ( inboundSchema = \"classpath:/schema.json\" , envelope = \"powertools_xml(path.to.xml_data)\" ) public String handleRequest ( MyEventWithXML myEvent , Context context ) { return \"OK\" ; } }","title":"Advanced ObjectMapper settings"}]}