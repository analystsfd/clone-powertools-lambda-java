{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Homepage","text":"<p>Powertools is a suite of utilities for AWS Lambda Functions that makes tracing with AWS X-Ray, structured logging and creating custom metrics asynchronously easier.</p> <p>Looking for a quick run through of the core utilities?</p> <p>Check out this detailed blog post with a practical example.</p>"},{"location":"#tenets","title":"Tenets","text":"<p>This project separates core utilities that will be available in other runtimes vs general utilities that might not be available across all runtimes.</p> <ul> <li>AWS Lambda only \u2013 We optimise for AWS Lambda function environments and supported runtimes only. Utilities might work with web frameworks and non-Lambda environments, though they are not officially supported.</li> <li>Eases the adoption of best practices \u2013 The main priority of the utilities is to facilitate best practices adoption, as defined in the AWS Well-Architected Serverless Lens; all other functionality is optional.</li> <li>Keep it lean \u2013 Additional dependencies are carefully considered for security and ease of maintenance, and prevent negatively impacting startup time.</li> <li>We strive for backwards compatibility \u2013 New features and changes should keep backwards compatibility. If a breaking change cannot be avoided, the deprecation and migration process should be clearly defined.</li> <li>We work backwards from the community \u2013 We aim to strike a balance of what would work best for 80% of customers. Emerging practices are considered and discussed via Requests for Comment (RFCs)</li> <li>Progressive -  Utilities are designed to be incrementally adoptable for customers at any stage of their Serverless journey. They follow language idioms and their community\u2019s common practices.</li> </ul>"},{"location":"#install","title":"Install","text":"<p>Powertools dependencies are available in Maven Central. You can use your favourite dependency management tool to install it</p> <ul> <li>Maven</li> <li>Gradle</li> </ul> <p>Quick hello world examples using SAM CLI</p> <p>You can use SAM to quickly setup a serverless project including AWS Lambda Powertools Java.</p> <pre><code>  sam init --location gh:aws-samples/cookiecutter-aws-sam-powertools-java\n</code></pre> <p>For more information about the project and available options refer to this repository</p> MavenGradle <pre><code>&lt;dependencies&gt;\n...\n    &lt;dependency&gt;\n&lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n&lt;artifactId&gt;powertools-tracing&lt;/artifactId&gt;\n&lt;version&gt;1.10.3&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n&lt;artifactId&gt;powertools-logging&lt;/artifactId&gt;\n&lt;version&gt;1.10.3&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n&lt;artifactId&gt;powertools-metrics&lt;/artifactId&gt;\n&lt;version&gt;1.10.3&lt;/version&gt;\n&lt;/dependency&gt;\n...\n&lt;/dependencies&gt;\n...\n&lt;!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --&gt;\n&lt;build&gt;\n&lt;plugins&gt;\n...\n        &lt;plugin&gt;\n&lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;\n&lt;artifactId&gt;aspectj-maven-plugin&lt;/artifactId&gt;\n&lt;version&gt;1.14.0&lt;/version&gt;\n&lt;configuration&gt;\n&lt;source&gt;1.8&lt;/source&gt;\n&lt;target&gt;1.8&lt;/target&gt;\n&lt;complianceLevel&gt;1.8&lt;/complianceLevel&gt;\n&lt;aspectLibraries&gt;\n&lt;aspectLibrary&gt;\n&lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n&lt;artifactId&gt;powertools-tracing&lt;/artifactId&gt;\n&lt;/aspectLibrary&gt;\n&lt;aspectLibrary&gt;\n&lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n&lt;artifactId&gt;powertools-logging&lt;/artifactId&gt;\n&lt;/aspectLibrary&gt;\n&lt;aspectLibrary&gt;\n&lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n&lt;artifactId&gt;powertools-metrics&lt;/artifactId&gt;\n&lt;/aspectLibrary&gt;\n&lt;/aspectLibraries&gt;\n&lt;/configuration&gt;\n&lt;executions&gt;\n&lt;execution&gt;\n&lt;goals&gt;\n&lt;goal&gt;compile&lt;/goal&gt;\n&lt;/goals&gt;\n&lt;/execution&gt;\n&lt;/executions&gt;\n&lt;/plugin&gt;\n...\n    &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> <pre><code>plugins{\nid 'java'\nid 'io.freefair.aspectj.post-compile-weaving' version '6.3.0'\n}\n\nrepositories {\nmavenCentral()\n}\n\ndependencies {\naspect 'software.amazon.lambda:powertools-logging:1.10.3'\naspect 'software.amazon.lambda:powertools-tracing:1.10.3'\naspect 'software.amazon.lambda:powertools-metrics:1.10.3'\n}\n\nsourceCompatibility = 11\ntargetCompatibility = 11\n</code></pre>"},{"location":"#environment-variables","title":"Environment variables","text":"<p>Info</p> <p>Explicit parameters take precedence over environment variables.</p> Environment variable Description Utility POWERTOOLS_SERVICE_NAME Sets service name used for tracing namespace, metrics dimension and structured logging All POWERTOOLS_METRICS_NAMESPACE Sets namespace used for metrics Metrics POWERTOOLS_LOGGER_SAMPLE_RATE Debug log sampling Logging POWERTOOLS_LOG_LEVEL Sets logging level Logging POWERTOOLS_TRACER_CAPTURE_RESPONSE Enables/Disables tracing mode to capture method response Tracing POWERTOOLS_TRACER_CAPTURE_ERROR Enables/Disables tracing mode to capture method error Tracing"},{"location":"FAQs/","title":"FAQs","text":""},{"location":"FAQs/#how-can-i-use-powertools-with-lombok","title":"How can I use Powertools with Lombok?","text":"<p>Poweretools uses <code>aspectj-maven-plugin</code> to compile-time weave (CTW) aspects into the project. In case you want to use <code>Lombok</code> or other compile-time preprocessor for your project, it is required to change <code>aspectj-maven-plugin</code> configuration to enable in-place weaving feature. Otherwise the plugin will ignore changes introduced by <code>Lombok</code> and will use <code>.java</code> files as a source. </p> <p>To enable in-place weaving feature you need to use following <code>aspectj-maven-plugin</code> configuration:</p> <pre><code>&lt;configuration&gt;\n&lt;forceAjcCompile&gt;true&lt;/forceAjcCompile&gt; &lt;sources/&gt;\n&lt;weaveDirectories&gt;\n&lt;weaveDirectory&gt;${project.build.directory}/classes&lt;/weaveDirectory&gt;\n&lt;/weaveDirectories&gt;\n...\n    &lt;aspectLibraries&gt;\n&lt;aspectLibrary&gt;\n&lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n&lt;artifactId&gt;powertools-logging&lt;/artifactId&gt;\n&lt;/aspectLibrary&gt;\n&lt;/aspectLibraries&gt;\n&lt;/configuration&gt;\n</code></pre>"},{"location":"FAQs/#how-can-i-use-powertools-with-kotlin-projects","title":"How can I use Powertools with Kotlin projects?","text":"<p>Poweretools uses <code>aspectj-maven-plugin</code> to compile-time weave (CTW) aspects into the project. When using it with Kotlin projects, it is required to <code>forceAjcCompile</code>.  No explicit configuration should be required for gradle projects. </p> <p>To enable <code>forceAjcCompile</code> you need to use following <code>aspectj-maven-plugin</code> configuration:</p> <pre><code>&lt;configuration&gt;\n&lt;forceAjcCompile&gt;true&lt;/forceAjcCompile&gt; ...\n    &lt;aspectLibraries&gt;\n&lt;aspectLibrary&gt;\n&lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n&lt;artifactId&gt;powertools-logging&lt;/artifactId&gt;\n&lt;/aspectLibrary&gt;\n&lt;/aspectLibraries&gt;\n&lt;/configuration&gt;\n</code></pre>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>This project follows Keep a Changelog format for changes and adheres to Semantic Versioning.</p>"},{"location":"changelog/#unreleased","title":"[Unreleased]","text":""},{"location":"changelog/#1103-2022-02-01","title":"[1.10.3] - 2022-02-01","text":""},{"location":"changelog/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>SQS Batch processing: Prevent message to be marked as success if failed sending to DLQ for non retryable exceptions. #731</li> </ul>"},{"location":"changelog/#documentation","title":"Documentation","text":"<ul> <li>SQS Batch processing: Improve documentation on IAM premissions required by function when using utility with an encrypted SQS queue with customer managed KMS keys.</li> </ul>"},{"location":"changelog/#1102-2022-01-07","title":"[1.10.2] - 2022-01-07","text":"<ul> <li>Tracing: Ability to override object mapper used for serializing method response as trace metadata when enabled. This provides users ability to customize how and what you want to capture as metadata from method response object. #698</li> </ul>"},{"location":"changelog/#1101-2022-01-06","title":"[1.10.1] - 2022-01-06","text":"<ul> <li>Logging: Upgrade Log4j to version 2.17.1 for CVE-2021-44832</li> </ul>"},{"location":"changelog/#1100-2021-12-27","title":"[1.10.0] - 2021-12-27","text":"<ul> <li>Logging: Modern log4j configuration to customise structured logging. Refer docs to start using new config. #670</li> <li>SQS Batch: Support batch size greater than 10. #667</li> </ul>"},{"location":"changelog/#190-2021-12-21","title":"[1.9.0] - 2021-12-21","text":"<ul> <li>Logging: Upgrade Log4j to version 2.17.0 for CVE-2021-45105</li> <li>Tracing: add <code>Service</code> annotation. #654</li> </ul>"},{"location":"changelog/#182-2021-12-15","title":"[1.8.2] - 2021-12-15","text":""},{"location":"changelog/#security","title":"Security","text":"<ul> <li>Upgrading Log4j to version 2.16.0 for CVE-2021-45046</li> </ul>"},{"location":"changelog/#181-2021-12-10","title":"[1.8.1] - 2021-12-10","text":""},{"location":"changelog/#security_1","title":"Security","text":"<ul> <li>Upgrading Log4j to version 2.15.0 for CVE-2021-44228</li> </ul>"},{"location":"changelog/#180-2021-11-05","title":"[1.8.0] - 2021-11-05","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Powertools Cloudformation module (NEW): New module simplifying AWS Lambda-backed custom resources written in Java. #560</li> <li>SQS Large message processing: Ability to override the default <code>S3Client</code> use to fetch payload from S3. #602</li> </ul>"},{"location":"changelog/#regression","title":"Regression","text":"<ul> <li>Logging: <code>@Logging</code> annotation now works with <code>@Tracing</code> annotation on <code>RequestStreamHandler</code> when used in <code>logEvent</code> mode. #567</li> </ul>"},{"location":"changelog/#maintenance","title":"Maintenance","text":"<ul> <li>deps: Bump third party dependencies to the latest versions.</li> </ul>"},{"location":"changelog/#173-2021-09-14","title":"[1.7.3] - 2021-09-14","text":"<ul> <li>SQS Batch processing: Ability to move non retryable message to configured dead letter queue(DLQ). #500</li> </ul>"},{"location":"changelog/#172-2021-08-03","title":"[1.7.2] - 2021-08-03","text":"<ul> <li>Powertools All Modules: Upgrade to the latest(1.14.0) aspectj-maven-plugin which also supports Java 9 and newer versions.  Users no longer need to depend on com.nickwongdev as a workaround. #489</li> <li>Logging: Performance optimisation to improve cold start. #484</li> <li>SQS Batch processing/Large message: Module now lazy loads default SQS client. #484</li> </ul>"},{"location":"changelog/#171-2021-07-06","title":"[1.7.1] - 2021-07-06","text":"<ul> <li>Powertools All Modules: Fix static code analysis violations done via spotbugs (#458).</li> </ul>"},{"location":"changelog/#170-2021-07-05","title":"[1.7.0] - 2021-07-05","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>Logging: Support for extracting Correlation id using <code>@Logging</code> annotation via <code>correlationIdPath</code> attribute and <code>setCorrelationId()</code> method in <code>LoggingUtils</code>(#448).</li> <li>Logging: New <code>clearState</code> attribute on <code>@Logging</code> annotation to clear previously added custom keys upon invocation(#453).</li> </ul>"},{"location":"changelog/#maintenance_1","title":"Maintenance","text":"<ul> <li>deps: Bump third party dependencies to the latest versions.</li> </ul>"},{"location":"changelog/#160-2021-06-21","title":"[1.6.0] - 2021-06-21","text":""},{"location":"changelog/#added_2","title":"Added","text":"<ul> <li>Tracing: Support for Boolean and Number type as value in <code>TracingUtils.putAnnotation()</code>(#423).</li> <li>Logging: API to remove any additional custom key from logger entry using <code>LoggingUtils.removeKeys()</code>(#395).</li> </ul>"},{"location":"changelog/#maintenance_2","title":"Maintenance","text":"<ul> <li>deps: Bump third party dependencies to the latest versions.</li> </ul>"},{"location":"changelog/#150-2021-03-30","title":"[1.5.0] - 2021-03-30","text":"<ul> <li>Metrics: Ability to set multiple dimensions as default dimensions via <code>MetricsUtils.defaultDimensions()</code>.    Introduced in v1.4.0 <code>MetricsUtils.defaultDimensionSet()</code> is deprecated now for better user experience.</li> </ul>"},{"location":"changelog/#140-2021-03-11","title":"[1.4.0] - 2021-03-11","text":"<ul> <li>Metrics: Ability to set default dimension for metrics via <code>MetricsUtils.defaultDimensionSet()</code>.</li> </ul> <p>Note: If your monitoring depends on default dimensions captured before via aws-embedded-metrics-java,    those either need to be updated or has to be explicitly captured via <code>MetricsUtils.defaultDimensionSet()</code>.</p> <ul> <li>Metrics: Remove validation of having minimum one dimension. EMF now support Dimension set being empty as well.</li> </ul>"},{"location":"changelog/#130-2021-03-05","title":"[1.3.0] - 2021-03-05","text":"<ul> <li>Powertools: It now works out of the box with code guru profile handler implementation.</li> <li>Logging: Ability to override object mapper used for logging event. This provides customers ability to customize how and what they want to log from event.</li> <li>Metrics: Module now by default captures AWS Request id as property if used together with Metrics annotation. It will also capture Xray Trace ID as property if tracing is enabled. This ensures good observability and tracing.</li> <li>Metrics:<code>withSingleMetric</code> from `MetricsUtils can now pick the default namespace specified either on Metrics annotation or via POWERTOOLS_METRICS_NAMESPACE env var, without need to specify explicitly for each call.</li> <li>Metrics:<code>Metrics</code> annotation captures metrics even in case of unhandled exception from Lambda function.</li> <li>Docs: Migrated from Gatsby to MKdocs documentation system</li> </ul>"},{"location":"core/logging/","title":"Logging","text":"<p>Logging provides an opinionated logger with output structured as JSON.</p> <p>Key features</p> <ul> <li>Capture key fields from Lambda context, cold start and structures logging output as JSON</li> <li>Log Lambda event when instructed, disabled by default, can be enabled explicitly via annotation param</li> <li>Append additional keys to structured log at any point in time</li> </ul>"},{"location":"core/logging/#initialization","title":"Initialization","text":"<p>Powertools extends the functionality of Log4J. Below is an example <code>log4j2.xml</code> file, with the <code>JsonTemplateLayout</code> using <code>LambdaJsonLayout.json</code> configured. </p> <p>LambdaJsonLayout is now deprecated</p> <p>Configuring utiltiy using <code>&lt;LambdaJsonLayout/&gt;</code> plugin is deprecated now. While utility still supports the old configuration, we strongly recommend upgrading the  <code>log4j2.xml</code> configuration to <code>JsonTemplateLayout</code> instead. JsonTemplateLayout is recommended way of doing structured logging.</p> <p>Please follow this guide for upgrade steps.</p> log4j2.xml <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;Configuration&gt;\n&lt;Appenders&gt;\n&lt;Console name=\"JsonAppender\" target=\"SYSTEM_OUT\"&gt;\n&lt;JsonTemplateLayout eventTemplateUri=\"classpath:LambdaJsonLayout.json\" /&gt;\n&lt;/Console&gt;\n&lt;/Appenders&gt;\n&lt;Loggers&gt;\n&lt;Logger name=\"JsonLogger\" level=\"INFO\" additivity=\"false\"&gt;\n&lt;AppenderRef ref=\"JsonAppender\"/&gt;\n&lt;/Logger&gt;\n&lt;Root level=\"info\"&gt;\n&lt;AppenderRef ref=\"JsonAppender\"/&gt;\n&lt;/Root&gt;\n&lt;/Loggers&gt;\n&lt;/Configuration&gt;\n</code></pre> <p>You can also override log level by setting <code>POWERTOOLS_LOG_LEVEL</code> env var. Here is an example using AWS Serverless Application Model (SAM)</p> template.yaml <pre><code>Resources:\nHelloWorldFunction:\nType: AWS::Serverless::Function\nProperties:\n...\nRuntime: java8\nEnvironment:\nVariables:\nPOWERTOOLS_LOG_LEVEL: DEBUG\nPOWERTOOLS_SERVICE_NAME: example\n</code></pre> <p>You can also explicitly set a service name via <code>POWERTOOLS_SERVICE_NAME</code> env var. This sets service key that will be present across all log statements.</p>"},{"location":"core/logging/#standard-structured-keys","title":"Standard structured keys","text":"<p>Your logs will always include the following keys to your structured logging:</p> Key Type Example Description timestamp String \"2020-05-24 18:17:33,774\" Timestamp of actual log statement level String \"INFO\" Logging level coldStart Boolean true ColdStart value. service String \"payment\" Service name defined. \"service_undefined\" will be used if unknown samplingRate int 0.1 Debug logging sampling rate in percentage e.g. 10% in this case message String \"Collecting payment\" Log statement value. Unserializable JSON values will be casted to string functionName String \"example-powertools-HelloWorldFunction-1P1Z6B39FLU73\" functionVersion String \"12\" functionMemorySize String \"128\" functionArn String \"arn:aws:lambda:eu-west-1:012345678910:function:example-powertools-HelloWorldFunction-1P1Z6B39FLU73\" xray_trace_id String \"1-5759e988-bd862e3fe1be46a994272793\" X-Ray Trace ID when Lambda function has enabled Tracing function_request_id String \"899856cb-83d1-40d7-8611-9e78f15f32f4\"\" AWS Request ID from lambda context"},{"location":"core/logging/#capturing-context-lambda-info","title":"Capturing context Lambda info","text":"<p>You can enrich your structured logs with key Lambda context information via <code>logEvent</code> annotation parameter.  You can also explicitly log any incoming event using <code>logEvent</code> param. Refer Override default object mapper  to customise what is logged.</p> <p>Warning</p> <p>Log event is disabled by default to prevent sensitive info being logged.</p> App.javaAppLogEvent.java <pre><code>import org.apache.logging.log4j.LogManager;\nimport org.apache.logging.log4j.Logger;\nimport software.amazon.lambda.powertools.logging.LoggingUtils;\nimport software.amazon.lambda.powertools.logging.Logging;\n...\n\n/**\n * Handler for requests to Lambda function.\n */\npublic class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\nLogger log = LogManager.getLogger();\n\n@Logging\npublic APIGatewayProxyResponseEvent handleRequest(final APIGatewayProxyRequestEvent input, final Context context) {\n...\n}\n}\n</code></pre> <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class AppLogEvent implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\nLogger log = LogManager.getLogger();\n\n@Logging(logEvent = true)\npublic APIGatewayProxyResponseEvent handleRequest(final APIGatewayProxyRequestEvent input, final Context context) {\n...\n}\n}\n</code></pre>"},{"location":"core/logging/#customising-fields-in-logs","title":"Customising  fields in logs","text":"<ul> <li>Utility by default emits <code>timestamp</code> field in the logs in format <code>yyyy-MM-dd'T'HH:mm:ss.SSSZz</code> and in system default timezone.  If you need to customize format and timezone, you can do so by configuring <code>log4j2.component.properties</code> and configuring properties as shown in example below:</li> </ul> log4j2.component.properties <pre><code>log4j.layout.jsonTemplate.timestampFormatPattern=yyyy-MM-dd'T'HH:mm:ss.SSSZz\nlog4j.layout.jsonTemplate.timeZone=Europe/Oslo\n</code></pre> <ul> <li> <p>Utility also provides sample template for Elastic Common Schema(ECS) layout. The field emitted in logs will follow specs from ECS together with field captured by utility as mentioned above.</p> <p>Use <code>LambdaEcsLayout.json</code> as <code>eventTemplateUri</code> when configuring <code>JsonTemplateLayout</code>.</p> </li> </ul> log4j2.xml <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;Configuration&gt;\n&lt;Appenders&gt;\n&lt;Console name=\"JsonAppender\" target=\"SYSTEM_OUT\"&gt;\n&lt;JsonTemplateLayout eventTemplateUri=\"classpath:LambdaEcsLayout.json\" /&gt;\n&lt;/Console&gt;\n&lt;/Appenders&gt;\n&lt;Loggers&gt;\n&lt;Logger name=\"JsonLogger\" level=\"INFO\" additivity=\"false\"&gt;\n&lt;AppenderRef ref=\"JsonAppender\"/&gt;\n&lt;/Logger&gt;\n&lt;Root level=\"info\"&gt;\n&lt;AppenderRef ref=\"JsonAppender\"/&gt;\n&lt;/Root&gt;\n&lt;/Loggers&gt;\n&lt;/Configuration&gt;\n</code></pre>"},{"location":"core/logging/#setting-a-correlation-id","title":"Setting a Correlation ID","text":"<p>You can set a Correlation ID using <code>correlationIdPath</code> attribute by passing a JSON Pointer expression.</p> App.javaExample EventExample CloudWatch Logs excerpt <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\nLogger log = LogManager.getLogger();\n\n@Logging(correlationIdPath = \"/headers/my_request_id_header\")\npublic APIGatewayProxyResponseEvent handleRequest(final APIGatewayProxyRequestEvent input, final Context context) {\n...\nlog.info(\"Collecting payment\")\n...\n}\n}\n</code></pre> <pre><code>{\n\"headers\": {\n\"my_request_id_header\": \"correlation_id_value\"\n}\n}\n</code></pre> <pre><code>{\n\"level\": \"INFO\",\n\"message\": \"Collecting payment\",\n\"timestamp\": \"2021-05-03 11:47:12,494+0200\",\n\"service\": \"payment\",\n\"coldStart\": true,\n\"functionName\": \"test\",\n\"functionMemorySize\": 128,\n\"functionArn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n\"lambda_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\",\n\"correlation_id\": \"correlation_id_value\"\n}\n</code></pre> <p>We provide built-in JSON Pointer expression  for known event sources, where either a request ID or X-Ray Trace ID are present.</p> App.javaExample EventExample CloudWatch Logs excerpt <pre><code>import software.amazon.lambda.powertools.logging.CorrelationIdPathConstants;\n\n/**\n * Handler for requests to Lambda function.\n */\npublic class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\nLogger log = LogManager.getLogger();\n\n@Logging(correlationIdPath = CorrelationIdPathConstants.API_GATEWAY_REST)\npublic APIGatewayProxyResponseEvent handleRequest(final APIGatewayProxyRequestEvent input, final Context context) {\n...\nlog.info(\"Collecting payment\")\n...\n}\n}\n</code></pre> <pre><code>{\n\"requestContext\": {\n\"requestId\": \"correlation_id_value\"\n}\n}\n</code></pre> <pre><code>{\n\"level\": \"INFO\",\n\"message\": \"Collecting payment\",\n\"timestamp\": \"2021-05-03 11:47:12,494+0200\",\n\"service\": \"payment\",\n\"coldStart\": true,\n\"functionName\": \"test\",\n\"functionMemorySize\": 128,\n\"functionArn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n\"lambda_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\",\n\"correlation_id\": \"correlation_id_value\"\n}\n</code></pre>"},{"location":"core/logging/#appending-additional-keys","title":"Appending additional keys","text":"<p>Custom keys are persisted across warm invocations<p>Always set additional keys as part of your handler to ensure they have the latest value, or explicitly clear them with <code>clearState=true</code>.</p> </p> <p>You can append your own keys to your existing logs via <code>appendKey</code>.</p> App.java <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\nLogger log = LogManager.getLogger();\n\n@Logging(logEvent = true)\npublic APIGatewayProxyResponseEvent handleRequest(final APIGatewayProxyRequestEvent input, final Context context) {\n...\nLoggingUtils.appendKey(\"test\", \"willBeLogged\");\n...\n\n...\nMap&lt;String, String&gt; customKeys = new HashMap&lt;&gt;();\ncustomKeys.put(\"test\", \"value\");\ncustomKeys.put(\"test1\", \"value1\");\n\nLoggingUtils.appendKeys(customKeys);\n...\n}\n}\n</code></pre>"},{"location":"core/logging/#removing-additional-keys","title":"Removing additional keys","text":"<p>You can remove any additional key from entry using <code>LoggingUtils.removeKeys()</code>.</p> App.java <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\nLogger log = LogManager.getLogger();\n\n@Logging(logEvent = true)\npublic APIGatewayProxyResponseEvent handleRequest(final APIGatewayProxyRequestEvent input, final Context context) {\n...\nLoggingUtils.appendKey(\"test\", \"willBeLogged\");\n...\nMap&lt;String, String&gt; customKeys = new HashMap&lt;&gt;();\ncustomKeys.put(\"test1\", \"value\");\ncustomKeys.put(\"test2\", \"value1\");\n\nLoggingUtils.appendKeys(customKeys);\n...\nLoggingUtils.removeKey(\"test\");\nLoggingUtils.removeKeys(\"test1\", \"test2\");\n...\n}\n}\n</code></pre>"},{"location":"core/logging/#clearing-all-state","title":"Clearing all state","text":"<p>Logger is commonly initialized in the global scope. Due to Lambda Execution Context reuse,  this means that custom keys can be persisted across invocations. If you want all custom keys to be deleted, you can use  <code>clearState=true</code> attribute on <code>@Logging</code> annotation.</p> App.java#1 Request#2 Request <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\nLogger log = LogManager.getLogger();\n\n@Logging(clearState = true)\npublic APIGatewayProxyResponseEvent handleRequest(final APIGatewayProxyRequestEvent input, final Context context) {\n...\nif(input.getHeaders().get(\"someSpecialHeader\")) {\nLoggingUtils.appendKey(\"specialKey\", \"value\");\n}\n\nlog.info(\"Collecting payment\");\n...\n}\n}\n</code></pre> <pre><code>{\n\"level\": \"INFO\",\n\"message\": \"Collecting payment\",\n\"timestamp\": \"2021-05-03 11:47:12,494+0200\",\n\"service\": \"payment\",\n\"coldStart\": true,\n\"functionName\": \"test\",\n\"functionMemorySize\": 128,\n\"functionArn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n\"lambda_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\",\n\"specialKey\": \"value\"\n}\n</code></pre> <pre><code>{\n\"level\": \"INFO\",\n\"message\": \"Collecting payment\",\n\"timestamp\": \"2021-05-03 11:47:12,494+0200\",\n\"service\": \"payment\",\n\"coldStart\": true,\n\"functionName\": \"test\",\n\"functionMemorySize\": 128,\n\"functionArn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n\"lambda_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n}\n</code></pre>"},{"location":"core/logging/#override-default-object-mapper","title":"Override default object mapper","text":"<p>You can optionally choose to override default object mapper which is used to serialize lambda function events. You might want to supply custom object mapper in order to control how serialisation is done, for example, when you want to log only specific fields from received event due to security.</p> App.java <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\nLogger log = LogManager.getLogger();\n\nstatic {\nObjectMapper objectMapper = new ObjectMapper();\nLoggingUtils.defaultObjectMapper(objectMapper);\n}\n\n@Logging(logEvent = true)\npublic APIGatewayProxyResponseEvent handleRequest(final APIGatewayProxyRequestEvent input, final Context context) {\n...\n}\n}\n</code></pre>"},{"location":"core/logging/#sampling-debug-logs","title":"Sampling debug logs","text":"<p>You can dynamically set a percentage of your logs to DEBUG level via env var <code>POWERTOOLS_LOGGER_SAMPLE_RATE</code> or via <code>samplingRate</code> attribute on annotation. </p> <p>Info</p> <p>Configuration on environment variable is given precedence over sampling rate configuration on annotation, provided it's in valid value range.</p> Sampling via annotation attributeSampling via environment variable <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\nLogger log = LogManager.getLogger();\n\n@Logging(samplingRate = 0.5)\npublic APIGatewayProxyResponseEvent handleRequest(final APIGatewayProxyRequestEvent input, final Context context) {\n...\n}\n}\n</code></pre> <pre><code>Resources:\nHelloWorldFunction:\nType: AWS::Serverless::Function\nProperties:\n...\nRuntime: java8\nEnvironment:\nVariables:\nPOWERTOOLS_LOGGER_SAMPLE_RATE: 0.5\n</code></pre>"},{"location":"core/logging/#upgrade-to-jsontemplatelayout-from-deprecated-lambdajsonlayout-configuration-in-log4j2xml","title":"Upgrade to JsonTemplateLayout from deprecated LambdaJsonLayout configuration in log4j2.xml","text":"<p>Prior to version 1.10.0, only supported way of configuring <code>log4j2.xml</code> was via  <code>&lt;LambdaJsonLayout/&gt;</code>. This plugin is  deprecated now and will be removed in future version. Switching to <code>JsonTemplateLayout</code> is straight forward. </p> <p>Below examples shows deprecated and new configuration of <code>log4j2.xml</code>.</p> Deprecated configuration of log4j2.xmlNew configuration of log4j2.xml <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;Configuration&gt;\n&lt;Appenders&gt;\n&lt;Console name=\"JsonAppender\" target=\"SYSTEM_OUT\"&gt;\n&lt;LambdaJsonLayout compact=\"true\" eventEol=\"true\"/&gt;\n&lt;/Console&gt;\n&lt;/Appenders&gt;\n&lt;Loggers&gt;\n&lt;Logger name=\"JsonLogger\" level=\"INFO\" additivity=\"false\"&gt;\n&lt;AppenderRef ref=\"JsonAppender\"/&gt;\n&lt;/Logger&gt;\n&lt;Root level=\"info\"&gt;\n&lt;AppenderRef ref=\"JsonAppender\"/&gt;\n&lt;/Root&gt;\n&lt;/Loggers&gt;\n&lt;/Configuration&gt;\n</code></pre> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;Configuration&gt;\n&lt;Appenders&gt;\n&lt;Console name=\"JsonAppender\" target=\"SYSTEM_OUT\"&gt;\n&lt;JsonTemplateLayout eventTemplateUri=\"classpath:LambdaJsonLayout.json\" /&gt;\n&lt;/Console&gt;\n&lt;/Appenders&gt;\n&lt;Loggers&gt;\n&lt;Logger name=\"JsonLogger\" level=\"INFO\" additivity=\"false\"&gt;\n&lt;AppenderRef ref=\"JsonAppender\"/&gt;\n&lt;/Logger&gt;\n&lt;Root level=\"info\"&gt;\n&lt;AppenderRef ref=\"JsonAppender\"/&gt;\n&lt;/Root&gt;\n&lt;/Loggers&gt;\n&lt;/Configuration&gt;\n</code></pre>"},{"location":"core/metrics/","title":"Metrics","text":"<p>Metrics creates custom metrics asynchronously by logging metrics to standard output following Amazon CloudWatch Embedded Metric Format (EMF).</p> <p>These metrics can be visualized through Amazon CloudWatch Console.</p> <p>Key features</p> <ul> <li>Aggregate up to 100 metrics using a single CloudWatch EMF object (large JSON blob).</li> <li>Validate against common metric definitions mistakes (metric unit, values, max dimensions, max metrics, etc).</li> <li>Metrics are created asynchronously by the CloudWatch service, no custom stacks needed.</li> <li>Context manager to create a one off metric with a different dimension.</li> </ul>"},{"location":"core/metrics/#terminologies","title":"Terminologies","text":"<p>If you're new to Amazon CloudWatch, there are two terminologies you must be aware of before using this utility:</p> <ul> <li>Namespace. It's the highest level container that will group multiple metrics from multiple services for a given application, for example <code>ServerlessEcommerce</code>.</li> <li>Dimensions. Metrics metadata in key-value format. They help you slice and dice metrics visualization, for example <code>ColdStart</code> metric by Payment <code>service</code>.</li> </ul> Metric terminology, visually explained"},{"location":"core/metrics/#getting-started","title":"Getting started","text":"<p>Metric has two global settings that will be used across all metrics emitted:</p> Setting Description Environment variable Constructor parameter Metric namespace Logical container where all metrics will be placed e.g. <code>ServerlessAirline</code> <code>POWERTOOLS_METRICS_NAMESPACE</code> <code>namespace</code> Service Optionally, sets service metric dimension across all metrics e.g. <code>payment</code> <code>POWERTOOLS_SERVICE_NAME</code> <code>service</code> <p>Use your application or main service as the metric namespace to easily group all metrics</p> template.yamlMetricsEnabledHandler.java <pre><code>Resources:\nHelloWorldFunction:\nType: AWS::Serverless::Function\nProperties:\n...\nRuntime: java8\nEnvironment:\nVariables:\nPOWERTOOLS_SERVICE_NAME: payment\nPOWERTOOLS_METRICS_NAMESPACE: ServerlessAirline\n</code></pre> <pre><code>import software.amazon.lambda.powertools.metrics.Metrics;\n\npublic class MetricsEnabledHandler implements RequestHandler&lt;Object, Object&gt; {\n\nMetricsLogger metricsLogger = MetricsUtils.metricsLogger();\n\n@Override\n@Metrics(namespace = \"ExampleApplication\", service = \"booking\")\npublic Object handleRequest(Object input, Context context) {\n...\n}\n}\n</code></pre> <p>You can initialize Metrics anywhere in your code as many times as you need - It'll keep track of your aggregate metrics in memory.</p>"},{"location":"core/metrics/#creating-metrics","title":"Creating metrics","text":"<p>You can create metrics using <code>putMetric</code>, and manually create dimensions for all your aggregate metrics using <code>putDimensions</code>.</p> MetricsEnabledHandler.java <pre><code>import software.amazon.lambda.powertools.metrics.Metrics;\nimport software.amazon.cloudwatchlogs.emf.logger.MetricsLogger;\n\npublic class MetricsEnabledHandler implements RequestHandler&lt;Object, Object&gt; {\n\nMetricsLogger metricsLogger = MetricsUtils.metricsLogger();\n\n@Override\n@Metrics(namespace = \"ExampleApplication\", service = \"booking\")\npublic Object handleRequest(Object input, Context context) {\nmetricsLogger.putDimensions(DimensionSet.of(\"environment\", \"prod\"));\nmetricsLogger.putMetric(\"SuccessfulBooking\", 1, Unit.COUNT);\n...\n}\n}\n</code></pre> <p>The <code>Unit</code> enum facilitate finding a supported metric unit by CloudWatch.</p> <p>Metrics overflow</p> <p>CloudWatch EMF supports a max of 100 metrics. Metrics utility will flush all metrics when adding the 100th metric while subsequent metrics will be aggregated into a new EMF object, for your convenience.</p>"},{"location":"core/metrics/#flushing-metrics","title":"Flushing metrics","text":"<p>The <code>@Metrics</code> annotation validates, serializes, and flushes all your metrics. During metrics validation,  if no metrics are provided no exception will be raised. If metrics are provided, and any of the following criteria are  not met, <code>ValidationException</code> exception will be raised.</p> <p>Metric validation</p> <ul> <li>Maximum of 9 dimensions</li> </ul> <p>If you want to ensure that at least one metric is emitted, you can pass <code>raiseOnEmptyMetrics = true</code> to the @Metrics annotation:</p> MetricsRaiseOnEmpty.java <pre><code>import software.amazon.lambda.powertools.metrics.Metrics;\n\npublic class MetricsRaiseOnEmpty implements RequestHandler&lt;Object, Object&gt; {\n\n@Override\n@Metrics(raiseOnEmptyMetrics = true)\npublic Object handleRequest(Object input, Context context) {\n...\n}\n}\n</code></pre>"},{"location":"core/metrics/#capturing-cold-start-metric","title":"Capturing cold start metric","text":"<p>You can capture cold start metrics automatically with <code>@Metrics</code> via the <code>captureColdStart</code> variable.</p> MetricsColdStart.java <pre><code>import software.amazon.lambda.powertools.metrics.Metrics;\n\npublic class MetricsColdStart implements RequestHandler&lt;Object, Object&gt; {\n\n@Override\n@Metrics(captureColdStart = true)\npublic Object handleRequest(Object input, Context context) {\n...\n}\n}\n</code></pre> <p>If it's a cold start invocation, this feature will:</p> <ul> <li>Create a separate EMF blob solely containing a metric named <code>ColdStart</code></li> <li>Add <code>FunctionName</code> and <code>Service</code> dimensions</li> </ul> <p>This has the advantage of keeping cold start metric separate from your application metrics.</p>"},{"location":"core/metrics/#advanced","title":"Advanced","text":""},{"location":"core/metrics/#adding-metadata","title":"Adding metadata","text":"<p>You can use <code>putMetadata</code> for advanced use cases, where you want to metadata as part of the serialized metrics object.</p> <p>Info</p> <p>This will not be available during metrics visualization, use <code>dimensions</code> for this purpose.</p> App.java <pre><code>import software.amazon.lambda.powertools.metrics.Metrics;\nimport software.amazon.cloudwatchlogs.emf.logger.MetricsLogger;\n\npublic class App implements RequestHandler&lt;Object, Object&gt; {\n\n@Override\n@Metrics(namespace = \"ServerlessAirline\", service = \"payment\")\npublic Object handleRequest(Object input, Context context) {\nmetricsLogger().putMetric(\"CustomMetric1\", 1, Unit.COUNT);\nmetricsLogger().putMetadata(\"booking_id\", \"1234567890\");\n...\n}\n}\n</code></pre> <p>This will be available in CloudWatch Logs to ease operations on high cardinal data.</p>"},{"location":"core/metrics/#overriding-default-dimension-set","title":"Overriding default dimension set","text":"<p>By default, all metrics emitted via module captures <code>Service</code> as one of the default dimension. This is either specified via <code>POWERTOOLS_SERVICE_NAME</code> environment variable or via <code>service</code> attribute on <code>Metrics</code> annotation. If you wish to override the default  Dimension, it can be done via <code>MetricsUtils.defaultDimensions()</code>.</p> App.java <pre><code>import software.amazon.lambda.powertools.metrics.Metrics;\nimport static software.amazon.lambda.powertools.metrics.MetricsUtils;\n\npublic class App implements RequestHandler&lt;Object, Object&gt; {\n\nMetricsLogger metricsLogger = MetricsUtils.metricsLogger();\n\nstatic {\nMetricsUtils.defaultDimensions(DimensionSet.of(\"CustomDimension\", \"booking\"));\n}\n@Override\n@Metrics(namespace = \"ExampleApplication\", service = \"booking\")\npublic Object handleRequest(Object input, Context context) {\n...\nMetricsUtils.withSingleMetric(\"Metric2\", 1, Unit.COUNT, log -&gt; {});\n}\n}\n</code></pre>"},{"location":"core/metrics/#creating-a-metric-with-a-different-dimension","title":"Creating a metric with a different dimension","text":"<p>CloudWatch EMF uses the same dimensions across all your metrics. Use <code>withSingleMetric</code> if you have a metric that should have different dimensions.</p> <p>Info</p> <p>Generally, this would be an edge case since you pay for unique metric. Keep the following formula in mind: unique metric = (metric_name + dimension_name + dimension_value)</p> App.java <pre><code>import static software.amazon.lambda.powertools.metrics.MetricsUtils.withSingleMetric;\n\npublic class App implements RequestHandler&lt;Object, Object&gt; {\n\n@Override\npublic Object handleRequest(Object input, Context context) {\nwithSingleMetric(\"CustomMetrics2\", 1, Unit.COUNT, \"Another\", (metric) -&gt; {\nmetric.setDimensions(DimensionSet.of(\"AnotherService\", \"CustomService\"));\n});\n}\n}\n</code></pre>"},{"location":"core/tracing/","title":"Tracing","text":"<p>Powertools tracing is an opinionated thin wrapper for AWS X-Ray Java SDK a provides functionality to reduce the overhead of performing common tracing tasks.</p> <p></p> <p>Key Features</p> <ul> <li>Capture cold start as annotation, and responses as well as full exceptions as metadata</li> <li>Helper methods to improve the developer experience of creating new X-Ray subsegments.</li> <li>Better developer experience when developing with multiple threads.</li> <li>Auto patch supported modules by AWS X-Ray</li> </ul> <p>Initialization</p> <p>Before your use this utility, your AWS Lambda function must have permissions to send traces to AWS X-Ray.</p> <p>Example using AWS Serverless Application Model (SAM)</p> template.yaml <pre><code>Resources:\nHelloWorldFunction:\nType: AWS::Serverless::Function\nProperties:\n...\nRuntime: java8\n\nTracing: Active\nEnvironment:\nVariables:\nPOWERTOOLS_SERVICE_NAME: example\n</code></pre> <p>The Powertools service name is used as the X-Ray namespace. This can be set using the environment variable <code>POWERTOOLS_SERVICE_NAME</code></p>"},{"location":"core/tracing/#lambda-handler","title":"Lambda handler","text":"<p>To enable Powertools tracing to your function add the <code>@Tracing</code> annotation to your <code>handleRequest</code> method or on any method will capture the method as a separate subsegment automatically. You can optionally choose to customize  segment name that appears in traces.</p> Tracing annotationCustom Segment names <pre><code>public class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n@Tracing\npublic APIGatewayProxyResponseEvent handleRequest(APIGatewayProxyRequestEvent input, Context context) {\nbusinessLogic1();\n\nbusinessLogic2();\n}\n\n@Tracing\npublic void businessLogic1(){\n\n}\n\n@Tracing\npublic void businessLogic2(){\n\n}\n}\n</code></pre> <pre><code>public class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n@Tracing(segmentName=\"yourCustomName\")\npublic APIGatewayProxyResponseEvent handleRequest(APIGatewayProxyRequestEvent input, Context context) {\n...\n}\n</code></pre> <p>When using this <code>@Tracing</code> annotation, Utility performs these additional tasks to ease operations:</p> <ul> <li>Creates a <code>ColdStart</code> annotation to easily filter traces that have had an initialization overhead.</li> <li>Creates a <code>Service</code> annotation if service parameter or <code>POWERTOOLS_SERVICE_NAME</code> is set.</li> <li>Captures any response, or full exceptions generated by the handler, and include as tracing metadata.</li> </ul> <p>By default, this annotation will automatically record method responses and exceptions. You can change the default behavior by setting the environment variables <code>POWERTOOLS_TRACER_CAPTURE_RESPONSE</code> and <code>POWERTOOLS_TRACER_CAPTURE_ERROR</code> as needed. Optionally, you can override behavior by different supported <code>captureMode</code> to record response, exception or both.</p> <p>Returning sensitive information from your Lambda handler or functions, where <code>Tracing</code> is used?</p> <p>You can disable annotation from capturing their responses and exception as tracing metadata with <code>captureMode=DISABLED</code> or globally by setting environment variables <code>POWERTOOLS_TRACER_CAPTURE_RESPONSE</code> and <code>POWERTOOLS_TRACER_CAPTURE_ERROR</code> to <code>false</code></p> Disable on annotationDisable Globally <pre><code>public class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n@Tracing(captureMode=CaptureMode.DISABLED)\npublic APIGatewayProxyResponseEvent handleRequest(APIGatewayProxyRequestEvent input, Context context) {\n...\n}\n</code></pre> <pre><code>Resources:\nHelloWorldFunction:\nType: AWS::Serverless::Function\nProperties:\n...\nRuntime: java8\n\nTracing: Active\nEnvironment:\nVariables:\nPOWERTOOLS_TRACER_CAPTURE_RESPONSE: false\nPOWERTOOLS_TRACER_CAPTURE_ERROR: false\n</code></pre>"},{"location":"core/tracing/#annotations-metadata","title":"Annotations &amp; Metadata","text":"<p>Annotations are key-values associated with traces and indexed by AWS X-Ray. You can use them to filter traces and to create Trace Groups to slice and dice your transactions.</p> <p>Metadata are key-values also associated with traces but not indexed by AWS X-Ray. You can use them to add additional  context for an operation using any native object.</p> AnnotationsMetadata <p>You can add annotations using <code>putAnnotation()</code> method from TracingUtils <pre><code>import software.amazon.lambda.powertools.tracing.Tracing;\nimport software.amazon.lambda.powertools.tracing.TracingUtils;\n\npublic class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n@Tracing\npublic APIGatewayProxyResponseEvent handleRequest(APIGatewayProxyRequestEvent input, Context context) {\nTracingUtils.putAnnotation(\"annotation\", \"value\");\n}\n}\n</code></pre></p> <p>You can add metadata using <code>putMetadata()</code> method from TracingUtils <pre><code>import software.amazon.lambda.powertools.tracing.Tracing;\nimport software.amazon.lambda.powertools.tracing.TracingUtils;\n\npublic class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n@Tracing\npublic APIGatewayProxyResponseEvent handleRequest(APIGatewayProxyRequestEvent input, Context context) {\nTracingUtils.putMetadata(\"content\", \"value\");\n}\n}\n</code></pre></p>"},{"location":"core/tracing/#override-default-object-mapper","title":"Override default object mapper","text":"<p>You can optionally choose to override default object mapper which is used to serialize method response and exceptions when enabled. You might want to supply custom object mapper in order to control how serialisation is done, for example, when you want to log only specific fields from received event due to security.</p> App.java <pre><code>import software.amazon.lambda.powertools.tracing.Tracing;\nimport software.amazon.lambda.powertools.tracing.TracingUtils;\nimport static software.amazon.lambda.powertools.tracing.CaptureMode.RESPONSE;\n\n/**\n * Handler for requests to Lambda function.\n */\npublic class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; { static {\nObjectMapper objectMapper = new ObjectMapper();\nSimpleModule simpleModule = new SimpleModule();\nobjectMapper.registerModule(simpleModule);\nTracingUtils.defaultObjectMapper(objectMapper);\n}\n\n@Tracing(captureMode = RESPONSE)\npublic APIGatewayProxyResponseEvent handleRequest(final APIGatewayProxyRequestEvent input, final Context context) {\n...\n}\n}\n</code></pre>"},{"location":"core/tracing/#utilities","title":"Utilities","text":"<p>Tracing modules comes with certain utility method when you don't want to use annotation for capturing a code block under a subsegment, or you are doing multithreaded programming. Refer examples below.</p> Functional ApiMulti Threaded Programming <pre><code>import software.amazon.lambda.powertools.tracing.Tracing;\nimport software.amazon.lambda.powertools.tracing.TracingUtils;\n\npublic class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\npublic APIGatewayProxyResponseEvent handleRequest(APIGatewayProxyRequestEvent input, Context context) {\nTracingUtils.withSubsegment(\"loggingResponse\", subsegment -&gt; {\n// Some business logic\n});\nTracingUtils.withSubsegment(\"localNamespace\", \"loggingResponse\", subsegment -&gt; {\n// Some business logic\n});\n}\n}\n</code></pre> <pre><code>import static software.amazon.lambda.powertools.tracing.TracingUtils.withEntitySubsegment;\n\npublic class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\npublic APIGatewayProxyResponseEvent handleRequest(APIGatewayProxyRequestEvent input, Context context) {\n// Extract existing trace data\nEntity traceEntity = AWSXRay.getTraceEntity();\nThread anotherThread = new Thread(() -&gt; withEntitySubsegment(\"inlineLog\", traceEntity, subsegment -&gt; {\n// Business logic in separate thread\n}));\n}\n}\n</code></pre>"},{"location":"core/tracing/#instrumenting-sdk-clients-and-http-calls","title":"Instrumenting SDK clients and HTTP calls","text":"<p>User should make sure to instrument the SDK clients explicitly based on the function dependency. Refer details on how to instrument SDK client with Xray and outgoing http calls.</p>"},{"location":"core/tracing/#testing-your-code","title":"Testing your code","text":"<p>When using <code>@Tracing</code> annotation, your Junit test cases needs to be configured to create parent Segment required by AWS X-Ray SDK for Java.</p> <p>Below are two ways in which you can configure your tests.</p>"},{"location":"core/tracing/#configure-environment-variable-on-project-level-recommended","title":"Configure environment variable on project level (Recommended)","text":"<p>You can choose to configure environment variable on project level for your test cases run. This is recommended approach as it will avoid the need of configuring each test case specifically.</p> <p>Below are examples configuring your maven/gradle projects. You can choose to configure it differently as well as long as you are making sure that environment variable <code>LAMBDA_TASK_ROOT</code> is set. This variable is  used internally via AWS X-Ray SDK to configure itself properly for lambda runtime.</p> Maven (pom.xml)Gradle (build.gradle)  <pre><code>&lt;build&gt;\n...\n  &lt;plugins&gt;\n&lt;!--  Configures environment variable to avoid initialization of AWS X-Ray segments for each tests--&gt;\n&lt;plugin&gt;\n&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n&lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;\n&lt;configuration&gt;\n&lt;environmentVariables&gt;\n&lt;LAMBDA_TASK_ROOT&gt;handler&lt;/LAMBDA_TASK_ROOT&gt;\n&lt;/environmentVariables&gt;\n&lt;/configuration&gt;\n&lt;/plugin&gt;\n&lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> <pre><code>// Configures environment variable to avoid initialization of AWS X-Ray segments for each tests\ntest {\nenvironment \"LAMBDA_TASK_ROOT\", \"handler\"\n}\n</code></pre>"},{"location":"core/tracing/#configure-test-cases-not-recommended","title":"Configure test cases (Not Recommended)","text":"<p>You can choose to configure each of your test case instead as well if you choose not to configure environment variable on project level.  Below is an example configuration needed for each test case.</p> AppTest.java <pre><code>import com.amazonaws.xray.AWSXRay;\nimport org.junit.After;\nimport org.junit.Before;\nimport org.junit.Test;\n\npublic class AppTest {\n\n@Before\npublic void setup() {\nif(null == System.getenv(\"LAMBDA_TASK_ROOT\")) {\nAWSXRay.beginSegment(\"test\");\n}\n}\n\n@After\npublic void tearDown() {\n// Needed when using sam build --use-container\nif (AWSXRay.getCurrentSubsegmentOptional().isPresent()) {\nAWSXRay.endSubsegment();\n}\nif(null == System.getenv(\"LAMBDA_TASK_ROOT\")) {\nAWSXRay.endSegment();\n}\n}\n\n@Test\npublic void successfulResponse() {\n// test logic\n}\n</code></pre>"},{"location":"utilities/batch/","title":"SQS Batch Processing","text":"<p>The SQS batch processing utility provides a way to handle partial failures when processing batches of messages from SQS.</p> <p>Key Features</p> <ul> <li>Prevent successfully processed messages from being returned to SQS</li> <li>A simple interface for individually processing messages from a batch</li> </ul> <p>Background</p> <p>When using SQS as a Lambda event source mapping, Lambda functions can be triggered with a batch of messages from SQS.  If your function fails to process any message from the batch, the entire batch returns to your SQS queue, and your  Lambda function will be triggered with the same batch again. With this utility, messages within a batch will be handled individually - only messages that were not successfully processed are returned to the queue.</p> <p>Warning</p> <p>While this utility lowers the chance of processing messages more than once, it is not guaranteed. We recommend implementing processing logic in an idempotent manner wherever possible. More details on how Lambda works with SQS can be found in the AWS documentation</p>"},{"location":"utilities/batch/#install","title":"Install","text":"<p>To install this utility, add the following dependency to your project.</p> MavenGradle <pre><code>&lt;dependencies&gt;\n...\n    &lt;dependency&gt;\n&lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n&lt;artifactId&gt;powertools-sqs&lt;/artifactId&gt;\n&lt;version&gt;1.10.3&lt;/version&gt;\n&lt;/dependency&gt;\n...\n&lt;/dependencies&gt;\n&lt;!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --&gt;\n&lt;build&gt;\n&lt;plugins&gt;\n...\n        &lt;plugin&gt;\n&lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;\n&lt;artifactId&gt;aspectj-maven-plugin&lt;/artifactId&gt;\n&lt;version&gt;1.14.0&lt;/version&gt;\n&lt;configuration&gt;\n&lt;source&gt;1.8&lt;/source&gt;\n&lt;target&gt;1.8&lt;/target&gt;\n&lt;complianceLevel&gt;1.8&lt;/complianceLevel&gt;\n&lt;aspectLibraries&gt;\n&lt;aspectLibrary&gt;\n&lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n&lt;artifactId&gt;powertools-sqs&lt;/artifactId&gt;\n&lt;/aspectLibrary&gt;\n&lt;/aspectLibraries&gt;\n&lt;/configuration&gt;\n&lt;executions&gt;\n&lt;execution&gt;\n&lt;goals&gt;\n&lt;goal&gt;compile&lt;/goal&gt;\n&lt;/goals&gt;\n&lt;/execution&gt;\n&lt;/executions&gt;\n&lt;/plugin&gt;\n...\n    &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> <pre><code>plugins{\nid 'java'\nid 'io.freefair.aspectj.post-compile-weaving' version '6.3.0'\n}\n\nrepositories {\nmavenCentral()\n}\n\ndependencies {\n...\naspect 'software.amazon.lambda:powertools-sqs:1.10.3'\n}\n</code></pre>"},{"location":"utilities/batch/#iam-permissions","title":"IAM Permissions","text":"<p>This utility requires additional permissions to work as expected. Lambda functions using this utility require the <code>sqs:DeleteMessageBatch</code> permission.</p> <p>If you are also using nonRetryableExceptions attribute, utility will need additional permission of <code>sqs:GetQueueAttributes</code> on source SQS.  It also needs <code>sqs:SendMessage</code> and <code>sqs:SendMessageBatch</code> on configured dead letter queue.  </p> <p>If source or dead letter queue is configured to use encryption at rest using AWS Key Management Service (KMS), function will need additional permissions of  <code>kms:GenerateDataKey</code> and <code>kms:Decrypt</code> on the KMS key being used for encryption. Refer docs for more details.</p> <p>Refer example project for policy details example.</p>"},{"location":"utilities/batch/#processing-messages-from-sqs","title":"Processing messages from SQS","text":"<p>You can use either SqsBatch annotation, or SqsUtils Utility API as a fluent API.</p> <p>Both have nearly the same behaviour when it comes to processing messages from the batch:</p> <ul> <li>Entire batch has been successfully processed, where your Lambda handler returned successfully, we will let SQS delete the batch to optimize your cost</li> <li>Entire Batch has been partially processed successfully, where exceptions were raised within your <code>SqsMessageHandler</code> interface implementation, we will:<ul> <li>1) Delete successfully processed messages from the queue by directly calling <code>sqs:DeleteMessageBatch</code></li> <li>2) if, non retryable exceptions occur, messages resulting in configured exceptions during processing will be immediately moved to the dead letter queue associated to the source SQS queue or deleted from the source SQS queue if <code>deleteNonRetryableMessageFromQueue</code> is set to <code>true</code>.</li> <li>3) Raise <code>SQSBatchProcessingException</code> to ensure failed messages return to your SQS queue</li> </ul> </li> </ul> <p>The only difference is that SqsUtils Utility API will give you access to return from the processed messages if you need. Exception <code>SQSBatchProcessingException</code> thrown from the utility will have access to both successful and failed messaged along with failure exceptions.</p>"},{"location":"utilities/batch/#functional-interface-sqsmessagehandler","title":"Functional Interface SqsMessageHandler","text":"<p>Both annotation and SqsUtils Utility API requires an implementation of functional interface <code>SqsMessageHandler</code>.</p> <p>This implementation is responsible for processing each individual message from the batch, and to raise an exception if unable to process any of the messages sent.</p> <p>Any non-exception/successful return from your record handler function will instruct utility to queue up each individual message for deletion.</p>"},{"location":"utilities/batch/#sqsbatch-annotation","title":"SqsBatch annotation","text":"<p>When using this annotation, you need provide a class implementation of <code>SqsMessageHandler</code> that will process individual messages from the batch - It should raise an exception if it is unable to process the record.</p> <p>All records in the batch will be passed to this handler for processing, even if exceptions are thrown - Here's the behaviour after completing the batch:</p> <ul> <li>Any successfully processed messages, we will delete them from the queue via <code>sqs:DeleteMessageBatch</code>.</li> <li>if, nonRetryableExceptions attribute is used, messages resulting in configured exceptions during processing will be immediately moved to the dead letter queue associated to the source SQS queue or deleted from the source SQS queue if <code>deleteNonRetryableMessageFromQueue</code> is set to <code>true</code>.</li> <li>Any unprocessed messages detected, we will raise <code>SQSBatchProcessingException</code> to ensure failed messages return to your SQS queue.</li> </ul> <p>Warning</p> <p>You will not have access to the processed messages within the Lambda Handler - all processing logic will and should be performed by the implemented <code>SqsMessageHandler#process()</code> function.</p> AppSqsEvent.javaAppSqsEventWithNonRetryableExceptions.java <pre><code>import software.amazon.lambda.powertools.sqs.SqsBatch;\nimport software.amazon.lambda.powertools.sqs.SqsMessageHandler;\nimport software.amazon.lambda.powertools.sqs.SqsUtils;\n\npublic class AppSqsEvent implements RequestHandler&lt;SQSEvent, String&gt; {\n@Override\n@SqsBatch(SampleMessageHandler.class)\npublic String handleRequest(SQSEvent input, Context context) {\nreturn \"{\\\"statusCode\\\": 200}\";\n}\n\npublic class SampleMessageHandler implements SqsMessageHandler&lt;Object&gt; {\n\n@Override\npublic String process(SQSMessage message) {\n// This will be called for each individual message from a batch\n// It should raise an exception if the message was not processed successfully\nString returnVal = doSomething(message.getBody());\nreturn returnVal;\n}\n}\n}\n</code></pre> <pre><code>import software.amazon.lambda.powertools.sqs.SqsBatch;\nimport software.amazon.lambda.powertools.sqs.SqsMessageHandler;\nimport software.amazon.lambda.powertools.sqs.SqsUtils;\n\npublic class AppSqsEvent implements RequestHandler&lt;SQSEvent, String&gt; {\n@Override\n@SqsBatch(value = SampleMessageHandler.class, nonRetryableExceptions = {IllegalArgumentException.class})\npublic String handleRequest(SQSEvent input, Context context) {\nreturn \"{\\\"statusCode\\\": 200}\";\n}\n\npublic class SampleMessageHandler implements SqsMessageHandler&lt;Object&gt; {\n\n@Override\npublic String process(SQSMessage message) {\n// This will be called for each individual message from a batch\n// It should raise an exception if the message was not processed successfully\nString returnVal = doSomething(message.getBody());\n\nif(/**Business validation failure**/) {\nthrow new IllegalArgumentException(\"Failed business validation. No point of retrying. Move me to DLQ.\" + message.getMessageId());\n}\n\nreturn returnVal;\n}\n}\n}\n</code></pre>"},{"location":"utilities/batch/#sqsutils-utility-api","title":"SqsUtils Utility API","text":"<p>If you require access to the result of processed messages, you can use this utility. The result from calling <code>SqsUtils#batchProcessor()</code> on the context manager will be a list of all the return values  from your <code>SqsMessageHandler#process()</code> function.</p> <p>You can also use the utility in functional way by providing inline implementation of functional interface <code>SqsMessageHandler#process()</code></p> Utility APIFunction implementation <pre><code>public class AppSqsEvent implements RequestHandler&lt;SQSEvent, List&lt;String&gt;&gt; {\n@Override\npublic List&lt;String&gt; handleRequest(SQSEvent input, Context context) {\nList&lt;String&gt; returnValues = SqsUtils.batchProcessor(input, SampleMessageHandler.class);\nreturn returnValues;\n}\n\npublic class SampleMessageHandler implements SqsMessageHandler&lt;String&gt; {\n\n@Override\npublic String process(SQSMessage message) {\n// This will be called for each individual message from a batch\n// It should raise an exception if the message was not processed successfully\nString returnVal = doSomething(message.getBody());\nreturn returnVal;\n}\n}\n}\n</code></pre> <pre><code>public class AppSqsEvent implements RequestHandler&lt;SQSEvent, List&lt;String&gt;&gt; {\n\n@Override\npublic List&lt;String&gt; handleRequest(SQSEvent input, Context context) {\nList&lt;String&gt; returnValues = SqsUtils.batchProcessor(input, (message) -&gt; {\n// This will be called for each individual message from a batch\n// It should raise an exception if the message was not processed successfully\nString returnVal = doSomething(message.getBody());\nreturn returnVal;\n});\nreturn returnValues;\n}\n}\n</code></pre>"},{"location":"utilities/batch/#passing-custom-sqsclient","title":"Passing custom SqsClient","text":"<p>If you need to pass custom SqsClient such as region to the SDK, you can pass your own <code>SqsClient</code> to be used by utility either for SqsBatch annotation, or SqsUtils Utility API.</p> App.java <pre><code>public class AppSqsEvent implements RequestHandler&lt;SQSEvent, List&lt;String&gt;&gt; {\nstatic {\nSqsUtils.overrideSqsClient(SqsClient.builder()\n.build());\n}\n\n@Override\npublic List&lt;String&gt; handleRequest(SQSEvent input, Context context) {\nList&lt;String&gt; returnValues = SqsUtils.batchProcessor(input, SampleMessageHandler.class);\n\nreturn returnValues;\n}\n\npublic class SampleMessageHandler implements SqsMessageHandler&lt;String&gt; {\n\n@Override\npublic String process(SQSMessage message) {\n// This will be called for each individual message from a batch\n// It should raise an exception if the message was not processed successfully\nString returnVal = doSomething(message.getBody());\nreturn returnVal;\n}\n}\n}\n</code></pre>"},{"location":"utilities/batch/#suppressing-exceptions","title":"Suppressing exceptions","text":"<p>If you want to disable the default behavior where <code>SQSBatchProcessingException</code> is raised if there are any exception, you can pass the <code>suppressException</code> boolean argument.</p> Within SqsBatch annotationWithin SqsUtils Utility API <pre><code>    @Override\n@SqsBatch(value = SampleMessageHandler.class, suppressException = true)\npublic String handleRequest(SQSEvent input, Context context) {\nreturn \"{\\\"statusCode\\\": 200}\";\n}\n</code></pre> <pre><code>    @Override\npublic List&lt;String&gt; handleRequest(SQSEvent input, Context context) {\nList&lt;String&gt; returnValues = SqsUtils.batchProcessor(input, true, SampleMessageHandler.class);\nreturn returnValues;\n}\n</code></pre>"},{"location":"utilities/batch/#move-non-retryable-messages-to-a-dead-letter-queue","title":"Move non retryable messages to a dead letter queue","text":"<p>If you want certain exceptions to be treated as permanent failures during batch processing, i.e. exceptions where the result of retrying will always be a failure and want these can be immediately moved to the dead letter queue associated to the source SQS queue, you can use <code>SqsBatch#nonRetryableExceptions()</code>  to configure such exceptions. </p> <p>If you want such messages to be deleted instead, set <code>SqsBatch#deleteNonRetryableMessageFromQueue()</code> to <code>true</code>. By default, its value is <code>false</code>.</p> <p>Same capability is also provided by SqsUtils Utility API.</p> <p>Info</p> <p>Make sure the lambda function has required permissions needed by utility. Refer this section.</p> SqsBatch annotationSqsBatch API <pre><code>import software.amazon.lambda.powertools.sqs.SqsBatch;\nimport software.amazon.lambda.powertools.sqs.SqsMessageHandler;\nimport software.amazon.lambda.powertools.sqs.SqsUtils;\n\npublic class AppSqsEvent implements RequestHandler&lt;SQSEvent, String&gt; {\n@Override\n@SqsBatch(value = SampleMessageHandler.class, nonRetryableExceptions = {IllegalArgumentException.class})\npublic String handleRequest(SQSEvent input, Context context) {\nreturn \"{\\\"statusCode\\\": 200}\";\n}\n\npublic class SampleMessageHandler implements SqsMessageHandler&lt;Object&gt; {\n\n@Override\npublic String process(SQSMessage message) {\n// This will be called for each individual message from a batch\n// It should raise an exception if the message was not processed successfully\nString returnVal = doSomething(message.getBody());\n\nif(/**Business validation failure**/) {\nthrow new IllegalArgumentException(\"Failed business validation. No point of retrying. Move me to DLQ.\" + message.getMessageId());\n}\n\nreturn returnVal;\n}\n}\n}\n</code></pre> <pre><code>import software.amazon.lambda.powertools.sqs.SqsBatch;\nimport software.amazon.lambda.powertools.sqs.SqsMessageHandler;\nimport software.amazon.lambda.powertools.sqs.SqsUtils;\n\npublic class AppSqsEvent implements RequestHandler&lt;SQSEvent, String&gt; {\n@Override\npublic String handleRequest(SQSEvent input, Context context) {\n\nSqsUtils.batchProcessor(input, BatchProcessor.class, IllegalArgumentException.class);\nreturn \"{\\\"statusCode\\\": 200}\";\n}\n\npublic class SampleMessageHandler implements SqsMessageHandler&lt;Object&gt; {\n\n@Override\npublic String process(SQSMessage message) {\n// This will be called for each individual message from a batch\n// It should raise an exception if the message was not processed successfully\nString returnVal = doSomething(message.getBody());\n\nif(/**Business validation failure**/) {\nthrow new IllegalArgumentException(\"Failed business validation. No point of retrying. Move me to DLQ.\" + message.getMessageId());\n}\n\nreturn returnVal;\n}\n}\n}\n</code></pre>"},{"location":"utilities/custom_resources/","title":"Custom resources","text":""},{"location":"utilities/custom_resources/#title-custom-resources-description-utility","title":"title: Custom Resources description: Utility","text":"<p>Custom resources provide a way for AWS Lambda functions to execute provisioning logic whenever CloudFormation stacks are created, updated, or deleted. The CloudFormation utility enables developers to write these Lambda functions in Java.</p> <p>The utility provides a base <code>AbstractCustomResourceHandler</code> class which handles custom resource request events, constructs custom resource responses, and sends them to the custom resources. Subclasses implement the provisioning logic and configure certain properties of these response objects.</p>"},{"location":"utilities/custom_resources/#install","title":"Install","text":"<p>To install this utility, add the following dependency to your project.</p> MavenGradle <pre><code>&lt;dependency&gt;\n&lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n&lt;artifactId&gt;powertools-cloudformation&lt;/artifactId&gt;\n&lt;version&gt;1.10.3&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> <pre><code> dependencies {\n...\nimplementation 'software.amazon.lambda:powertools-cloudformation:1.10.3'\n}\n</code></pre>"},{"location":"utilities/custom_resources/#usage","title":"Usage","text":"<p>Create a new <code>AbstractCustomResourceHandler</code> subclass and implement the <code>create</code>, <code>update</code>, and <code>delete</code> methods with provisioning logic in the appropriate methods(s).</p> <p>As an example, if a Lambda function only needs to provision something when a stack is created, put the provisioning logic exclusively within the <code>create</code> method; the other methods can just return <code>null</code>.</p> <pre><code>import com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.events.CloudFormationCustomResourceEvent;\nimport software.amazon.lambda.powertools.cloudformation.AbstractCustomResourceHandler;\nimport software.amazon.lambda.powertools.cloudformation.Response;\n\npublic class ProvisionOnCreateHandler extends AbstractCustomResourceHandler {\n\n@Override\nprotected Response create(CloudFormationCustomResourceEvent createEvent, Context context) {\ndoProvisioning();\nreturn Response.success();\n}\n\n@Override\nprotected Response update(CloudFormationCustomResourceEvent updateEvent, Context context) {\nreturn null;\n}\n\n@Override\nprotected Response delete(CloudFormationCustomResourceEvent deleteEvent, Context context) {\nreturn null;\n}\n}\n</code></pre>"},{"location":"utilities/custom_resources/#signaling-provisioning-failures","title":"Signaling Provisioning Failures","text":"<p>If provisioning fails, the stack creation/modification/deletion as a whole can be failed by either throwing a <code>RuntimeException</code> or by explicitly returning a <code>Response</code> with a failed status, e.g. <code>Response.failure()</code>.</p>"},{"location":"utilities/custom_resources/#configuring-response-objects","title":"Configuring Response Objects","text":"<p>When provisioning results in data to be shared with other parts of the stack, include this data within the returned <code>Response</code> instance.</p> <p>This Lambda function creates a Chime AppInstance and maps the returned ARN to a \"ChimeAppInstanceArn\" attribute.</p> <pre><code>public class ChimeAppInstanceHandler extends AbstractCustomResourceHandler {\n@Override\nprotected Response create(CloudFormationCustomResourceEvent createEvent, Context context) {\nCreateAppInstanceRequest chimeRequest = CreateAppInstanceRequest.builder()\n.name(\"my-app-name\")\n.build();\nCreateAppInstanceResponse chimeResponse = ChimeClient.builder()\n.region(\"us-east-1\")\n.createAppInstance(chimeRequest);\n\nMap&lt;String, String&gt; chimeAtts = Map.of(\"ChimeAppInstanceArn\", chimeResponse.appInstanceArn());\nreturn Response.builder()\n.value(chimeAtts)\n.build();\n}\n}\n</code></pre> <p>For the example above the following response payload will be sent.</p> <pre><code>{\n\"Status\": \"SUCCESS\",\n\"PhysicalResourceId\": \"2021/10/01/e3a37e552eff4718a5675c1e31f0649e\",\n\"StackId\": \"arn:aws:cloudformation:us-east-1:123456789000:stack/Custom-stack/59e4d2d0-2fe2-10ec-b00e-124d7c1c5f15\",\n\"RequestId\": \"7cae0346-0359-4dff-b80a-a82f247467b6\",\n\"LogicalResourceId:\": \"ChimeTriggerResource\",\n\"NoEcho\": false,\n\"Data\": {\n\"ChimeAppInstanceArn\": \"arn:aws:chime:us-east-1:123456789000:app-instance/150972c2-5490-49a9-8ba7-e7da4257c16a\"\n}\n}\n</code></pre> <p>Once the custom resource receives this response, it's \"ChimeAppInstanceArn\" attribute is set and the Fn::GetAtt function may be used to retrieve the attribute value and make it available to other resources in the stack.</p>"},{"location":"utilities/custom_resources/#sensitive-response-data","title":"Sensitive Response Data","text":"<p>If any attributes are sensitive, enable the \"noEcho\" flag to mask the output of the custom resource when it's retrieved with the Fn::GetAtt function.</p> <pre><code>public class SensitiveDataHandler extends AbstractResourceHandler {\n@Override\nprotected Response create(CloudFormationCustomResourceEvent createEvent, Context context) {\nreturn Response.builder()\n.value(Map.of(\"SomeSecret\", sensitiveValue))\n.noEcho(true)\n.build();\n}\n}\n</code></pre>"},{"location":"utilities/custom_resources/#customizing-serialization","title":"Customizing Serialization","text":"<p>Although using a <code>Map</code> as the Response's value is the most straightforward way to provide attribute name/value pairs, any arbitrary <code>java.lang.Object</code> may be used. By default, these objects are serialized with an internal Jackson <code>ObjectMapper</code>. If the object requires special serialization logic, a custom <code>ObjectMapper</code> can be specified.</p> <pre><code>public class CustomSerializationHandler extends AbstractResourceHandler {\n/**\n     * Type representing the custom response Data. \n     */\nstatic class Policy {\npublic ZonedDateTime getExpires() {\nreturn ZonedDateTime.now().plusDays(10);\n}\n}\n\n/**\n     * Mapper for serializing Policy instances.\n     */\nprivate final ObjectMapper policyMapper = new ObjectMapper()\n.registerModule(new JavaTimeModule())\n.disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS);\n\n@Override\nprotected Response create(CloudFormationCustomResourceEvent createEvent, Context context) {\nPolicy policy = new Policy();\nreturn Response.builder()\n.value(policy)\n.objectMapper(policyMapper) // customize serialization\n.build();\n}\n}\n</code></pre>"},{"location":"utilities/idempotency/","title":"Idempotency","text":"<p>The idempotency utility provides a simple solution to convert your Lambda functions into idempotent operations which are safe to retry.</p>"},{"location":"utilities/idempotency/#terminology","title":"Terminology","text":"<p>The property of idempotency means that an operation does not cause additional side effects if it is called more than once with the same input parameters.</p> <p>Idempotent operations will return the same result when they are called multiple times with the same parameters. This makes idempotent operations safe to retry. Read more about idempotency.</p> <p>Idempotency key is a hash representation of either the entire event or a specific configured subset of the event, and invocation results are JSON serialized and stored in your persistence storage layer.</p>"},{"location":"utilities/idempotency/#key-features","title":"Key features","text":"<ul> <li>Prevent Lambda handler function from executing more than once on the same event payload during a time window</li> <li>Ensure Lambda handler returns the same result when called with the same payload</li> <li>Select a subset of the event as the idempotency key using JMESPath expressions</li> <li>Set a time window in which records with the same payload should be considered duplicates</li> </ul>"},{"location":"utilities/idempotency/#getting-started","title":"Getting started","text":""},{"location":"utilities/idempotency/#installation","title":"Installation","text":"Maven <pre><code>&lt;dependencies&gt;\n...\n    &lt;dependency&gt;\n&lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n&lt;artifactId&gt;powertools-idempotency&lt;/artifactId&gt;\n&lt;version&gt;1.10.3&lt;/version&gt;\n&lt;/dependency&gt;\n...\n&lt;/dependencies&gt;\n\n&lt;!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --&gt;\n&lt;build&gt;\n&lt;plugins&gt;\n...\n        &lt;plugin&gt;\n&lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;\n&lt;artifactId&gt;aspectj-maven-plugin&lt;/artifactId&gt;\n&lt;version&gt;1.14.0&lt;/version&gt;\n&lt;configuration&gt;\n&lt;source&gt;1.8&lt;/source&gt;\n&lt;target&gt;1.8&lt;/target&gt;\n&lt;complianceLevel&gt;1.8&lt;/complianceLevel&gt;\n&lt;aspectLibraries&gt;\n&lt;aspectLibrary&gt;\n&lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n&lt;artifactId&gt;powertools-idempotency&lt;/artifactId&gt;\n&lt;/aspectLibrary&gt;\n...\n                 &lt;/aspectLibraries&gt;\n&lt;/configuration&gt;\n&lt;executions&gt;\n&lt;execution&gt;\n&lt;goals&gt;\n&lt;goal&gt;compile&lt;/goal&gt;\n&lt;/goals&gt;\n&lt;/execution&gt;\n&lt;/executions&gt;\n&lt;/plugin&gt;\n...\n    &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre>"},{"location":"utilities/idempotency/#required-resources","title":"Required resources","text":"<p>Before getting started, you need to create a persistent storage layer where the idempotency utility can store its state - your Lambda functions will need read and write access to it.</p> <p>As of now, Amazon DynamoDB is the only supported persistent storage layer, so you'll need to create a table first.</p> <p>Default table configuration</p> <p>If you're not changing the default configuration for the DynamoDB persistence layer, this is the expected default configuration:</p> Configuration Value Notes Partition key <code>id</code> TTL attribute name <code>expiration</code> This can only be configured after your table is created if you're using AWS Console <p>Tip: You can share a single state table for all functions</p> <p>You can reuse the same DynamoDB table to store idempotency state. We add your function name in addition to the idempotency key as a hash key.</p> AWS Serverless Application Model (SAM) example<pre><code>Resources:\nIdempotencyTable:\nType: AWS::DynamoDB::Table\nProperties:\nAttributeDefinitions:\n- AttributeName: id\nAttributeType: S\nKeySchema:\n- AttributeName: id\nKeyType: HASH\nTimeToLiveSpecification:\nAttributeName: expiration\nEnabled: true\nBillingMode: PAY_PER_REQUEST\n\nIdempotencyFunction:\nType: AWS::Serverless::Function\nProperties:\nCodeUri: Function\nHandler: helloworld.App::handleRequest\nPolicies:\n- DynamoDBCrudPolicy:\nTableName: !Ref IdempotencyTable\nEnvironment:\nVariables:\nIDEMPOTENCY_TABLE: !Ref IdempotencyTable\n</code></pre> <p>Warning: Large responses with DynamoDB persistence layer</p> <p>When using this utility with DynamoDB, your function's responses must be smaller than 400KB. Larger items cannot be written to DynamoDB and will cause exceptions.</p> <p>Info: DynamoDB</p> <p>Each function invocation will generally make 2 requests to DynamoDB. If the result returned by your Lambda is less than 1kb, you can expect 2 WCUs per invocation. For retried invocations, you will see 1WCU and 1RCU. Review the DynamoDB pricing documentation to estimate the cost.</p>"},{"location":"utilities/idempotency/#idempotent-annotation","title":"Idempotent annotation","text":"<p>You can quickly start by initializing the <code>DynamoDBPersistenceStore</code> and using it with the <code>@Idempotent</code> annotation on your Lambda handler.</p> <p>Important</p> <p>Initialization and configuration of the <code>DynamoDBPersistenceStore</code> must be performed outside the handler, preferably in the constructor.</p> App.javaExample event <pre><code>public class App implements RequestHandler&lt;Subscription, SubscriptionResult&gt; {\n\npublic App() {\n// we need to initialize idempotency store before the handleRequest method is called\nIdempotency.config().withPersistenceStore(\nDynamoDBPersistenceStore.builder()\n.withTableName(System.getenv(\"TABLE_NAME\"))\n.build()\n).configure();\n}\n\n@Idempotent\npublic SubscriptionResult handleRequest(final Subscription event, final Context context) {\nSubscriptionPayment payment = createSubscriptionPayment(\nevent.getUsername(),\nevent.getProductId()\n);\n\nreturn new SubscriptionResult(payment.getId(), \"success\", 200);\n}\n}\n</code></pre> <pre><code>{\n\"username\": \"xyz\",\n\"product_id\": \"123456789\"\n}\n</code></pre>"},{"location":"utilities/idempotency/#idempotent-annotation-on-another-method","title":"Idempotent annotation on another method","text":"<p>You can use the <code>@Idempotent</code> annotation for any synchronous Java function, not only the <code>handleRequest</code> one.</p> <p>When using <code>@Idempotent</code> annotation on another method, you must tell which parameter in the method signature has the data we should use:</p> <ul> <li>If the method only has one parameter, it will be used by default. </li> <li>If there are 2 or more parameters, you must set the <code>@IdempotencyKey</code> on the parameter to use.</li> </ul> <p>The parameter must be serializable in JSON. We use Jackson internally to (de)serialize objects</p> AppSqsEvent.javaBatch event <p>This example also demonstrates how you can integrate with Batch utility, so you can process each record in an idempotent manner.</p> <pre><code>public class AppSqsEvent implements RequestHandler&lt;SQSEvent, String&gt; {\n\npublic AppSqsEvent() {\nIdempotency.config()\n.withPersistenceStore(\nDynamoDBPersistenceStore.builder()\n.withTableName(System.getenv(\"TABLE_NAME\"))\n.build()\n).withConfig(\nIdempotencyConfig.builder()\n.withEventKeyJMESPath(\"messageId\") // see Choosing a payload subset section\n.build()\n).configure();\n}\n\n@Override\n@SqsBatch(SampleMessageHandler.class)\npublic String handleRequest(SQSEvent input, Context context) {\ndummy(\"hello\", \"world\");\nreturn \"{\\\"statusCode\\\": 200}\";\n}\n\n@Idempotent\nprivate String dummy(String argOne, @IdempotencyKey String argTwo) {\nreturn \"something\";\n}\n\npublic static class SampleMessageHandler implements SqsMessageHandler&lt;Object&gt; {\n@Override\n@Idempotent\n// no need to use @IdempotencyKey as there is only one parameter\npublic String process(SQSMessage message) {\nString returnVal = doSomething(message.getBody());\nreturn returnVal;\n}\n}\n}\n</code></pre> <pre><code>{\n\"Records\": [\n{\n\"messageId\": \"059f36b4-87a3-44ab-83d2-661975830a7d\",\n\"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a...\",\n\"body\": \"Test message.\",\n\"attributes\": {\n\"ApproximateReceiveCount\": \"1\",\n\"SentTimestamp\": \"1545082649183\",\n\"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n\"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n},\n\"messageAttributes\": {\n\"testAttr\": {\n\"stringValue\": \"100\",\n\"binaryValue\": \"base64Str\",\n\"dataType\": \"Number\"\n}\n},\n\"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n\"eventSource\": \"aws:sqs\",\n\"eventSourceARN\": \"arn:aws:sqs:us-east-2:123456789012:my-queue\",\n\"awsRegion\": \"us-east-2\"\n}\n]\n}\n</code></pre>"},{"location":"utilities/idempotency/#choosing-a-payload-subset-for-idempotency","title":"Choosing a payload subset for idempotency","text":"<p>Tip: Dealing with always changing payloads</p> <p>When dealing with an elaborate payload (API Gateway request for example), where parts of the payload always change, you should configure the <code>EventKeyJMESPath</code>.</p> <p>Use <code>IdempotencyConfig</code> to instruct the Idempotent annotation to only use a portion of your payload to verify whether a request is idempotent, and therefore it should not be retried.</p> <p>Payment scenario</p> <p>In this example, we have a Lambda handler that creates a payment for a user subscribing to a product. We want to ensure that we don't accidentally charge our customer by subscribing them more than once.</p> <p>Imagine the function executes successfully, but the client never receives the response due to a connection issue. It is safe to retry in this instance, as the idempotent decorator will return a previously saved response.</p> <p>Warning: Idempotency for JSON payloads</p> <p>The payload extracted by the <code>EventKeyJMESPath</code> is treated as a string by default, so will be sensitive to differences in whitespace even when the JSON payload itself is identical.</p> <p>To alter this behaviour, you can use the JMESPath built-in function <code>powertools_json()</code> to treat the payload as a JSON object rather than a string.</p> PaymentFunction.javaExample event <pre><code>public class PaymentFunction implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\npublic PaymentFunction() {\nIdempotency.config()\n.withConfig(\nIdempotencyConfig.builder()\n.withEventKeyJMESPath(\"powertools_json(body)\")\n.build())\n.withPersistenceStore(\nDynamoDBPersistenceStore.builder()\n.withTableName(System.getenv(\"TABLE_NAME\"))\n.build())\n.configure();\n}\n\n@Idempotent\npublic APIGatewayProxyResponseEvent handleRequest(final APIGatewayProxyRequestEvent event, final Context context) {\nAPIGatewayProxyResponseEvent response = new APIGatewayProxyResponseEvent();\n\ntry {\nSubscription subscription = JsonConfig.get().getObjectMapper().readValue(event.getBody(), Subscription.class);\n\nSubscriptionPayment payment = createSubscriptionPayment(\nsubscription.getUsername(),\nsubscription.getProductId()\n);\n\nreturn response\n.withStatusCode(200)\n.withBody(String.format(\"{\\\"paymentId\\\":\\\"%s\\\"}\", payment.getId()));\n} catch (JsonProcessingException e) {\nreturn response.withStatusCode(500);\n}\n}\n</code></pre> <pre><code>{\n\"version\":\"2.0\",\n\"body\":\"{\\\"username\\\":\\\"xyz\\\",\\\"productId\\\":\\\"123456789\\\"}\",\n\"routeKey\":\"ANY /createpayment\",\n\"rawPath\":\"/createpayment\",\n\"rawQueryString\":\"\",\n\"headers\": {\n\"Header1\": \"value1\",\n\"Header2\": \"value2\"\n},\n\"requestContext\":{\n\"accountId\":\"123456789012\",\n\"apiId\":\"api-id\",\n\"domainName\":\"id.execute-api.us-east-1.amazonaws.com\",\n\"domainPrefix\":\"id\",\n\"http\":{\n\"method\":\"POST\",\n\"path\":\"/createpayment\",\n\"protocol\":\"HTTP/1.1\",\n\"sourceIp\":\"ip\",\n\"userAgent\":\"agent\"\n},\n\"requestId\":\"id\",\n\"routeKey\":\"ANY /createpayment\",\n\"stage\":\"$default\",\n\"time\":\"10/Feb/2021:13:40:43 +0000\",\n\"timeEpoch\":1612964443723\n},\n\"isBase64Encoded\":false\n}\n</code></pre>"},{"location":"utilities/idempotency/#idempotency-request-flow","title":"Idempotency request flow","text":"<p>This sequence diagram shows an example flow of what happens in the payment scenario:</p> <p></p> <p>The client was successful in receiving the result after the retry. Since the Lambda handler was only executed once, our customer hasn't been charged twice.</p> <p>Note</p> <p>Bear in mind that the entire Lambda handler is treated as a single idempotent operation. If your Lambda handler can cause multiple side effects, consider splitting it into separate functions.</p>"},{"location":"utilities/idempotency/#handling-exceptions","title":"Handling exceptions","text":"<p>If you are using the <code>@Idempotent</code> annotation on your Lambda handler or any other method, any unhandled exceptions that are thrown during the code execution will cause the record in the persistence layer to be deleted. This means that new invocations will execute your code again despite having the same payload. If you don't want the record to be deleted, you need to catch exceptions within the idempotent function and return a successful response.</p> <p></p> <p>If an Exception is raised outside the scope of a decorated method and after your method has been called, the persistent record will not be affected. In this case, idempotency will be maintained for your decorated function. Example:</p> Exception not affecting idempotency record sample<pre><code>  public SubscriptionResult handleRequest(final Subscription event, final Context context) {\n// If an exception is thrown here, no idempotent record will ever get created as the\n// idempotent function does not get called \ndoSomeStuff();\nresult = idempotentMethod(event);\n\n// This exception will not cause the idempotent record to be deleted, since it\n// happens after the decorated function has been successfully called    \nthrow new Exception();\n}\n\n@Idempotent\nprivate String idempotentMethod(final Subscription subscription) {\n// perform some operation with no exception thrown\n}\n</code></pre> <p>Warning</p> <p>We will throw an <code>IdempotencyPersistenceLayerException</code> if any of the calls to the persistence layer fail unexpectedly.</p> <p>As this happens outside the scope of your decorated function, you are not able to catch it.</p>"},{"location":"utilities/idempotency/#persistence-stores","title":"Persistence stores","text":""},{"location":"utilities/idempotency/#dynamodbpersistencestore","title":"DynamoDBPersistenceStore","text":"<p>This persistence store is built-in, and you can either use an existing DynamoDB table or create a new one dedicated for idempotency state (recommended).</p> <p>Use the builder to customize the table structure: Customizing DynamoDBPersistenceStore to suit your table structure<pre><code>DynamoDBPersistenceStore.builder()\n.withTableName(System.getenv(\"TABLE_NAME\"))\n.withKeyAttr(\"idempotency_key\")\n.withExpiryAttr(\"expires_at\")\n.withStatusAttr(\"current_status\")\n.withDataAttr(\"result_data\")\n.withValidationAttr(\"validation_key\")\n.build()\n</code></pre></p> <p>When using DynamoDB as a persistence layer, you can alter the attribute names by passing these parameters when initializing the persistence layer:</p> Parameter Required Default Description TableName Y Table name to store state KeyAttr <code>id</code> Partition key of the table. Hashed representation of the payload (unless SortKeyAttr is specified) ExpiryAttr <code>expiration</code> Unix timestamp of when record expires StatusAttr <code>status</code> Stores status of the Lambda execution during and after invocation DataAttr <code>data</code> Stores results of successfully idempotent methods ValidationAttr <code>validation</code> Hashed representation of the parts of the event used for validation SortKeyAttr Sort key of the table (if table is configured with a sort key). StaticPkValue <code>idempotency#{LAMBDA_FUNCTION_NAME}</code> Static value to use as the partition key. Only used when SortKeyAttr is set."},{"location":"utilities/idempotency/#advanced","title":"Advanced","text":""},{"location":"utilities/idempotency/#customizing-the-default-behavior","title":"Customizing the default behavior","text":"<p>Idempotency behavior can be further configured with <code>IdempotencyConfig</code> using a builder:</p> Customizing IdempotencyConfig<pre><code>IdempotencyConfig.builder()\n.withEventKeyJMESPath(\"id\")\n.withPayloadValidationJMESPath(\"paymentId\")\n.withThrowOnNoIdempotencyKey(true)\n.withExpiration(Duration.of(5, ChronoUnit.MINUTES))\n.withUseLocalCache(true)\n.withLocalCacheMaxItems(432)\n.withHashFunction(\"SHA-256\")\n.build()\n</code></pre> <p>These are the available options for further configuration:</p> Parameter Default Description EventKeyJMESPath <code>\"\"</code> JMESPath expression to extract the idempotency key from the event record. See available built-in functions PayloadValidationJMESPath <code>\"\"</code> JMESPath expression to validate whether certain parameters have changed in the event ThrowOnNoIdempotencyKey <code>False</code> Throw exception if no idempotency key was found in the request ExpirationInSeconds 3600 The number of seconds to wait before a record is expired UseLocalCache <code>false</code> Whether to locally cache idempotency results (LRU cache) LocalCacheMaxItems 256 Max number of items to store in local cache HashFunction <code>MD5</code> Algorithm to use for calculating hashes, as supported by <code>java.security.MessageDigest</code> (eg. SHA-1, SHA-256, ...) <p>These features are detailed below.</p>"},{"location":"utilities/idempotency/#handling-concurrent-executions-with-the-same-payload","title":"Handling concurrent executions with the same payload","text":"<p>This utility will throw an <code>IdempotencyAlreadyInProgressException</code> if we receive multiple invocations with the same payload while the first invocation hasn't completed yet.</p> <p>Info</p> <p>If you receive <code>IdempotencyAlreadyInProgressException</code>, you can safely retry the operation.</p> <p>This is a locking mechanism for correctness. Since we don't know the result from the first invocation yet, we can't safely allow another concurrent execution.</p>"},{"location":"utilities/idempotency/#using-in-memory-cache","title":"Using in-memory cache","text":"<p>By default, in-memory local caching is disabled, to avoid using memory in an unpredictable way. </p> <p>Warning</p> <p>Be sure to configure the Lambda memory according to the number of records and the potential size of each record.</p> <p>You can enable it as seen before with: Enable local cache<pre><code>    IdempotencyConfig.builder()\n.withUseLocalCache(true)\n.build()\n</code></pre> When enabled, we cache a maximum of 256 records in each Lambda execution environment - You can change it with the <code>LocalCacheMaxItems</code> parameter.</p> <p>Note: This in-memory cache is local to each Lambda execution environment</p> <p>This means it will be effective in cases where your function's concurrency is low in comparison to the number of \"retry\" invocations with the same payload, because cache might be empty.</p>"},{"location":"utilities/idempotency/#expiring-idempotency-records","title":"Expiring idempotency records","text":"<p>Note</p> <p>By default, we expire idempotency records after an hour (3600 seconds).</p> <p>In most cases, it is not desirable to store the idempotency records forever. Rather, you want to guarantee that the same payload won't be executed within a period of time.</p> <p>You can change this window with the <code>ExpirationInSeconds</code> parameter: Customizing expiration time<pre><code>IdempotencyConfig.builder()\n.withExpiration(Duration.of(5, ChronoUnit.MINUTES))\n.build()\n</code></pre></p> <p>Records older than 5 minutes will be marked as expired, and the Lambda handler will be executed normally even if it is invoked with a matching payload.</p> <p>Note: DynamoDB time-to-live field</p> <p>This utility uses <code>expiration</code> as the TTL field in DynamoDB, as demonstrated in the SAM example earlier.</p>"},{"location":"utilities/idempotency/#payload-validation","title":"Payload validation","text":"<p>Question: What if your function is invoked with the same payload except some outer parameters have changed?</p> <p>Example: A payment transaction for a given productID was requested twice for the same customer, however the amount to be paid has changed in the second transaction.</p> <p>By default, we will return the same result as it returned before, however in this instance it may be misleading; we provide a fail fast payload validation to address this edge case.</p> <p>With <code>PayloadValidationJMESPath</code>, you can provide an additional JMESPath expression to specify which part of the event body should be validated against previous idempotent invocations</p> App.javaExample Event 1Example Event 2 <pre><code>public App() {\nIdempotency.config()\n.withPersistenceStore(DynamoDBPersistenceStore.builder()\n.withTableName(System.getenv(\"TABLE_NAME\"))\n.build())\n.withConfig(IdempotencyConfig.builder()\n.withEventKeyJMESPath(\"[userDetail, productId]\")\n.withPayloadValidationJMESPath(\"amount\")\n.build())\n.configure();\n}\n\n@Idempotent\npublic SubscriptionResult handleRequest(final Subscription input, final Context context) {\n// Creating a subscription payment is a side\n// effect of calling this function!\nSubscriptionPayment payment = createSubscriptionPayment(\ninput.getUserDetail().getUsername(),\ninput.getProductId(),\ninput.getAmount()\n)\n// ...\nreturn new SubscriptionResult(\n\"success\", 200,\npayment.getId(),\npayment.getAmount()\n);\n}\n</code></pre> <pre><code>{\n\"userDetail\": {\n\"username\": \"User1\",\n\"user_email\": \"user@example.com\"\n},\n\"productId\": 1500,\n\"charge_type\": \"subscription\",\n\"amount\": 500\n}\n</code></pre> <pre><code>{\n\"userDetail\": {\n\"username\": \"User1\",\n\"user_email\": \"user@example.com\"\n},\n\"productId\": 1500,\n\"charge_type\": \"subscription\",\n\"amount\": 1\n}\n</code></pre> <p>In this example, the <code>userDetail</code> and <code>productId</code> keys are used as the payload to generate the idempotency key, as per <code>EventKeyJMESPath</code> parameter.</p> <p>Note</p> <p>If we try to send the same request but with a different amount, we will raise <code>IdempotencyValidationException</code>.</p> <p>Without payload validation, we would have returned the same result as we did for the initial request. Since we're also returning an amount in the response, this could be quite confusing for the client.</p> <p>By using <code>withPayloadValidationJMESPath(\"amount\")</code>, we prevent this potentially confusing behavior and instead throw an Exception.</p>"},{"location":"utilities/idempotency/#making-idempotency-key-required","title":"Making idempotency key required","text":"<p>If you want to enforce that an idempotency key is required, you can set <code>ThrowOnNoIdempotencyKey</code> to <code>True</code>.</p> <p>This means that we will throw <code>IdempotencyKeyException</code> if the evaluation of <code>EventKeyJMESPath</code> is <code>null</code>.</p> App.javaSuccess EventFailure Event <pre><code>public App() {\nIdempotency.config()\n.withPersistenceStore(DynamoDBPersistenceStore.builder()\n.withTableName(System.getenv(\"TABLE_NAME\"))\n.build())\n.withConfig(IdempotencyConfig.builder()\n// Requires \"user\".\"uid\" and \"orderId\" to be present\n.withEventKeyJMESPath(\"[user.uid, orderId]\")\n.withThrowOnNoIdempotencyKey(true)\n.build())\n.configure();\n}\n@Idempotent\npublic OrderResult handleRequest(final Order input, final Context context) {\n// ...\n}\n</code></pre> <pre><code>{\n\"user\": {\n\"uid\": \"BB0D045C-8878-40C8-889E-38B3CB0A61B1\",\n\"name\": \"Foo\"\n},\n\"orderId\": 10000\n}\n</code></pre> <p>Notice that <code>orderId</code> is now accidentally within <code>user</code> key</p> <pre><code>{\n\"user\": {\n\"uid\": \"DE0D000E-1234-10D1-991E-EAC1DD1D52C8\",\n\"name\": \"Joe Bloggs\",\n\"orderId\": 10000\n},\n}\n</code></pre>"},{"location":"utilities/idempotency/#customizing-dynamodb-configuration","title":"Customizing DynamoDB configuration","text":"<p>When creating the <code>DynamoDBPersistenceStore</code>, you can set a custom <code>DynamoDbClient</code> if you need to customize the configuration:</p> Custom DynamoDbClient with X-Ray interceptor <pre><code>public App() {\nDynamoDbClient customClient = DynamoDbClient.builder()\n.region(Region.US_WEST_2)\n.overrideConfiguration(ClientOverrideConfiguration.builder()\n.addExecutionInterceptor(new TracingInterceptor())\n.build()\n)\n.build();\nIdempotency.config().withPersistenceStore(\nDynamoDBPersistenceStore.builder()\n.withTableName(System.getenv(\"TABLE_NAME\"))\n.withDynamoDbClient(customClient)\n.build()\n).configure();\n}\n</code></pre> <p>Default configuration is the following:</p> <pre><code>DynamoDbClient.builder()\n.credentialsProvider(EnvironmentVariableCredentialsProvider.create())\n.httpClient(UrlConnectionHttpClient.builder().build())\n.region(Region.of(System.getenv(AWS_REGION_ENV)))\n.build();\n</code></pre>"},{"location":"utilities/idempotency/#using-a-dynamodb-table-with-a-composite-primary-key","title":"Using a DynamoDB table with a composite primary key","text":"<p>When using a composite primary key table (hash+range key), use <code>SortKeyAttr</code> parameter when initializing your persistence store.</p> <p>With this setting, we will save the idempotency key in the sort key instead of the primary key. By default, the primary key will now be set to <code>idempotency#{LAMBDA_FUNCTION_NAME}</code>.</p> <p>You can optionally set a static value for the partition key using the <code>StaticPkValue</code> parameter.</p> Reusing a DynamoDB table that uses a composite primary key<pre><code>Idempotency.config().withPersistenceStore(\nDynamoDBPersistenceStore.builder()\n.withTableName(System.getenv(\"TABLE_NAME\"))\n.withSortKeyAttr(\"sort_key\")\n.build())\n.configure();\n</code></pre> <p>Data would then be stored in DynamoDB like this:</p> id sort_key expiration status data idempotency#MyLambdaFunction 1e956ef7da78d0cb890be999aecc0c9e 1636549553 COMPLETED {\"id\": 12391, \"message\": \"success\"} idempotency#MyLambdaFunction 2b2cdb5f86361e97b4383087c1ffdf27 1636549571 COMPLETED {\"id\": 527212, \"message\": \"success\"} idempotency#MyLambdaFunction f091d2527ad1c78f05d54cc3f363be80 1636549585 IN_PROGRESS"},{"location":"utilities/idempotency/#bring-your-own-persistent-store","title":"Bring your own persistent store","text":"<p>This utility provides an abstract base class, so that you can implement your choice of persistent storage layer.</p> <p>You can extend the <code>BasePersistenceStore</code> class and implement the abstract methods <code>getRecord</code>, <code>putRecord</code>, <code>updateRecord</code> and <code>deleteRecord</code>. You can have a look at <code>DynamoDBPersistenceStore</code> as an implementation reference.</p> <p>Danger</p> <p>Pay attention to the documentation for each method - you may need to perform additional checks inside these methods to ensure the idempotency guarantees remain intact.</p> <p>For example, the <code>putRecord</code> method needs to throw an exception if a non-expired record already exists in the data store with a matching key.</p>"},{"location":"utilities/idempotency/#compatibility-with-other-utilities","title":"Compatibility with other utilities","text":""},{"location":"utilities/idempotency/#validation-utility","title":"Validation utility","text":"<p>The idempotency utility can be used with the <code>@Validation</code> annotation from the validation module. Ensure that idempotency is the innermost annotation.</p> Using Idempotency with JSONSchema Validation utility<pre><code>@Validation(inboundSchema = \"classpath:/schema_in.json\")\n@Idempotent\npublic APIGatewayProxyResponseEvent handleRequest(APIGatewayProxyRequestEvent input, Context context) {\n// ...\n}\n</code></pre> <p>Tip: JMESPath Powertools functions are also available</p> <p>Built-in functions like <code>powertools_json</code>, <code>powertools_base64</code>, <code>powertools_base64_gzip</code> are also available to use in this utility. See JMESPath Powertools functions</p>"},{"location":"utilities/idempotency/#testing-your-code","title":"Testing your code","text":"<p>The idempotency utility provides several routes to test your code.</p>"},{"location":"utilities/idempotency/#disabling-the-idempotency-utility","title":"Disabling the idempotency utility","text":"<p>When testing your code, you may wish to disable the idempotency logic altogether and focus on testing your business logic. To do this, you can set the environment variable <code>POWERTOOLS_IDEMPOTENCY_DISABLED</code> to true.  If you prefer setting this for specific tests, and are using JUnit 5, you can use junit-pioneer library:</p> MyFunctionTest.java <pre><code>@Test\n@SetEnvironmentVariable(key = Constants.IDEMPOTENCY_DISABLED_ENV, value = \"true\")\npublic void testIdempotencyDisabled_shouldJustRunTheFunction() {\nMyFunction func = new MyFunction();\nfunc.handleRequest(someInput, mockedContext);\n}\n</code></pre> <p>You can also disable the idempotency for all tests using <code>maven-surefire-plugin</code> and adding the environment variable:</p> pom.xml <pre><code>&lt;plugin&gt;\n&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n&lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;\n&lt;configuration&gt;\n&lt;environmentVariables&gt;\n&lt;POWERTOOLS_IDEMPOTENCY_DISABLED&gt;true&lt;/POWERTOOLS_IDEMPOTENCY_DISABLED&gt;\n&lt;/environmentVariables&gt;\n&lt;/configuration&gt;\n&lt;/plugin&gt;\n</code></pre>"},{"location":"utilities/idempotency/#testing-with-dynamodb-local","title":"Testing with DynamoDB Local","text":""},{"location":"utilities/idempotency/#unit-tests","title":"Unit tests","text":"<p>To unit test your function with DynamoDB Local, you can refer to this guide to setup with Maven.</p> pom.xmlAppTest.javaApp.java <pre><code>&lt;dependencies&gt;\n&lt;!-- maven dependency for DynamoDB local --&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.amazonaws&lt;/groupId&gt;\n&lt;artifactId&gt;DynamoDBLocal&lt;/artifactId&gt;\n&lt;version&gt;[1.12,2.0)&lt;/version&gt;\n&lt;scope&gt;test&lt;/scope&gt;\n&lt;/dependency&gt;\n&lt;!-- Needed when building locally on M1 Mac --&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;io.github.ganadist.sqlite4java&lt;/groupId&gt;\n&lt;artifactId&gt;libsqlite4java-osx-aarch64&lt;/artifactId&gt;\n&lt;version&gt;1.0.392&lt;/version&gt;\n&lt;scope&gt;test&lt;/scope&gt;\n&lt;type&gt;dylib&lt;/type&gt;\n&lt;/dependency&gt;\n&lt;/dependencies&gt;\n&lt;repositories&gt;\n&lt;!-- custom repository to get the dependency --&gt;\n&lt;!-- see https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBLocal.DownloadingAndRunning.html#apache-maven --&gt;\n&lt;repository&gt;\n&lt;id&gt;dynamodb-local-oregon&lt;/id&gt;\n&lt;name&gt;DynamoDB Local Release Repository&lt;/name&gt;\n&lt;url&gt;https://s3-us-west-2.amazonaws.com/dynamodb-local/release&lt;/url&gt;\n&lt;/repository&gt;\n&lt;/repositories&gt;\n&lt;plugins&gt;\n&lt;plugin&gt;\n&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n&lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;\n&lt;version&gt;3.0.0-M5&lt;/version&gt;\n&lt;configuration&gt;\n&lt;!-- need sqlite native libs --&gt;\n&lt;systemPropertyVariables&gt;\n&lt;sqlite4java.library.path&gt;${project.build.directory}/native-libs&lt;/sqlite4java.library.path&gt;\n&lt;/systemPropertyVariables&gt;\n&lt;!-- environment variables for the tests --&gt;\n&lt;environmentVariables&gt;\n&lt;IDEMPOTENCY_TABLE_NAME&gt;idempotency&lt;/IDEMPOTENCY_TABLE_NAME&gt;\n&lt;AWS_REGION&gt;eu-central-1&lt;/AWS_REGION&gt;\n&lt;/environmentVariables&gt;\n&lt;/configuration&gt;\n&lt;/plugin&gt;\n&lt;plugin&gt;\n&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n&lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt;\n&lt;executions&gt;\n&lt;execution&gt;\n&lt;id&gt;copy&lt;/id&gt;\n&lt;phase&gt;test-compile&lt;/phase&gt;\n&lt;goals&gt;\n&lt;goal&gt;copy-dependencies&lt;/goal&gt;\n&lt;/goals&gt;\n&lt;configuration&gt;\n&lt;includeScope&gt;test&lt;/includeScope&gt;\n&lt;includeTypes&gt;so,dll,dylib&lt;/includeTypes&gt;\n&lt;outputDirectory&gt;${project.build.directory}/native-libs&lt;/outputDirectory&gt;\n&lt;/configuration&gt;\n&lt;/execution&gt;\n&lt;/executions&gt;\n&lt;/plugin&gt;\n&lt;/plugins&gt;\n</code></pre> <pre><code>public class AppTest {\n@Mock\nprivate Context context;\nprivate App app;\nprivate static DynamoDbClient client;\n\n@BeforeAll\npublic static void setupDynamoLocal() {\nint port = getFreePort();\n\n// Initialize DynamoDBLocal\ntry {\nDynamoDBProxyServer dynamoProxy = ServerRunner.createServerFromCommandLineArgs(new String[]{\n\"-inMemory\",\n\"-port\",\nInteger.toString(port)\n});\ndynamoProxy.start();\n} catch (Exception e) {\nthrow new RuntimeException();\n}\n\n// Initialize DynamoDBClient\nclient = DynamoDbClient.builder()\n.httpClient(UrlConnectionHttpClient.builder().build())\n.region(Region.EU_WEST_1)\n.endpointOverride(URI.create(\"http://localhost:\" + port))\n.credentialsProvider(StaticCredentialsProvider.create(\nAwsBasicCredentials.create(\"FAKE\", \"FAKE\")))\n.build();\n// create the table (use same table name as in pom.xml)\nclient.createTable(CreateTableRequest.builder()\n.tableName(\"idempotency\")\n.keySchema(KeySchemaElement.builder().keyType(KeyType.HASH).attributeName(\"id\").build())\n.attributeDefinitions(\nAttributeDefinition.builder().attributeName(\"id\").attributeType(ScalarAttributeType.S).build()\n)\n.billingMode(BillingMode.PAY_PER_REQUEST)\n.build());\n}\n\nprivate static int getFreePort() {\ntry {\nServerSocket socket = new ServerSocket(0);\nint port = socket.getLocalPort();\nsocket.close();\nreturn port;\n} catch (IOException ioe) {\nthrow new RuntimeException(ioe);\n}\n}\n\n@BeforeEach\nvoid setUp() {\nMockitoAnnotations.openMocks(this);\napp = new App(client);\n}\n\n@Test\npublic void testApp() {\napp.handleRequest(..., context);\n// ... assert\n}\n}\n</code></pre> <pre><code>public class App implements RequestHandler&lt;Subscription, SubscriptionResult&gt; {\n\npublic App(DynamoDbClient ddbClient) {\nIdempotency.config().withPersistenceStore(\nDynamoDBPersistenceStore.builder()\n.withTableName(System.getenv(\"IDEMPOTENCY_TABLE_NAME\"))\n.withDynamoDbClient(ddbClient)\n.build()\n).configure();\n}\n\npublic App() {\nthis(null);\n}\n\n@Idempotent\npublic SubscriptionResult handleRequest(final Subscription event, final Context context) {\n// ...\n}\n</code></pre>"},{"location":"utilities/idempotency/#sam-local","title":"SAM Local","text":"App.javashellenv.json <pre><code>public class App implements RequestHandler&lt;Subscription, SubscriptionResult&gt; {\n\npublic App() {\nDynamoDbClientBuilder ddbBuilder = DynamoDbClient.builder()\n.credentialsProvider(EnvironmentVariableCredentialsProvider.create())\n.httpClient(UrlConnectionHttpClient.builder().build());\n\nif (System.getenv(\"AWS_SAM_LOCAL\") != null) {\nddbBuilder.endpointOverride(URI.create(\"http://dynamo:8000\"));\n} else {\nddbBuilder.region(Region.of(System.getenv(\"AWS_REGION\")));\n}\n\nIdempotency.config().withPersistenceStore(\nDynamoDBPersistenceStore.builder()\n.withTableName(System.getenv(\"IDEMPOTENCY_TABLE_NAME\"))\n.withDynamoDbClient(ddbBuilder.build())\n.build()\n).configure();\n}\n\n@Idempotent\npublic SubscriptionResult handleRequest(final Subscription event, final Context context) {\n// ...\n}\n}\n</code></pre> <pre><code># use or create a docker network \ndocker network inspect sam-local || docker network create sam-local\n\n# start dynamodb-local with docker\ndocker run -d --rm -p 8000:8000 \\\n--network sam-local \\\n--name dynamo \\\namazon/dynamodb-local\n\n# create the idempotency table\naws dynamodb create-table --table-name idempotency \\\n--attribute-definitions AttributeName=id,AttributeType=S \\\n--key-schema AttributeName=id,KeyType=HASH \\\n--billing-mode PAY_PER_REQUEST \\\n--endpoint-url http://localhost:8000\n\n# invoke the function locally\nsam local invoke IdempotentFunction \\\n--event event.json \\\n--env-vars env.json \\\n--docker-network sam-local\n</code></pre> <pre><code>{\n\"IdempotentFunction\": {\n\"IDEMPOTENCY_TABLE_NAME\": \"idempotency\"\n}\n}\n</code></pre>"},{"location":"utilities/idempotency/#extra-resources","title":"Extra resources","text":"<p>If you're interested in a deep dive on how Amazon uses idempotency when building our APIs, check out this article.</p>"},{"location":"utilities/parameters/","title":"Parameters","text":"<p>The parameters utility provides a way to retrieve parameter values from AWS Systems Manager Parameter Store or AWS Secrets Manager. It also provides a base class to create your parameter provider implementation.</p> <p>Key features</p> <ul> <li>Retrieve one or multiple parameters from the underlying provider</li> <li>Cache parameter values for a given amount of time (defaults to 5 seconds)</li> <li>Transform parameter values from JSON or base 64 encoded strings</li> </ul>"},{"location":"utilities/parameters/#install","title":"Install","text":"<p>To install this utility, add the following dependency to your project.</p> MavenGradle <pre><code>&lt;dependency&gt;\n&lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n&lt;artifactId&gt;powertools-parameters&lt;/artifactId&gt;\n&lt;version&gt;1.10.3&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> <pre><code> dependencies {\n...\naspect 'software.amazon.lambda:powertools-parameters:1.10.3'\n}\n</code></pre> <p>IAM Permissions</p> <p>This utility requires additional permissions to work as expected. See the table below:</p> Provider Function/Method IAM Permission SSM Parameter Store <code>SSMProvider.get(String)</code> <code>SSMProvider.get(String, Class)</code> <code>ssm:GetParameter</code> SSM Parameter Store <code>SSMProvider.getMultiple(String)</code> <code>ssm:GetParametersByPath</code> Secrets Manager <code>SecretsProvider.get(String)</code> <code>SecretsProvider.get(String, Class)</code> <code>secretsmanager:GetSecretValue</code>"},{"location":"utilities/parameters/#ssm-parameter-store","title":"SSM Parameter Store","text":"<p>You can retrieve a single parameter using SSMProvider.get() and pass the key of the parameter. For multiple parameters, you can use SSMProvider.getMultiple() and pass the path to retrieve them all.</p> <p>Alternatively, you can retrieve an instance of a provider and configure its underlying SDK client, in order to get data from other regions or use specific credentials.</p> SSMProviderSSMProvider with an explicit region <pre><code>import software.amazon.lambda.powertools.parameters.SSMProvider;\nimport software.amazon.lambda.powertools.parameters.ParamManager;\n\npublic class AppWithSSM implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n// Get an instance of the SSM Provider\nSSMProvider ssmProvider = ParamManager.getSsmProvider();\n// Retrieve a single parameter\nString value = ssmProvider.get(\"/my/parameter\");\n\n// Retrieve multiple parameters from a path prefix\n// This returns a Map with the parameter name as key\nMap&lt;String, String&gt; values = ssmProvider.getMultiple(\"/my/path/prefix\");\n\n}\n</code></pre> <pre><code>import software.amazon.lambda.powertools.parameters.SSMProvider;\nimport software.amazon.lambda.powertools.parameters.ParamManager;\n\npublic class AppWithSSM implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\nSsmClient client = SsmClient.builder().region(Region.EU_CENTRAL_1).build();\n// Get an instance of the SSM Provider\nSSMProvider ssmProvider = ParamManager.getSsmProvider(client);\n// Retrieve a single parameter\nString value = ssmProvider.get(\"/my/parameter\");\n\n// Retrieve multiple parameters from a path prefix\n// This returns a Map with the parameter name as key\nMap&lt;String, String&gt; values = ssmProvider.getMultiple(\"/my/path/prefix\");\n\n}\n</code></pre>"},{"location":"utilities/parameters/#additional-arguments","title":"Additional arguments","text":"<p>The AWS Systems Manager Parameter Store provider supports two additional arguments for the <code>get()</code> and <code>getMultiple()</code> methods:</p> Option Default Description withDecryption() <code>False</code> Will automatically decrypt the parameter. recursive() <code>False</code> For <code>getMultiple()</code> only, will fetch all parameter values recursively based on a path prefix. <p>Example:</p> AppWithSSM.java <pre><code>import software.amazon.lambda.powertools.parameters.SSMProvider;\nimport software.amazon.lambda.powertools.parameters.ParamManager;\n\npublic class AppWithSSM implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n// Get an instance of the SSM Provider\nSSMProvider ssmProvider = ParamManager.getSsmProvider();\n\n// Retrieve a single parameter and decrypt it\nString value = ssmProvider.withDecryption().get(\"/my/parameter\");\n// Retrieve multiple parameters recursively from a path prefix\nMap&lt;String, String&gt; values = ssmProvider.recursive().getMultiple(\"/my/path/prefix\");\n}\n</code></pre>"},{"location":"utilities/parameters/#secrets-manager","title":"Secrets Manager","text":"<p>For secrets stored in Secrets Manager, use <code>getSecretsProvider</code>.</p> <p>Alternatively, you can retrieve an instance of a provider and configure its underlying SDK client, in order to get data from other regions or use specific credentials.</p> SecretsProviderSecretsProvider with an explicit region <pre><code>import software.amazon.lambda.powertools.parameters.SecretsProvider;\nimport software.amazon.lambda.powertools.parameters.ParamManager;\n\npublic class AppWithSecrets implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n// Get an instance of the Secrets Provider\nSecretsProvider secretsProvider = ParamManager.getSecretsProvider();\n\n// Retrieve a single secret\nString value = secretsProvider.get(\"/my/secret\");\n}\n</code></pre> <pre><code>import software.amazon.lambda.powertools.parameters.SecretsProvider;\nimport software.amazon.lambda.powertools.parameters.ParamManager;\n\npublic class AppWithSecrets implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\nSecretsManagerClient client = SecretsManagerClient.builder().region(Region.EU_CENTRAL_1).build();\n// Get an instance of the Secrets Provider\nSecretsProvider secretsProvider = ParamManager.getSecretsProvider(client);\n// Retrieve a single secret\nString value = secretsProvider.get(\"/my/secret\");\n\n}\n</code></pre>"},{"location":"utilities/parameters/#advanced-configuration","title":"Advanced configuration","text":""},{"location":"utilities/parameters/#caching","title":"Caching","text":"<p>By default, all parameters and their corresponding values are cached for 5 seconds.</p> <p>You can customize this default value using <code>defaultMaxAge</code>. You can also customize this value for each parameter using  <code>withMaxAge</code>.</p> Provider with default Max ageProvider with age for each param <pre><code>import software.amazon.lambda.powertools.parameters.SecretsProvider;\nimport software.amazon.lambda.powertools.parameters.ParamManager;\n\npublic class AppWithSecrets implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n// Get an instance of the Secrets Provider\nSecretsProvider secretsProvider = ParamManager.getSecretsProvider()\n.defaultMaxAge(10, ChronoUnit.SECONDS);\n\nString value = secretsProvider.get(\"/my/secret\");\n}\n</code></pre> <pre><code>import software.amazon.lambda.powertools.parameters.SecretsProvider;\nimport software.amazon.lambda.powertools.parameters.ParamManager;\n\npublic class AppWithSecrets implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\nSecretsManagerClient client = SecretsManagerClient.builder().region(Region.EU_CENTRAL_1).build();\n\nSecretsProvider secretsProvider = ParamManager.getSecretsProvider(client);\nString value = secretsProvider.withMaxAge(10, ChronoUnit.SECONDS).get(\"/my/secret\");\n\n}\n</code></pre>"},{"location":"utilities/parameters/#transform-values","title":"Transform values","text":"<p>Parameter values can be transformed using <code>withTransformation(transformerClass)</code>. Base64 and JSON transformations are provided. For more complex transformation, you need to specify how to deserialize-</p> <p><code>SSMProvider.getMultiple()</code> does not support transformation and will return simple Strings.</p> Base64 TransformationComplex Transformation <pre><code>   String value = provider\n.withTransformation(Transformer.base64)\n.get(\"/my/parameter/b64\");\n</code></pre> <pre><code>   MyObj object = provider\n.withTransformation(Transformer.json)\n.get(\"/my/parameter/json\", MyObj.class);\n</code></pre>"},{"location":"utilities/parameters/#write-your-own-transformer","title":"Write your own Transformer","text":"<p>You can write your own transformer, by implementing the <code>Transformer</code> interface and the <code>applyTransformation()</code> method. For example, if you wish to deserialize XML into an object.</p> XmlTransformer.javaUsing XmlTransformer <pre><code>public class XmlTransformer&lt;T&gt; implements Transformer&lt;T&gt; {\nprivate final XmlMapper mapper = new XmlMapper();\n\n@Override\npublic T applyTransformation(String value, Class&lt;T&gt; targetClass) throws TransformationException {\ntry {\nreturn mapper.readValue(value, targetClass);\n} catch (IOException e) {\nthrow new TransformationException(e);\n}\n}\n}\n</code></pre> <pre><code>    MyObj object = provider\n.withTransformation(XmlTransformer.class)\n.get(\"/my/parameter/xml\", MyObj.class);\n</code></pre>"},{"location":"utilities/parameters/#fluent-api","title":"Fluent API","text":"<p>To simplify the use of the library, you can chain all method calls before a get.</p> Fluent API call <pre><code>    ssmProvider\n.defaultMaxAge(10, SECONDS)     // will set 10 seconds as the default cache TTL\n.withMaxAge(1, MINUTES)         // will set the cache TTL for this value at 1 minute\n.withTransformation(json)       // json is a static import from Transformer.json\n.withDecryption()               // enable decryption of the parameter value\n.get(\"/my/param\", MyObj.class); // finally get the value\n</code></pre>"},{"location":"utilities/parameters/#create-your-own-provider","title":"Create your own provider","text":"<p>You can create your own custom parameter store provider by inheriting the <code>BaseProvider</code> class and implementing the <code>String getValue(String key)</code> method to retrieve data from your underlying store. All transformation and caching logic is handled by the get() methods in the base class.</p> Example implementation using S3 as a custom parameterUsing custom parameter store <pre><code>public class S3Provider extends BaseProvider {\n\nprivate final S3Client client;\nprivate String bucket;\n\nS3Provider(CacheManager cacheManager) {\nthis(cacheManager, S3Client.create());\n}\n\nS3Provider(CacheManager cacheManager, S3Client client) {\nsuper(cacheManager);\nthis.client = client;\n}\n\npublic S3Provider withBucket(String bucket) {\nthis.bucket = bucket;\nreturn this;\n}\n\n@Override\nprotected String getValue(String key) {\nif (bucket == null) {\nthrow new IllegalStateException(\"A bucket must be specified, using withBucket() method\");\n}\n\nGetObjectRequest request = GetObjectRequest.builder().bucket(bucket).key(key).build();\nResponseBytes&lt;GetObjectResponse&gt; response = client.getObject(request, ResponseTransformer.toBytes());\nreturn response.asUtf8String();\n}\n\n@Override\nprotected Map&lt;String, String&gt; getMultipleValues(String path) {\nif (bucket == null) {\nthrow new IllegalStateException(\"A bucket must be specified, using withBucket() method\");\n}\n\nListObjectsV2Request listRequest = ListObjectsV2Request.builder().bucket(bucket).prefix(path).build();\nList&lt;S3Object&gt; s3Objects = client.listObjectsV2(listRequest).contents();\n\nMap&lt;String, String&gt; result = new HashMap&lt;&gt;();\ns3Objects.forEach(s3Object -&gt; {\nresult.put(s3Object.key(), getValue(s3Object.key()));\n});\n\nreturn result;\n}\n\n@Override\nprotected void resetToDefaults() {\nsuper.resetToDefaults();\nbucket = null;\n}\n\n}\n</code></pre> <pre><code>    S3Provider provider = new S3Provider(ParamManager.getCacheManager());\n\nprovider.setTransformationManager(ParamManager.getTransformationManager());\nString value = provider.withBucket(\"myBucket\").get(\"myKey\");\n</code></pre>"},{"location":"utilities/parameters/#annotation","title":"Annotation","text":"<p>You can make use of the annotation <code>@Param</code> to inject a parameter value in a variable.</p> <p>By default, it will use <code>SSMProvider</code> to retrieve the value from AWS System Manager Parameter Store. You could specify a different provider as long as it extends <code>BaseProvider</code> and/or a <code>Transformer</code>.</p> Param AnnotationCustom Provider Usage <pre><code>public class AppWithAnnotation implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n@Param(key = \"/my/parameter/json\")\nObjectToDeserialize value;\n\n}\n</code></pre> <pre><code>public class AppWithAnnotation implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n@Param(key = \"/my/parameter/json\" provider = SecretsProvider.class, transformer = JsonTransformer.class)\nObjectToDeserialize value;\n\n}\n</code></pre> <p>In this case <code>SecretsProvider</code> will be used to retrieve a raw value that is then trasformed into the target Object by using <code>JsonTransformer</code>. To show the convenience of the annotation compare the following two code snippets.</p>"},{"location":"utilities/parameters/#install_1","title":"Install","text":"<p>If you want to use the <code>@Param</code> annotation in your project add configuration to compile-time weave (CTW) the powertools-parameters aspects into your project.</p> MavenGradle <pre><code>&lt;build&gt;\n&lt;plugins&gt;\n...\n        &lt;plugin&gt;\n&lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;\n&lt;artifactId&gt;aspectj-maven-plugin&lt;/artifactId&gt;\n&lt;version&gt;1.14.0&lt;/version&gt;\n&lt;configuration&gt;\n...\n                 &lt;aspectLibraries&gt;\n...\n                     &lt;aspectLibrary&gt;\n&lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n&lt;artifactId&gt;powertools-parameters&lt;/artifactId&gt;\n&lt;/aspectLibrary&gt;\n&lt;/aspectLibraries&gt;\n&lt;/configuration&gt;\n&lt;executions&gt;\n&lt;execution&gt;\n&lt;goals&gt;\n&lt;goal&gt;compile&lt;/goal&gt;\n&lt;/goals&gt;\n&lt;/execution&gt;\n&lt;/executions&gt;\n&lt;/plugin&gt;\n...\n    &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> <pre><code>plugins{\nid 'java'\nid 'io.freefair.aspectj.post-compile-weaving' version '6.3.0'\n}\n\nrepositories {\nmavenCentral()\n}\n\ndependencies {\n...\naspect 'software.amazon.lambda:powertools-parameters:1.10.3'\n}\n</code></pre>"},{"location":"utilities/serialization/","title":"Serialization Utilities","text":"<p>This module contains a set of utilities you may use in your Lambda functions, mainly associated with other modules like validation and idempotency, to manipulate JSON.</p>"},{"location":"utilities/serialization/#jmespath-functions","title":"JMESPath functions","text":"<p>Tip</p> <p>JMESPath is a query language for JSON used by AWS CLI and AWS Lambda Powertools for Java to get a specific part of a json.</p>"},{"location":"utilities/serialization/#key-features","title":"Key features","text":"<ul> <li>Deserialize JSON from JSON strings, base64, and compressed data</li> <li>Use JMESPath to extract and combine data recursively</li> </ul>"},{"location":"utilities/serialization/#getting-started","title":"Getting started","text":"<p>You might have events that contain encoded JSON payloads as string, base64, or even in compressed format. It is a common use case to decode and extract them partially or fully as part of your Lambda function invocation.</p> <p>You will generally use this in combination with other Lambda Powertools modules (validation and idempotency) where you might need to extract a portion of your data before using them.</p>"},{"location":"utilities/serialization/#built-in-functions","title":"Built-in functions","text":"<p>Powertools provides the following JMESPath Functions to easily deserialize common encoded JSON payloads in Lambda functions:</p>"},{"location":"utilities/serialization/#powertools_json-function","title":"powertools_json function","text":"<p>Use <code>powertools_json</code> function to decode any JSON string anywhere a JMESPath expression is allowed.</p> <p>Below example use this function to load the content from the body of an API Gateway request event as a JSON object and retrieve the id field in it:</p> MyHandler.javaevent <pre><code>public class MyHandler implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\npublic MyHandler() {\nIdempotency.config()\n.withConfig(\nIdempotencyConfig.builder()\n.withEventKeyJMESPath(\"powertools_json(body).id\")\n.build())\n.withPersistenceStore(\nDynamoDBPersistenceStore.builder()\n.withTableName(System.getenv(\"TABLE_NAME\"))\n.build())\n.configure();\n}\n\n@Idempotent\npublic APIGatewayProxyResponseEvent handleRequest(final APIGatewayProxyRequestEvent event, final Context context) {\n}\n</code></pre> <pre><code>{\n\"body\": \"{\\\"message\\\": \\\"Lambda rocks\\\", \\\"id\\\": 43876123454654}\",\n\"resource\": \"/{proxy+}\",\n\"path\": \"/path/to/resource\",\n\"httpMethod\": \"POST\",\n\"queryStringParameters\": {\n\"foo\": \"bar\"\n},\n\"headers\": {\n\"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n\"Accept-Encoding\": \"gzip, deflate, sdch\",\n\"Accept-Language\": \"en-US,en;q=0.8\",\n\"Cache-Control\": \"max-age=0\",\n},\n\"requestContext\": {\n\"accountId\": \"123456789012\",\n\"resourceId\": \"123456\",\n\"stage\": \"prod\",\n\"requestId\": \"c6af9ac6-7b61-11e6-9a41-93e8deadbeef\",\n\"requestTime\": \"09/Apr/2015:12:34:56 +0000\",\n\"requestTimeEpoch\": 1428582896000,\n\"identity\": {\n\"cognitoIdentityPoolId\": null,\n\"accountId\": null,\n\"cognitoIdentityId\": null,\n\"caller\": null,\n\"accessKey\": null,\n\"sourceIp\": \"127.0.0.1\",\n\"cognitoAuthenticationType\": null,\n\"cognitoAuthenticationProvider\": null,\n\"userArn\": null,\n\"userAgent\": \"Custom User Agent String\",\n\"user\": null\n},\n\"path\": \"/prod/path/to/resource\",\n\"resourcePath\": \"/{proxy+}\",\n\"httpMethod\": \"POST\",\n\"apiId\": \"1234567890\",\n\"protocol\": \"HTTP/1.1\"\n}\n}\n</code></pre>"},{"location":"utilities/serialization/#powertools_base64-function","title":"powertools_base64 function","text":"<p>Use <code>powertools_base64</code> function to decode any base64 data.</p> <p>Below sample will decode the base64 value within the <code>data</code> key, and decode the JSON string into a valid JSON before we can validate it.</p> MyEventHandler.javaschema.json <pre><code>import software.amazon.lambda.powertools.validation.ValidationUtils;\n\npublic class MyEventHandler implements RequestHandler&lt;MyEvent, String&gt; {\n\n@Override\npublic String handleRequest(MyEvent myEvent, Context context) {\nvalidate(myEvent, \"classpath:/schema.json\", \"powertools_base64(data)\");\nreturn \"OK\";\n}\n}\n</code></pre> <pre><code>{\n\"data\" : \"ewogICJpZCI6IDQzMjQyLAogICJuYW1lIjogIkZvb0JhciBYWSIsCiAgInByaWNlIjogMjU4Cn0=\"\n}\n</code></pre>"},{"location":"utilities/serialization/#powertools_base64_gzip-function","title":"powertools_base64_gzip function","text":"<p>Use <code>powertools_base64_gzip</code> function to decompress and decode base64 data.</p> <p>Below sample will decompress and decode base64 data.</p> MyEventHandler.javaschema.json <pre><code>import software.amazon.lambda.powertools.validation.ValidationUtils;\n\npublic class MyEventHandler implements RequestHandler&lt;MyEvent, String&gt; {\n\n@Override\npublic String handleRequest(MyEvent myEvent, Context context) {\nvalidate(myEvent, \"classpath:/schema.json\", \"powertools_base64_gzip(data)\");\nreturn \"OK\";\n}\n}\n</code></pre> <pre><code>{\n\"data\" : \"H4sIAAAAAAAA/6vmUlBQykxRslIwMTYyMdIBcfMSc1OBAkpu+flOiUUKEZFKYOGCosxkkLiRqQVXLQDnWo6bOAAAAA==\"\n}\n</code></pre>"},{"location":"utilities/serialization/#bring-your-own-jmespath-function","title":"Bring your own JMESPath function","text":"<p>Warning</p> <p>This should only be used for advanced use cases where you have special formats not covered by the built-in functions. Please open an issue in Github if you need us to add some common functions.</p> <p>Your function must extend <code>io.burt.jmespath.function.BaseFunction</code>, take a String as parameter and return a String. You can read the doc for more information.</p> <p>Below is an example that takes some xml and transform it into json. Once your function is created, you need to add it to powertools.You can then use it to do your validation or in idempotency module.</p> XMLFunction.javaHandler with validation APIHandler with validation annotation <pre><code>public class XMLFunction extends BaseFunction {\npublic Base64Function() {\nsuper(\"powertools_xml\", ArgumentConstraints.typeOf(JmesPathType.STRING));\n}\n\n@Override\nprotected &lt;T&gt; T callFunction(Adapter&lt;T&gt; runtime, List&lt;FunctionArgument&lt;T&gt;&gt; arguments) {\nT value = arguments.get(0).value();\nString xmlString = runtime.toString(value);\n\nString jsonString =  // ... transform xmlString to json\n\nreturn runtime.createString(jsonString);\n}\n}\n</code></pre> <pre><code>...\nimport software.amazon.lambda.powertools.validation.ValidationConfig;\nimport software.amazon.lambda.powertools.validation.ValidationUtils.validate;\n\nstatic {\nJsonConfig.get().addFunction(new XMLFunction());\n}\n\npublic class MyXMLEventHandler implements RequestHandler&lt;MyEventWithXML, String&gt; {\n\n@Override\npublic String handleRequest(MyEventWithXML myEvent, Context context) {\nvalidate(myEvent, \"classpath:/schema.json\", \"powertools_xml(path.to.xml_data)\");\nreturn \"OK\";\n}\n}\n</code></pre> <pre><code>...\nimport software.amazon.lambda.powertools.validation.ValidationConfig;\nimport software.amazon.lambda.powertools.validation.Validation;\n\nstatic {\nJsonConfig.get().addFunction(new XMLFunction());\n}\n\npublic class MyXMLEventHandler implements RequestHandler&lt;MyEventWithXML, String&gt; {\n\n@Override\n@Validation(inboundSchema=\"classpath:/schema.json\", envelope=\"powertools_xml(path.to.xml_data)\")\npublic String handleRequest(MyEventWithXML myEvent, Context context) {\nreturn \"OK\";\n}\n}\n</code></pre>"},{"location":"utilities/sqs_large_message_handling/","title":"SQS Large Message Handling","text":"<p>The large message handling utility handles SQS messages which have had their payloads offloaded to S3 due to them being larger than the SQS maximum.</p> <p>The utility automatically retrieves messages which have been offloaded to S3 using the amazon-sqs-java-extended-client-lib client library. Once the message payloads have been processed successful the utility can delete the message payloads from S3.</p> <p>This utility is compatible with versions 1.1.0+ of amazon-sqs-java-extended-client-lib.</p> MavenGradle <pre><code>&lt;dependency&gt;\n&lt;groupId&gt;com.amazonaws&lt;/groupId&gt;\n&lt;artifactId&gt;amazon-sqs-java-extended-client-lib&lt;/artifactId&gt;\n&lt;version&gt;1.1.0&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> <pre><code> dependencies {\nimplementation 'com.amazonaws:amazon-sqs-java-extended-client-lib:1.1.0'\n}\n</code></pre>"},{"location":"utilities/sqs_large_message_handling/#install","title":"Install","text":"<p>To install this utility, add the following dependency to your project.</p> MavenGradle <pre><code>&lt;dependencies&gt;\n...\n    &lt;dependency&gt;\n&lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n&lt;artifactId&gt;powertools-sqs&lt;/artifactId&gt;\n&lt;version&gt;1.10.3&lt;/version&gt;\n&lt;/dependency&gt;\n...\n&lt;/dependencies&gt;\n&lt;!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --&gt;\n&lt;build&gt;\n&lt;plugins&gt;\n...\n        &lt;plugin&gt;\n&lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;\n&lt;artifactId&gt;aspectj-maven-plugin&lt;/artifactId&gt;\n&lt;version&gt;1.14.0&lt;/version&gt;\n&lt;configuration&gt;\n&lt;source&gt;1.8&lt;/source&gt;\n&lt;target&gt;1.8&lt;/target&gt;\n&lt;complianceLevel&gt;1.8&lt;/complianceLevel&gt;\n&lt;aspectLibraries&gt;\n&lt;aspectLibrary&gt;\n&lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n&lt;artifactId&gt;powertools-sqs&lt;/artifactId&gt;\n&lt;/aspectLibrary&gt;\n&lt;/aspectLibraries&gt;\n&lt;/configuration&gt;\n&lt;executions&gt;\n&lt;execution&gt;\n&lt;goals&gt;\n&lt;goal&gt;compile&lt;/goal&gt;\n&lt;/goals&gt;\n&lt;/execution&gt;\n&lt;/executions&gt;\n&lt;/plugin&gt;\n...\n    &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> <pre><code>plugins{\nid 'java'\nid 'io.freefair.aspectj.post-compile-weaving' version '6.3.0'\n}\n\nrepositories {\nmavenCentral()\n}\n\ndependencies {\n...\naspect 'software.amazon.lambda:powertools-sqs:1.10.3'\n}\n</code></pre>"},{"location":"utilities/sqs_large_message_handling/#lambda-handler","title":"Lambda handler","text":"<p>The annotation <code>@SqsLargeMessage</code> should be used with the handleRequest method of a class which implements <code>com.amazonaws.services.lambda.runtime.RequestHandler</code> with <code>com.amazonaws.services.lambda.runtime.events.SQSEvent</code> as the first parameter.</p> SqsMessageHandler.java <pre><code>import software.amazon.lambda.powertools.sqs.SqsLargeMessage;\n\npublic class SqsMessageHandler implements RequestHandler&lt;SQSEvent, String&gt; {\n\n@Override\n@SqsLargeMessage\npublic String handleRequest(SQSEvent sqsEvent, Context context) {\n// process messages\n\nreturn \"ok\";\n}\n}\n</code></pre> <p><code>@SqsLargeMessage</code> creates a default S3 Client <code>AmazonS3 amazonS3 = AmazonS3ClientBuilder.defaultClient()</code>.</p> <p>Tip</p> <p>When the Lambda function is invoked with an event from SQS, each received record in the SQSEvent is checked to see to validate if it is offloaded to S3. If it does then <code>getObject(bucket, key)</code> will be called, and the payload retrieved.  If there is an error during this process then the function will fail with a <code>FailedProcessingLargePayloadException</code> exception.</p> <p>If the request handler method returns without error then each payload will be deleted from S3 using <code>deleteObject(bucket, key)</code></p> <p>To disable deletion of payloads setting the following annotation parameter:</p> Disable payload deletion <pre><code>import software.amazon.lambda.powertools.sqs.SqsLargeMessage;\n\n@SqsLargeMessage(deletePayloads=false)\npublic class SqsMessageHandler implements RequestHandler&lt;SQSEvent, String&gt; {\n\n}\n</code></pre>"},{"location":"utilities/sqs_large_message_handling/#utility","title":"Utility","text":"<p>If you want to avoid using annotation and have control over error that can happen during payload enrichment use <code>SqsUtils.enrichedMessageFromS3()</code>. It provides you access with list of <code>SQSMessage</code> object enriched from S3 payload.</p> <p>Original <code>SQSEvent</code> object is never mutated. You can also control if the S3 payload should be deleted after successful processing.</p> Functional API without annotation <pre><code>import software.amazon.lambda.powertools.sqs.SqsLargeMessage;\nimport software.amazon.lambda.powertools.sqs.SqsUtils;\n\npublic class SqsMessageHandler implements RequestHandler&lt;SQSEvent, String&gt; {\n\n@Override\npublic String handleRequest(SQSEvent sqsEvent, Context context) {\n\nMap&lt;String, String&gt; sqsMessage = SqsUtils.enrichedMessageFromS3(sqsEvent, sqsMessages -&gt; {\n// Some business logic\nMap&lt;String, String&gt; someBusinessLogic = new HashMap&lt;&gt;();\nsomeBusinessLogic.put(\"Message\", sqsMessages.get(0).getBody());\nreturn someBusinessLogic;\n});\n// Do not delete payload after processing.\nMap&lt;String, String&gt; sqsMessage = SqsUtils.enrichedMessageFromS3(sqsEvent, false, sqsMessages -&gt; {\n// Some business logic\nMap&lt;String, String&gt; someBusinessLogic = new HashMap&lt;&gt;();\nsomeBusinessLogic.put(\"Message\", sqsMessages.get(0).getBody());\nreturn someBusinessLogic;\n});\n// Better control over exception during enrichment\ntry {\n// Do not delete payload after processing.\nSqsUtils.enrichedMessageFromS3(sqsEvent, false, sqsMessages -&gt; {\n// Some business logic\n});\n} catch (FailedProcessingLargePayloadException e) {\n// handle any exception.\n}\n\nreturn \"ok\";\n}\n}\n</code></pre>"},{"location":"utilities/sqs_large_message_handling/#overriding-the-default-s3client","title":"Overriding the default S3Client","text":"<p>If you require customisations to the default S3Client, you can create your own <code>S3Client</code> and pass it to be used by utility either for SqsLargeMessage annotation, or SqsUtils Utility API.</p> App.java <pre><code>import software.amazon.lambda.powertools.sqs.SqsLargeMessage;\n\nstatic {\nSqsUtils.overrideS3Client(S3Client.builder()\n.build());\n}\n\npublic class SqsMessageHandler implements RequestHandler&lt;SQSEvent, String&gt; {\n\n@Override\n@SqsLargeMessage\npublic String handleRequest(SQSEvent sqsEvent, Context context) {\n// process messages\n\nreturn \"ok\";\n}\n}\n</code></pre>"},{"location":"utilities/validation/","title":"Validation","text":"<p>This utility provides JSON Schema validation for payloads held within events and response used in AWS Lambda.</p> <p>Key features</p> <ul> <li>Validate incoming events and responses</li> <li>Built-in validation for most common events (API Gateway, SNS, SQS, ...)</li> <li>JMESPath support validate only a sub part of the event</li> </ul>"},{"location":"utilities/validation/#install","title":"Install","text":"<p>To install this utility, add the following dependency to your project.</p> MavenGradle <pre><code>&lt;dependencies&gt;\n...\n&lt;dependency&gt;\n&lt;groupId&gt;com.amazonaws&lt;/groupId&gt;\n&lt;artifactId&gt;powertools-validation&lt;/artifactId&gt;\n&lt;version&gt;1.10.3&lt;/version&gt;\n&lt;/dependency&gt;\n...\n&lt;/dependencies&gt;\n&lt;!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --&gt;\n&lt;build&gt;\n&lt;plugins&gt;\n...\n        &lt;plugin&gt;\n&lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;\n&lt;artifactId&gt;aspectj-maven-plugin&lt;/artifactId&gt;\n&lt;version&gt;1.14.0&lt;/version&gt;\n&lt;configuration&gt;\n&lt;source&gt;1.8&lt;/source&gt;\n&lt;target&gt;1.8&lt;/target&gt;\n&lt;complianceLevel&gt;1.8&lt;/complianceLevel&gt;\n&lt;aspectLibraries&gt;\n&lt;aspectLibrary&gt;\n&lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n&lt;artifactId&gt;powertools-validation&lt;/artifactId&gt;\n&lt;/aspectLibrary&gt;\n&lt;/aspectLibraries&gt;\n&lt;/configuration&gt;\n&lt;executions&gt;\n&lt;execution&gt;\n&lt;goals&gt;\n&lt;goal&gt;compile&lt;/goal&gt;\n&lt;/goals&gt;\n&lt;/execution&gt;\n&lt;/executions&gt;\n&lt;/plugin&gt;\n...\n    &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> <pre><code>plugins{\nid 'java'\nid 'io.freefair.aspectj.post-compile-weaving' version '6.3.0'\n}\n\nrepositories {\nmavenCentral()\n}\n\ndependencies {\naspect 'software.amazon.lambda:powertools-validation:1.10.3'\n}\n</code></pre>"},{"location":"utilities/validation/#validating-events","title":"Validating events","text":"<p>You can validate inbound and outbound events using <code>@Validation</code> annotation.</p> <p>You can also use the <code>Validator#validate()</code> methods, if you want more control over the validation process such as handling a validation error.</p> <p>We support JSON schema version 4, 6, 7 and 201909 (from jmespath-jackson library).</p>"},{"location":"utilities/validation/#validation-annotation","title":"Validation annotation","text":"<p><code>@Validation</code> annotation is used to validate either inbound events or functions' response.</p> <p>It will fail fast with <code>ValidationException</code> if an event or response doesn't conform with given JSON Schema.</p> <p>While it is easier to specify a json schema file in the classpath (using the notation <code>\"classpath:/path/to/schema.json\"</code>), you can also provide a JSON String containing the schema.</p> MyFunctionHandler.java <pre><code>import software.amazon.lambda.powertools.validation.Validation;\n\npublic class MyFunctionHandler implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n@Override\n@Validation(inboundSchema = \"classpath:/schema_in.json\", outboundSchema = \"classpath:/schema_out.json\")\npublic APIGatewayProxyResponseEvent handleRequest(APIGatewayProxyRequestEvent input, Context context) {\n// ...\nreturn something;\n}\n}\n</code></pre> <p>NOTE: It's not a requirement to validate both inbound and outbound schemas - You can either use one, or both.</p>"},{"location":"utilities/validation/#validate-function","title":"Validate function","text":"<p>Validate standalone function is used within the Lambda handler, or any other methods that perform data validation.</p> <p>You can also gracefully handle schema validation errors by catching <code>ValidationException</code>.</p> MyFunctionHandler.java <pre><code>import static software.amazon.lambda.powertools.validation.ValidationUtils.*;\n\npublic class MyFunctionHandler implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n@Override\npublic APIGatewayProxyResponseEvent handleRequest(APIGatewayProxyRequestEvent input, Context context) {\ntry {\nvalidate(input, \"classpath:/schema.json\");\n} catch (ValidationException ex) {\n// do something before throwing it\nthrow ex;\n}\n\n// ...\nreturn something;\n}\n}\n</code></pre> <p>NOTE: Schemas are stored in memory for reuse, to avoid loading them from file each time.</p>"},{"location":"utilities/validation/#built-in-events-and-responses","title":"Built-in events and responses","text":"<p>For the following events and responses, the Validator will automatically perform validation on the content.</p> <p> Events </p> Type of event Class Path to content API Gateway REST APIGatewayProxyRequestEvent <code>body</code> API Gateway HTTP APIGatewayV2HTTPEvent <code>body</code> Application Load Balancer ApplicationLoadBalancerRequestEvent <code>body</code> Cloudformation Custom Resource CloudFormationCustomResourceEvent <code>resourceProperties</code> CloudWatch Logs CloudWatchLogsEvent <code>awslogs.powertools_base64_gzip(data)</code> EventBridge / Cloudwatch ScheduledEvent <code>detail</code> Kafka KafkaEvent <code>records[*][*].value</code> Kinesis KinesisEvent <code>Records[*].kinesis.powertools_base64(data)</code> Kinesis Firehose KinesisFirehoseEvent <code>Records[*].powertools_base64(data)</code> Kinesis Analytics from Firehose KinesisAnalyticsFirehoseInputPreprocessingEvent <code>Records[*].powertools_base64(data)</code> Kinesis Analytics from Streams KinesisAnalyticsStreamsInputPreprocessingEvent <code>Records[*].powertools_base64(data)</code> SNS SNSEvent <code>Records[*].Sns.Message</code> SQS SQSEvent <code>Records[*].body</code> <p> Responses </p> Type of response Class Path to content (envelope) API Gateway REST APIGatewayProxyResponseEvent} <code>body</code> API Gateway HTTP APIGatewayV2HTTPResponse} <code>body</code> API Gateway WebSocket APIGatewayV2WebSocketResponse} <code>body</code> Load Balancer ApplicationLoadBalancerResponseEvent} <code>body</code> Kinesis Analytics KinesisAnalyticsInputPreprocessingResponse} `Records[*].powertools_base64(data)``"},{"location":"utilities/validation/#custom-events-and-responses","title":"Custom events and responses","text":"<p>You can also validate any Event or Response type, once you have the appropriate schema.</p> <p>Sometimes, you might want to validate only a portion of it - This is where the envelope parameter is for.</p> <p>Envelopes are JMESPath expressions to extract a portion of JSON you want before applying JSON Schema validation.</p> MyCustomEventHandler.javamy_custom_event_schema.json <pre><code>import software.amazon.lambda.powertools.validation.Validation;\n\npublic class MyCustomEventHandler implements RequestHandler&lt;MyCustomEvent, String&gt; {\n\n@Override\n@Validation(inboundSchema = \"classpath:/my_custom_event_schema.json\",\nenvelope = \"basket.products[*]\")\npublic String handleRequest(MyCustomEvent input, Context context) {\nreturn \"OK\";\n}\n}\n</code></pre> <pre><code>{\n\"basket\": {\n\"products\" : [\n{\n\"id\": 43242,\n\"name\": \"FooBar XY\",\n\"price\": 258\n},\n{\n\"id\": 765,\n\"name\": \"BarBaz AB\",\n\"price\": 43.99\n}\n]\n}\n}\n</code></pre> <p>This is quite powerful because you can use JMESPath Query language to extract records from arrays, slice and dice, to pipe expressions and function expressions, where you'd extract what you need before validating the actual payload.</p>"},{"location":"utilities/validation/#change-the-schema-version","title":"Change the schema version","text":"<p>By default, powertools-validation is configured with V7. You can use the <code>ValidationConfig</code> to change that behaviour.</p> Handler with custom schema version <pre><code>...\nimport software.amazon.lambda.powertools.validation.ValidationConfig;\nimport software.amazon.lambda.powertools.validation.Validation;\n\nstatic {\nValidationConfig.get().setSchemaVersion(SpecVersion.VersionFlag.V4);\n}\n\npublic class MyXMLEventHandler implements RequestHandler&lt;MyEventWithXML, String&gt; {\n\n@Override\n@Validation(inboundSchema=\"classpath:/schema.json\", envelope=\"powertools_xml(path.to.xml_data)\")\npublic String handleRequest(MyEventWithXML myEvent, Context context) {\nreturn \"OK\";\n}\n}\n</code></pre>"},{"location":"utilities/validation/#advanced-objectmapper-settings","title":"Advanced ObjectMapper settings","text":"<p>If you need to configure the Jackson ObjectMapper, you can use the <code>ValidationConfig</code>:</p> Handler with custom ObjectMapper <pre><code>...\nimport software.amazon.lambda.powertools.validation.ValidationConfig;\nimport software.amazon.lambda.powertools.validation.Validation;\n\nstatic {\nObjectMapper objectMapper= ValidationConfig.get().getObjectMapper();\n// update (de)serializationConfig or other properties\n}\n\npublic class MyXMLEventHandler implements RequestHandler&lt;MyEventWithXML, String&gt; {\n\n@Override\n@Validation(inboundSchema=\"classpath:/schema.json\", envelope=\"powertools_xml(path.to.xml_data)\")\npublic String handleRequest(MyEventWithXML myEvent, Context context) {\nreturn \"OK\";\n}\n}\n</code></pre>"}]}